{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "Lzt1SMEoSshL",
        "EgfaelmnXe04",
        "m-Hm3lsWXkbE",
        "Na73oRb9Xq69",
        "DBnTIBCDGX94",
        "mLO6GGJ5Nn9w",
        "2aZgEs15Kln5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cXWIFrrheAli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09b9852-670a-4388-9fe5-5267f8c09fb8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/model_line.zip' -d '/content/drive/MyDrive/model_line'"
      ],
      "metadata": {
        "id": "IMsCkbbpeDvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6ba509-4e6d-42b3-8562-1567bcc35d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/model_line.zip\n",
            "   creating: /content/drive/MyDrive/model_line/model_line/\n",
            "   creating: /content/drive/MyDrive/model_line/model_line/band/\n",
            "  inflating: /content/drive/MyDrive/model_line/model_line/band/test_band_line.csv  \n",
            "  inflating: /content/drive/MyDrive/model_line/model_line/band/train_band_line.csv  \n",
            "  inflating: /content/drive/MyDrive/model_line/model_line/band/valid_band_line.csv  \n",
            "   creating: /content/drive/MyDrive/model_line/model_line/high/\n",
            "  inflating: /content/drive/MyDrive/model_line/model_line/high/test_high_line.csv  \n",
            "  inflating: /content/drive/MyDrive/model_line/model_line/high/train_high_line.csv  \n",
            "  inflating: /content/drive/MyDrive/model_line/model_line/high/valid_high_line.csv  \n",
            "   creating: /content/drive/MyDrive/model_line/model_line/low/\n",
            "  inflating: /content/drive/MyDrive/model_line/model_line/low/test_low_line.csv  \n",
            "  inflating: /content/drive/MyDrive/model_line/model_line/low/train_low_line.csv  \n",
            "  inflating: /content/drive/MyDrive/model_line/model_line/low/valid_low_line.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Nhn3soxJQYzl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import itertools\n",
        "import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import (CosineAnnealingLR,\n",
        "                                      CosineAnnealingWarmRestarts,\n",
        "                                      StepLR,\n",
        "                                      ExponentialLR)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, auc, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm, re, sys\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint"
      ],
      "metadata": {
        "id": "88FIZSPSbA_H"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv('/content/drive/MyDrive/model_line/model_line/band/train_band_line.csv', header=None)\n",
        "data_test = pd.read_csv('/content/drive/MyDrive/model_line/model_line/band/test_band_line.csv', header=None)\n",
        "data_val= pd.read_csv('/content/drive/MyDrive/model_line/model_line/band/valid_band_line.csv', header=None)"
      ],
      "metadata": {
        "id": "Fo2pj1pSfN4N"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "YXRC4G52hrnx",
        "outputId": "002ac671-37bf-4761-bfc5-9a1f968b1160"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0    -0.013974 -0.011168 -0.009118 -0.008067 -0.008125 -0.009210 -0.011005   \n",
              "1    -0.168748 -0.165213 -0.162149 -0.159616 -0.157617 -0.156088 -0.154895   \n",
              "2    -0.065523 -0.063387 -0.062618 -0.063184 -0.064857 -0.067233 -0.069777   \n",
              "3     0.517435  0.633848  0.709706  0.733996  0.703265  0.622346  0.503432   \n",
              "4    -0.069052 -0.066942 -0.064951 -0.062974 -0.060851 -0.058435 -0.055658   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5995  0.004594  0.009590  0.017135  0.025880  0.034416  0.041620  0.046867   \n",
              "5996  0.017135  0.017694  0.019432  0.022356  0.026302  0.030971  0.035976   \n",
              "5997 -0.061678 -0.060521 -0.059365 -0.058206 -0.057080 -0.056067 -0.055283   \n",
              "5998 -0.039287 -0.039374 -0.039054 -0.038510 -0.037933 -0.037494 -0.037327   \n",
              "5999  0.030423 -0.043405 -0.110988 -0.163599 -0.195505 -0.204771 -0.193219   \n",
              "\n",
              "           7         8         9    ...       246       247       248  \\\n",
              "0    -0.012983 -0.014471 -0.014771  ...  0.006733  0.009824  0.013030   \n",
              "1    -0.153851 -0.152741 -0.151345  ... -0.112212 -0.109266 -0.106187   \n",
              "2    -0.071909 -0.073104 -0.072994  ... -0.108012 -0.104863 -0.102909   \n",
              "3     0.363695  0.221988  0.095392  ... -0.079957 -0.067902 -0.046360   \n",
              "4    -0.052576 -0.049378 -0.046363  ... -0.134398 -0.135559 -0.138471   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5995  0.050103  0.051777  0.052674  ...  0.045016  0.016083 -0.009705   \n",
              "5996  0.040891  0.045291  0.048799  ...  0.005152  0.044268  0.089211   \n",
              "5997 -0.054843 -0.054816 -0.055175  ... -0.046773 -0.050592 -0.052317   \n",
              "5998 -0.037532 -0.038153 -0.039167  ... -0.058137 -0.060069 -0.061489   \n",
              "5999 -0.165648 -0.128563 -0.088765  ...  0.125802  0.136895  0.147996   \n",
              "\n",
              "           249       250       251       252       253       254       255  \n",
              "0     0.016239  0.019380  0.022418  0.025327  0.028062  0.030516  0.032514  \n",
              "1    -0.103433 -0.101427 -0.100452 -0.100579 -0.101653 -0.103329 -0.105151  \n",
              "2    -0.101926 -0.101481 -0.101056 -0.100197 -0.098638 -0.096375 -0.093669  \n",
              "3    -0.023911 -0.006614  0.002560  0.003524 -0.001689 -0.009950 -0.018044  \n",
              "4    -0.142558 -0.147015 -0.150950 -0.153535 -0.154163 -0.152557 -0.148830  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "5995 -0.032355 -0.052129 -0.069386 -0.084460 -0.097612 -0.109031 -0.118868  \n",
              "5996  0.134152  0.171846  0.194955  0.197629  0.176948  0.133840  0.073184  \n",
              "5997 -0.052018 -0.049965 -0.046587 -0.042433 -0.038139 -0.034393 -0.031913  \n",
              "5998 -0.061986 -0.061385 -0.059834 -0.057803 -0.055972 -0.055062 -0.055631  \n",
              "5999  0.158825  0.169190  0.179084  0.188748  0.198658  0.209439  0.221705  \n",
              "\n",
              "[6000 rows x 256 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-487fde9f-e4c0-4700-a4cb-1889106da2b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.013974</td>\n",
              "      <td>-0.011168</td>\n",
              "      <td>-0.009118</td>\n",
              "      <td>-0.008067</td>\n",
              "      <td>-0.008125</td>\n",
              "      <td>-0.009210</td>\n",
              "      <td>-0.011005</td>\n",
              "      <td>-0.012983</td>\n",
              "      <td>-0.014471</td>\n",
              "      <td>-0.014771</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006733</td>\n",
              "      <td>0.009824</td>\n",
              "      <td>0.013030</td>\n",
              "      <td>0.016239</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.022418</td>\n",
              "      <td>0.025327</td>\n",
              "      <td>0.028062</td>\n",
              "      <td>0.030516</td>\n",
              "      <td>0.032514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.168748</td>\n",
              "      <td>-0.165213</td>\n",
              "      <td>-0.162149</td>\n",
              "      <td>-0.159616</td>\n",
              "      <td>-0.157617</td>\n",
              "      <td>-0.156088</td>\n",
              "      <td>-0.154895</td>\n",
              "      <td>-0.153851</td>\n",
              "      <td>-0.152741</td>\n",
              "      <td>-0.151345</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.112212</td>\n",
              "      <td>-0.109266</td>\n",
              "      <td>-0.106187</td>\n",
              "      <td>-0.103433</td>\n",
              "      <td>-0.101427</td>\n",
              "      <td>-0.100452</td>\n",
              "      <td>-0.100579</td>\n",
              "      <td>-0.101653</td>\n",
              "      <td>-0.103329</td>\n",
              "      <td>-0.105151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.065523</td>\n",
              "      <td>-0.063387</td>\n",
              "      <td>-0.062618</td>\n",
              "      <td>-0.063184</td>\n",
              "      <td>-0.064857</td>\n",
              "      <td>-0.067233</td>\n",
              "      <td>-0.069777</td>\n",
              "      <td>-0.071909</td>\n",
              "      <td>-0.073104</td>\n",
              "      <td>-0.072994</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108012</td>\n",
              "      <td>-0.104863</td>\n",
              "      <td>-0.102909</td>\n",
              "      <td>-0.101926</td>\n",
              "      <td>-0.101481</td>\n",
              "      <td>-0.101056</td>\n",
              "      <td>-0.100197</td>\n",
              "      <td>-0.098638</td>\n",
              "      <td>-0.096375</td>\n",
              "      <td>-0.093669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.517435</td>\n",
              "      <td>0.633848</td>\n",
              "      <td>0.709706</td>\n",
              "      <td>0.733996</td>\n",
              "      <td>0.703265</td>\n",
              "      <td>0.622346</td>\n",
              "      <td>0.503432</td>\n",
              "      <td>0.363695</td>\n",
              "      <td>0.221988</td>\n",
              "      <td>0.095392</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.079957</td>\n",
              "      <td>-0.067902</td>\n",
              "      <td>-0.046360</td>\n",
              "      <td>-0.023911</td>\n",
              "      <td>-0.006614</td>\n",
              "      <td>0.002560</td>\n",
              "      <td>0.003524</td>\n",
              "      <td>-0.001689</td>\n",
              "      <td>-0.009950</td>\n",
              "      <td>-0.018044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.069052</td>\n",
              "      <td>-0.066942</td>\n",
              "      <td>-0.064951</td>\n",
              "      <td>-0.062974</td>\n",
              "      <td>-0.060851</td>\n",
              "      <td>-0.058435</td>\n",
              "      <td>-0.055658</td>\n",
              "      <td>-0.052576</td>\n",
              "      <td>-0.049378</td>\n",
              "      <td>-0.046363</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.134398</td>\n",
              "      <td>-0.135559</td>\n",
              "      <td>-0.138471</td>\n",
              "      <td>-0.142558</td>\n",
              "      <td>-0.147015</td>\n",
              "      <td>-0.150950</td>\n",
              "      <td>-0.153535</td>\n",
              "      <td>-0.154163</td>\n",
              "      <td>-0.152557</td>\n",
              "      <td>-0.148830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>0.004594</td>\n",
              "      <td>0.009590</td>\n",
              "      <td>0.017135</td>\n",
              "      <td>0.025880</td>\n",
              "      <td>0.034416</td>\n",
              "      <td>0.041620</td>\n",
              "      <td>0.046867</td>\n",
              "      <td>0.050103</td>\n",
              "      <td>0.051777</td>\n",
              "      <td>0.052674</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045016</td>\n",
              "      <td>0.016083</td>\n",
              "      <td>-0.009705</td>\n",
              "      <td>-0.032355</td>\n",
              "      <td>-0.052129</td>\n",
              "      <td>-0.069386</td>\n",
              "      <td>-0.084460</td>\n",
              "      <td>-0.097612</td>\n",
              "      <td>-0.109031</td>\n",
              "      <td>-0.118868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>0.017135</td>\n",
              "      <td>0.017694</td>\n",
              "      <td>0.019432</td>\n",
              "      <td>0.022356</td>\n",
              "      <td>0.026302</td>\n",
              "      <td>0.030971</td>\n",
              "      <td>0.035976</td>\n",
              "      <td>0.040891</td>\n",
              "      <td>0.045291</td>\n",
              "      <td>0.048799</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005152</td>\n",
              "      <td>0.044268</td>\n",
              "      <td>0.089211</td>\n",
              "      <td>0.134152</td>\n",
              "      <td>0.171846</td>\n",
              "      <td>0.194955</td>\n",
              "      <td>0.197629</td>\n",
              "      <td>0.176948</td>\n",
              "      <td>0.133840</td>\n",
              "      <td>0.073184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>-0.061678</td>\n",
              "      <td>-0.060521</td>\n",
              "      <td>-0.059365</td>\n",
              "      <td>-0.058206</td>\n",
              "      <td>-0.057080</td>\n",
              "      <td>-0.056067</td>\n",
              "      <td>-0.055283</td>\n",
              "      <td>-0.054843</td>\n",
              "      <td>-0.054816</td>\n",
              "      <td>-0.055175</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.046773</td>\n",
              "      <td>-0.050592</td>\n",
              "      <td>-0.052317</td>\n",
              "      <td>-0.052018</td>\n",
              "      <td>-0.049965</td>\n",
              "      <td>-0.046587</td>\n",
              "      <td>-0.042433</td>\n",
              "      <td>-0.038139</td>\n",
              "      <td>-0.034393</td>\n",
              "      <td>-0.031913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>-0.039287</td>\n",
              "      <td>-0.039374</td>\n",
              "      <td>-0.039054</td>\n",
              "      <td>-0.038510</td>\n",
              "      <td>-0.037933</td>\n",
              "      <td>-0.037494</td>\n",
              "      <td>-0.037327</td>\n",
              "      <td>-0.037532</td>\n",
              "      <td>-0.038153</td>\n",
              "      <td>-0.039167</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.058137</td>\n",
              "      <td>-0.060069</td>\n",
              "      <td>-0.061489</td>\n",
              "      <td>-0.061986</td>\n",
              "      <td>-0.061385</td>\n",
              "      <td>-0.059834</td>\n",
              "      <td>-0.057803</td>\n",
              "      <td>-0.055972</td>\n",
              "      <td>-0.055062</td>\n",
              "      <td>-0.055631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>0.030423</td>\n",
              "      <td>-0.043405</td>\n",
              "      <td>-0.110988</td>\n",
              "      <td>-0.163599</td>\n",
              "      <td>-0.195505</td>\n",
              "      <td>-0.204771</td>\n",
              "      <td>-0.193219</td>\n",
              "      <td>-0.165648</td>\n",
              "      <td>-0.128563</td>\n",
              "      <td>-0.088765</td>\n",
              "      <td>...</td>\n",
              "      <td>0.125802</td>\n",
              "      <td>0.136895</td>\n",
              "      <td>0.147996</td>\n",
              "      <td>0.158825</td>\n",
              "      <td>0.169190</td>\n",
              "      <td>0.179084</td>\n",
              "      <td>0.188748</td>\n",
              "      <td>0.198658</td>\n",
              "      <td>0.209439</td>\n",
              "      <td>0.221705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 256 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-487fde9f-e4c0-4700-a4cb-1889106da2b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-487fde9f-e4c0-4700-a4cb-1889106da2b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-487fde9f-e4c0-4700-a4cb-1889106da2b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiFAK_crtJzg",
        "outputId": "65000220-cad9-47d9-b5ba-7848ad634ff6"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24000, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라벨생성"
      ],
      "metadata": {
        "id": "jaOKRwI5j8AT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([])\n",
        "\n",
        "for i in range(1,101):\n",
        "  for j in range(240):\n",
        "    arr = np.append(arr, np.array([i]))"
      ],
      "metadata": {
        "id": "fGX-38SD_5Ec"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train[256]=arr"
      ],
      "metadata": {
        "id": "j9sXeCZSMUpF"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "a2aUe3Cpex1M",
        "outputId": "59d34289-7de2-4496-8653-0ec4cb8bde87"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "0     -0.031820 -0.015874 -0.001172  0.011249  0.020713  0.026974  0.030190   \n",
              "1     -0.019872 -0.020594 -0.021637 -0.022515 -0.022798 -0.022202 -0.020644   \n",
              "2     -0.057454 -0.056822 -0.055984 -0.054985 -0.053945 -0.052999 -0.052250   \n",
              "3     -0.056099 -0.057035 -0.058395 -0.060043 -0.061694 -0.062967 -0.063465   \n",
              "4      0.053295  0.053439  0.055066  0.059409  0.067278  0.078961  0.094216   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "23995  0.043512  0.020932  0.001382 -0.014947 -0.027957 -0.037670 -0.044270   \n",
              "23996 -0.076867 -0.083002 -0.088128 -0.091454 -0.092582 -0.091623 -0.089189   \n",
              "23997  0.022090  0.024929  0.027786  0.031100  0.035075  0.039622  0.044402   \n",
              "23998 -0.079288 -0.083358 -0.086464 -0.087995 -0.087513 -0.084880 -0.080336   \n",
              "23999 -0.076782 -0.072269 -0.066348 -0.059776 -0.053461 -0.048271 -0.044867   \n",
              "\n",
              "            7         8         9    ...       247       248       249  \\\n",
              "0      0.030831  0.029559  0.027102  ... -0.035003 -0.034647 -0.033418   \n",
              "1     -0.018236 -0.015233 -0.011971  ... -0.072854 -0.070401 -0.067539   \n",
              "2     -0.051733 -0.051414 -0.051213  ... -0.059447 -0.057278 -0.056011   \n",
              "3     -0.062887 -0.061116 -0.058272  ... -0.071806 -0.071741 -0.071302   \n",
              "4      0.112361  0.132422  0.153321  ...  0.150072  0.164082  0.180535   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "23995 -0.048123 -0.049775 -0.049906  ... -0.020100 -0.018824 -0.018132   \n",
              "23996 -0.086281 -0.084051 -0.083490  ... -0.019352 -0.019054 -0.016308   \n",
              "23997  0.048933  0.052740  0.055510  ... -0.053679 -0.057318 -0.059515   \n",
              "23998 -0.074488 -0.068211 -0.062467  ... -0.066882 -0.067113 -0.068424   \n",
              "23999 -0.043568 -0.044302 -0.046625  ... -0.048461 -0.044455 -0.041670   \n",
              "\n",
              "            250       251       252       253       254       255    256  \n",
              "0     -0.031305 -0.028545 -0.025565 -0.022868 -0.020891 -0.019891    1.0  \n",
              "1     -0.064716 -0.062285 -0.060443 -0.059208 -0.058448 -0.057940    1.0  \n",
              "2     -0.055424 -0.055246 -0.055239 -0.055275 -0.055352 -0.055577    1.0  \n",
              "3     -0.070367 -0.068861 -0.066758 -0.064085 -0.060936 -0.057487    1.0  \n",
              "4      0.199168  0.219491  0.240843  0.262473  0.283635  0.303673    1.0  \n",
              "...         ...       ...       ...       ...       ...       ...    ...  \n",
              "23995 -0.018247 -0.019303 -0.021303 -0.024082 -0.027314 -0.030559  100.0  \n",
              "23996 -0.011295 -0.004783  0.002224  0.008807  0.014368  0.018726  100.0  \n",
              "23997 -0.061043 -0.062554 -0.064528 -0.067243 -0.070758 -0.074902  100.0  \n",
              "23998 -0.070704 -0.073600 -0.076563 -0.078930 -0.080050 -0.079413  100.0  \n",
              "23999 -0.040185 -0.039799 -0.040120 -0.040694 -0.041169 -0.041409  100.0  \n",
              "\n",
              "[24000 rows x 257 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e6f605d-e29d-4c04-9eb9-7fe4c7cf8a95\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.031820</td>\n",
              "      <td>-0.015874</td>\n",
              "      <td>-0.001172</td>\n",
              "      <td>0.011249</td>\n",
              "      <td>0.020713</td>\n",
              "      <td>0.026974</td>\n",
              "      <td>0.030190</td>\n",
              "      <td>0.030831</td>\n",
              "      <td>0.029559</td>\n",
              "      <td>0.027102</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.035003</td>\n",
              "      <td>-0.034647</td>\n",
              "      <td>-0.033418</td>\n",
              "      <td>-0.031305</td>\n",
              "      <td>-0.028545</td>\n",
              "      <td>-0.025565</td>\n",
              "      <td>-0.022868</td>\n",
              "      <td>-0.020891</td>\n",
              "      <td>-0.019891</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.019872</td>\n",
              "      <td>-0.020594</td>\n",
              "      <td>-0.021637</td>\n",
              "      <td>-0.022515</td>\n",
              "      <td>-0.022798</td>\n",
              "      <td>-0.022202</td>\n",
              "      <td>-0.020644</td>\n",
              "      <td>-0.018236</td>\n",
              "      <td>-0.015233</td>\n",
              "      <td>-0.011971</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.072854</td>\n",
              "      <td>-0.070401</td>\n",
              "      <td>-0.067539</td>\n",
              "      <td>-0.064716</td>\n",
              "      <td>-0.062285</td>\n",
              "      <td>-0.060443</td>\n",
              "      <td>-0.059208</td>\n",
              "      <td>-0.058448</td>\n",
              "      <td>-0.057940</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.057454</td>\n",
              "      <td>-0.056822</td>\n",
              "      <td>-0.055984</td>\n",
              "      <td>-0.054985</td>\n",
              "      <td>-0.053945</td>\n",
              "      <td>-0.052999</td>\n",
              "      <td>-0.052250</td>\n",
              "      <td>-0.051733</td>\n",
              "      <td>-0.051414</td>\n",
              "      <td>-0.051213</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059447</td>\n",
              "      <td>-0.057278</td>\n",
              "      <td>-0.056011</td>\n",
              "      <td>-0.055424</td>\n",
              "      <td>-0.055246</td>\n",
              "      <td>-0.055239</td>\n",
              "      <td>-0.055275</td>\n",
              "      <td>-0.055352</td>\n",
              "      <td>-0.055577</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.056099</td>\n",
              "      <td>-0.057035</td>\n",
              "      <td>-0.058395</td>\n",
              "      <td>-0.060043</td>\n",
              "      <td>-0.061694</td>\n",
              "      <td>-0.062967</td>\n",
              "      <td>-0.063465</td>\n",
              "      <td>-0.062887</td>\n",
              "      <td>-0.061116</td>\n",
              "      <td>-0.058272</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.071806</td>\n",
              "      <td>-0.071741</td>\n",
              "      <td>-0.071302</td>\n",
              "      <td>-0.070367</td>\n",
              "      <td>-0.068861</td>\n",
              "      <td>-0.066758</td>\n",
              "      <td>-0.064085</td>\n",
              "      <td>-0.060936</td>\n",
              "      <td>-0.057487</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.053295</td>\n",
              "      <td>0.053439</td>\n",
              "      <td>0.055066</td>\n",
              "      <td>0.059409</td>\n",
              "      <td>0.067278</td>\n",
              "      <td>0.078961</td>\n",
              "      <td>0.094216</td>\n",
              "      <td>0.112361</td>\n",
              "      <td>0.132422</td>\n",
              "      <td>0.153321</td>\n",
              "      <td>...</td>\n",
              "      <td>0.150072</td>\n",
              "      <td>0.164082</td>\n",
              "      <td>0.180535</td>\n",
              "      <td>0.199168</td>\n",
              "      <td>0.219491</td>\n",
              "      <td>0.240843</td>\n",
              "      <td>0.262473</td>\n",
              "      <td>0.283635</td>\n",
              "      <td>0.303673</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23995</th>\n",
              "      <td>0.043512</td>\n",
              "      <td>0.020932</td>\n",
              "      <td>0.001382</td>\n",
              "      <td>-0.014947</td>\n",
              "      <td>-0.027957</td>\n",
              "      <td>-0.037670</td>\n",
              "      <td>-0.044270</td>\n",
              "      <td>-0.048123</td>\n",
              "      <td>-0.049775</td>\n",
              "      <td>-0.049906</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020100</td>\n",
              "      <td>-0.018824</td>\n",
              "      <td>-0.018132</td>\n",
              "      <td>-0.018247</td>\n",
              "      <td>-0.019303</td>\n",
              "      <td>-0.021303</td>\n",
              "      <td>-0.024082</td>\n",
              "      <td>-0.027314</td>\n",
              "      <td>-0.030559</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23996</th>\n",
              "      <td>-0.076867</td>\n",
              "      <td>-0.083002</td>\n",
              "      <td>-0.088128</td>\n",
              "      <td>-0.091454</td>\n",
              "      <td>-0.092582</td>\n",
              "      <td>-0.091623</td>\n",
              "      <td>-0.089189</td>\n",
              "      <td>-0.086281</td>\n",
              "      <td>-0.084051</td>\n",
              "      <td>-0.083490</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.019352</td>\n",
              "      <td>-0.019054</td>\n",
              "      <td>-0.016308</td>\n",
              "      <td>-0.011295</td>\n",
              "      <td>-0.004783</td>\n",
              "      <td>0.002224</td>\n",
              "      <td>0.008807</td>\n",
              "      <td>0.014368</td>\n",
              "      <td>0.018726</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23997</th>\n",
              "      <td>0.022090</td>\n",
              "      <td>0.024929</td>\n",
              "      <td>0.027786</td>\n",
              "      <td>0.031100</td>\n",
              "      <td>0.035075</td>\n",
              "      <td>0.039622</td>\n",
              "      <td>0.044402</td>\n",
              "      <td>0.048933</td>\n",
              "      <td>0.052740</td>\n",
              "      <td>0.055510</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053679</td>\n",
              "      <td>-0.057318</td>\n",
              "      <td>-0.059515</td>\n",
              "      <td>-0.061043</td>\n",
              "      <td>-0.062554</td>\n",
              "      <td>-0.064528</td>\n",
              "      <td>-0.067243</td>\n",
              "      <td>-0.070758</td>\n",
              "      <td>-0.074902</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23998</th>\n",
              "      <td>-0.079288</td>\n",
              "      <td>-0.083358</td>\n",
              "      <td>-0.086464</td>\n",
              "      <td>-0.087995</td>\n",
              "      <td>-0.087513</td>\n",
              "      <td>-0.084880</td>\n",
              "      <td>-0.080336</td>\n",
              "      <td>-0.074488</td>\n",
              "      <td>-0.068211</td>\n",
              "      <td>-0.062467</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.066882</td>\n",
              "      <td>-0.067113</td>\n",
              "      <td>-0.068424</td>\n",
              "      <td>-0.070704</td>\n",
              "      <td>-0.073600</td>\n",
              "      <td>-0.076563</td>\n",
              "      <td>-0.078930</td>\n",
              "      <td>-0.080050</td>\n",
              "      <td>-0.079413</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23999</th>\n",
              "      <td>-0.076782</td>\n",
              "      <td>-0.072269</td>\n",
              "      <td>-0.066348</td>\n",
              "      <td>-0.059776</td>\n",
              "      <td>-0.053461</td>\n",
              "      <td>-0.048271</td>\n",
              "      <td>-0.044867</td>\n",
              "      <td>-0.043568</td>\n",
              "      <td>-0.044302</td>\n",
              "      <td>-0.046625</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.048461</td>\n",
              "      <td>-0.044455</td>\n",
              "      <td>-0.041670</td>\n",
              "      <td>-0.040185</td>\n",
              "      <td>-0.039799</td>\n",
              "      <td>-0.040120</td>\n",
              "      <td>-0.040694</td>\n",
              "      <td>-0.041169</td>\n",
              "      <td>-0.041409</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24000 rows × 257 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e6f605d-e29d-4c04-9eb9-7fe4c7cf8a95')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e6f605d-e29d-4c04-9eb9-7fe4c7cf8a95 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e6f605d-e29d-4c04-9eb9-7fe4c7cf8a95');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_t = np.array([])\n",
        "\n",
        "for i in range(1,101):\n",
        "  for j in range(60):\n",
        "    arr_t = np.append(arr_t, np.array([i]))"
      ],
      "metadata": {
        "id": "flq_Q9uOe5fd"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_v = np.array([])\n",
        "\n",
        "for i in range(1,101):\n",
        "  for j in range(60):\n",
        "    arr_v = np.append(arr_v, np.array([i]))"
      ],
      "metadata": {
        "id": "ddgT-ntvfAbn"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test[256]=arr_t\n",
        "data_val[256]=arr_v\n",
        "data_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "daFrtTuHfD96",
        "outputId": "7922c18f-eb72-48fe-a4b3-ec118e6fd41b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0    -0.054004 -0.050825 -0.048322 -0.046824 -0.046532 -0.047445 -0.049330   \n",
              "1    -0.209505 -0.208403 -0.206688 -0.204586 -0.202338 -0.200196 -0.198379   \n",
              "2    -0.067735 -0.065806 -0.063513 -0.060990 -0.058453 -0.056174 -0.054439   \n",
              "3    -0.002916 -0.007004 -0.012949 -0.020332 -0.028344 -0.035829 -0.041422   \n",
              "4    -0.028844 -0.028027 -0.028309 -0.029364 -0.030767 -0.032072 -0.032878   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5995  0.015685  0.016545  0.014765  0.010665  0.004884 -0.001771 -0.008494   \n",
              "5996 -0.171624 -0.175496 -0.177258 -0.176626 -0.173694 -0.168915 -0.163017   \n",
              "5997  0.000168 -0.001110 -0.003542 -0.006028 -0.007548 -0.007396 -0.005302   \n",
              "5998 -0.033347 -0.035287 -0.036169 -0.036014 -0.035070 -0.033744 -0.032503   \n",
              "5999 -0.041533 -0.041870 -0.042836 -0.044782 -0.047871 -0.052004 -0.056828   \n",
              "\n",
              "           7         8         9    ...       247       248       249  \\\n",
              "0    -0.051735 -0.054058 -0.055645  ... -0.028530 -0.029492 -0.029945   \n",
              "1    -0.197017 -0.196097 -0.195447  ... -0.205948 -0.202740 -0.198907   \n",
              "2    -0.053477 -0.053402 -0.054158  ... -0.093394 -0.093535 -0.092581   \n",
              "3    -0.043775 -0.041865 -0.035337  ... -0.097242 -0.124400 -0.137850   \n",
              "4    -0.032899 -0.032005 -0.030247  ... -0.074225 -0.075851 -0.077197   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5995 -0.014652 -0.019878 -0.024092  ... -0.052522 -0.020671  0.001335   \n",
              "5996 -0.156862 -0.151287 -0.146943  ...  0.013368  0.016800  0.019352   \n",
              "5997 -0.001433  0.003712  0.009473  ... -0.072272 -0.071268 -0.070220   \n",
              "5998 -0.031760 -0.031802 -0.032746  ... -0.036757 -0.033683 -0.032034   \n",
              "5999 -0.061806 -0.066332 -0.069845  ...  0.007247  0.056263  0.107776   \n",
              "\n",
              "           250       251       252       253       254       255    256  \n",
              "0    -0.029648 -0.028487 -0.026485 -0.023782 -0.020603 -0.017228    1.0  \n",
              "1    -0.194673 -0.190228 -0.185713 -0.181227 -0.176850 -0.172660    1.0  \n",
              "2    -0.090373 -0.086983 -0.082689 -0.077914 -0.073148 -0.068878    1.0  \n",
              "3    -0.128147 -0.087559 -0.012153  0.096530  0.230711  0.376848    1.0  \n",
              "4    -0.077950 -0.077920 -0.077074 -0.075531 -0.073514 -0.071283    1.0  \n",
              "...        ...       ...       ...       ...       ...       ...    ...  \n",
              "5995  0.013226  0.016606  0.014270  0.009428  0.004988  0.003041  100.0  \n",
              "5996  0.020889  0.021392  0.020985  0.019940  0.018650  0.017569  100.0  \n",
              "5997 -0.069094 -0.067885 -0.066618 -0.065335 -0.064074 -0.062856  100.0  \n",
              "5998 -0.031757 -0.032584 -0.034107 -0.035874 -0.037486 -0.038665  100.0  \n",
              "5999  0.154395  0.188125  0.201986  0.191623  0.156499  0.100301  100.0  \n",
              "\n",
              "[6000 rows x 257 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd2920ea-79af-42c0-841c-c3009ab56842\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.054004</td>\n",
              "      <td>-0.050825</td>\n",
              "      <td>-0.048322</td>\n",
              "      <td>-0.046824</td>\n",
              "      <td>-0.046532</td>\n",
              "      <td>-0.047445</td>\n",
              "      <td>-0.049330</td>\n",
              "      <td>-0.051735</td>\n",
              "      <td>-0.054058</td>\n",
              "      <td>-0.055645</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028530</td>\n",
              "      <td>-0.029492</td>\n",
              "      <td>-0.029945</td>\n",
              "      <td>-0.029648</td>\n",
              "      <td>-0.028487</td>\n",
              "      <td>-0.026485</td>\n",
              "      <td>-0.023782</td>\n",
              "      <td>-0.020603</td>\n",
              "      <td>-0.017228</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.209505</td>\n",
              "      <td>-0.208403</td>\n",
              "      <td>-0.206688</td>\n",
              "      <td>-0.204586</td>\n",
              "      <td>-0.202338</td>\n",
              "      <td>-0.200196</td>\n",
              "      <td>-0.198379</td>\n",
              "      <td>-0.197017</td>\n",
              "      <td>-0.196097</td>\n",
              "      <td>-0.195447</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.205948</td>\n",
              "      <td>-0.202740</td>\n",
              "      <td>-0.198907</td>\n",
              "      <td>-0.194673</td>\n",
              "      <td>-0.190228</td>\n",
              "      <td>-0.185713</td>\n",
              "      <td>-0.181227</td>\n",
              "      <td>-0.176850</td>\n",
              "      <td>-0.172660</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.067735</td>\n",
              "      <td>-0.065806</td>\n",
              "      <td>-0.063513</td>\n",
              "      <td>-0.060990</td>\n",
              "      <td>-0.058453</td>\n",
              "      <td>-0.056174</td>\n",
              "      <td>-0.054439</td>\n",
              "      <td>-0.053477</td>\n",
              "      <td>-0.053402</td>\n",
              "      <td>-0.054158</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.093394</td>\n",
              "      <td>-0.093535</td>\n",
              "      <td>-0.092581</td>\n",
              "      <td>-0.090373</td>\n",
              "      <td>-0.086983</td>\n",
              "      <td>-0.082689</td>\n",
              "      <td>-0.077914</td>\n",
              "      <td>-0.073148</td>\n",
              "      <td>-0.068878</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.002916</td>\n",
              "      <td>-0.007004</td>\n",
              "      <td>-0.012949</td>\n",
              "      <td>-0.020332</td>\n",
              "      <td>-0.028344</td>\n",
              "      <td>-0.035829</td>\n",
              "      <td>-0.041422</td>\n",
              "      <td>-0.043775</td>\n",
              "      <td>-0.041865</td>\n",
              "      <td>-0.035337</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.097242</td>\n",
              "      <td>-0.124400</td>\n",
              "      <td>-0.137850</td>\n",
              "      <td>-0.128147</td>\n",
              "      <td>-0.087559</td>\n",
              "      <td>-0.012153</td>\n",
              "      <td>0.096530</td>\n",
              "      <td>0.230711</td>\n",
              "      <td>0.376848</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.028844</td>\n",
              "      <td>-0.028027</td>\n",
              "      <td>-0.028309</td>\n",
              "      <td>-0.029364</td>\n",
              "      <td>-0.030767</td>\n",
              "      <td>-0.032072</td>\n",
              "      <td>-0.032878</td>\n",
              "      <td>-0.032899</td>\n",
              "      <td>-0.032005</td>\n",
              "      <td>-0.030247</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.074225</td>\n",
              "      <td>-0.075851</td>\n",
              "      <td>-0.077197</td>\n",
              "      <td>-0.077950</td>\n",
              "      <td>-0.077920</td>\n",
              "      <td>-0.077074</td>\n",
              "      <td>-0.075531</td>\n",
              "      <td>-0.073514</td>\n",
              "      <td>-0.071283</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.016545</td>\n",
              "      <td>0.014765</td>\n",
              "      <td>0.010665</td>\n",
              "      <td>0.004884</td>\n",
              "      <td>-0.001771</td>\n",
              "      <td>-0.008494</td>\n",
              "      <td>-0.014652</td>\n",
              "      <td>-0.019878</td>\n",
              "      <td>-0.024092</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.052522</td>\n",
              "      <td>-0.020671</td>\n",
              "      <td>0.001335</td>\n",
              "      <td>0.013226</td>\n",
              "      <td>0.016606</td>\n",
              "      <td>0.014270</td>\n",
              "      <td>0.009428</td>\n",
              "      <td>0.004988</td>\n",
              "      <td>0.003041</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>-0.171624</td>\n",
              "      <td>-0.175496</td>\n",
              "      <td>-0.177258</td>\n",
              "      <td>-0.176626</td>\n",
              "      <td>-0.173694</td>\n",
              "      <td>-0.168915</td>\n",
              "      <td>-0.163017</td>\n",
              "      <td>-0.156862</td>\n",
              "      <td>-0.151287</td>\n",
              "      <td>-0.146943</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013368</td>\n",
              "      <td>0.016800</td>\n",
              "      <td>0.019352</td>\n",
              "      <td>0.020889</td>\n",
              "      <td>0.021392</td>\n",
              "      <td>0.020985</td>\n",
              "      <td>0.019940</td>\n",
              "      <td>0.018650</td>\n",
              "      <td>0.017569</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>0.000168</td>\n",
              "      <td>-0.001110</td>\n",
              "      <td>-0.003542</td>\n",
              "      <td>-0.006028</td>\n",
              "      <td>-0.007548</td>\n",
              "      <td>-0.007396</td>\n",
              "      <td>-0.005302</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>0.003712</td>\n",
              "      <td>0.009473</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.072272</td>\n",
              "      <td>-0.071268</td>\n",
              "      <td>-0.070220</td>\n",
              "      <td>-0.069094</td>\n",
              "      <td>-0.067885</td>\n",
              "      <td>-0.066618</td>\n",
              "      <td>-0.065335</td>\n",
              "      <td>-0.064074</td>\n",
              "      <td>-0.062856</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>-0.033347</td>\n",
              "      <td>-0.035287</td>\n",
              "      <td>-0.036169</td>\n",
              "      <td>-0.036014</td>\n",
              "      <td>-0.035070</td>\n",
              "      <td>-0.033744</td>\n",
              "      <td>-0.032503</td>\n",
              "      <td>-0.031760</td>\n",
              "      <td>-0.031802</td>\n",
              "      <td>-0.032746</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.036757</td>\n",
              "      <td>-0.033683</td>\n",
              "      <td>-0.032034</td>\n",
              "      <td>-0.031757</td>\n",
              "      <td>-0.032584</td>\n",
              "      <td>-0.034107</td>\n",
              "      <td>-0.035874</td>\n",
              "      <td>-0.037486</td>\n",
              "      <td>-0.038665</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>-0.041533</td>\n",
              "      <td>-0.041870</td>\n",
              "      <td>-0.042836</td>\n",
              "      <td>-0.044782</td>\n",
              "      <td>-0.047871</td>\n",
              "      <td>-0.052004</td>\n",
              "      <td>-0.056828</td>\n",
              "      <td>-0.061806</td>\n",
              "      <td>-0.066332</td>\n",
              "      <td>-0.069845</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007247</td>\n",
              "      <td>0.056263</td>\n",
              "      <td>0.107776</td>\n",
              "      <td>0.154395</td>\n",
              "      <td>0.188125</td>\n",
              "      <td>0.201986</td>\n",
              "      <td>0.191623</td>\n",
              "      <td>0.156499</td>\n",
              "      <td>0.100301</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 257 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd2920ea-79af-42c0-841c-c3009ab56842')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd2920ea-79af-42c0-841c-c3009ab56842 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd2920ea-79af-42c0-841c-c3009ab56842');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train = arr\n",
        "# y_test = arr_t\n",
        "# y_val = arr_v"
      ],
      "metadata": {
        "id": "AtpvllHJRIr_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전체 섞기"
      ],
      "metadata": {
        "id": "I7BNW6vLSn40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_total=pd.concat([data_train, data_test, data_val])\n",
        "data_total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Tb9_tMy0SUkK",
        "outputId": "2f041d36-e4eb-4018-a1d3-b59287d53f2e"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0    -0.031820 -0.015874 -0.001172  0.011249  0.020713  0.026974  0.030190   \n",
              "1    -0.019872 -0.020594 -0.021637 -0.022515 -0.022798 -0.022202 -0.020644   \n",
              "2    -0.057454 -0.056822 -0.055984 -0.054985 -0.053945 -0.052999 -0.052250   \n",
              "3    -0.056099 -0.057035 -0.058395 -0.060043 -0.061694 -0.062967 -0.063465   \n",
              "4     0.053295  0.053439  0.055066  0.059409  0.067278  0.078961  0.094216   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5995  0.015685  0.016545  0.014765  0.010665  0.004884 -0.001771 -0.008494   \n",
              "5996 -0.171624 -0.175496 -0.177258 -0.176626 -0.173694 -0.168915 -0.163017   \n",
              "5997  0.000168 -0.001110 -0.003542 -0.006028 -0.007548 -0.007396 -0.005302   \n",
              "5998 -0.033347 -0.035287 -0.036169 -0.036014 -0.035070 -0.033744 -0.032503   \n",
              "5999 -0.041533 -0.041870 -0.042836 -0.044782 -0.047871 -0.052004 -0.056828   \n",
              "\n",
              "           7         8         9    ...       247       248       249  \\\n",
              "0     0.030831  0.029559  0.027102  ... -0.035003 -0.034647 -0.033418   \n",
              "1    -0.018236 -0.015233 -0.011971  ... -0.072854 -0.070401 -0.067539   \n",
              "2    -0.051733 -0.051414 -0.051213  ... -0.059447 -0.057278 -0.056011   \n",
              "3    -0.062887 -0.061116 -0.058272  ... -0.071806 -0.071741 -0.071302   \n",
              "4     0.112361  0.132422  0.153321  ...  0.150072  0.164082  0.180535   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5995 -0.014652 -0.019878 -0.024092  ... -0.052522 -0.020671  0.001335   \n",
              "5996 -0.156862 -0.151287 -0.146943  ...  0.013368  0.016800  0.019352   \n",
              "5997 -0.001433  0.003712  0.009473  ... -0.072272 -0.071268 -0.070220   \n",
              "5998 -0.031760 -0.031802 -0.032746  ... -0.036757 -0.033683 -0.032034   \n",
              "5999 -0.061806 -0.066332 -0.069845  ...  0.007247  0.056263  0.107776   \n",
              "\n",
              "           250       251       252       253       254       255    256  \n",
              "0    -0.031305 -0.028545 -0.025565 -0.022868 -0.020891 -0.019891    1.0  \n",
              "1    -0.064716 -0.062285 -0.060443 -0.059208 -0.058448 -0.057940    1.0  \n",
              "2    -0.055424 -0.055246 -0.055239 -0.055275 -0.055352 -0.055577    1.0  \n",
              "3    -0.070367 -0.068861 -0.066758 -0.064085 -0.060936 -0.057487    1.0  \n",
              "4     0.199168  0.219491  0.240843  0.262473  0.283635  0.303673    1.0  \n",
              "...        ...       ...       ...       ...       ...       ...    ...  \n",
              "5995  0.013226  0.016606  0.014270  0.009428  0.004988  0.003041  100.0  \n",
              "5996  0.020889  0.021392  0.020985  0.019940  0.018650  0.017569  100.0  \n",
              "5997 -0.069094 -0.067885 -0.066618 -0.065335 -0.064074 -0.062856  100.0  \n",
              "5998 -0.031757 -0.032584 -0.034107 -0.035874 -0.037486 -0.038665  100.0  \n",
              "5999  0.154395  0.188125  0.201986  0.191623  0.156499  0.100301  100.0  \n",
              "\n",
              "[36000 rows x 257 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdca647a-841a-4e46-872c-6b85f026a599\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.031820</td>\n",
              "      <td>-0.015874</td>\n",
              "      <td>-0.001172</td>\n",
              "      <td>0.011249</td>\n",
              "      <td>0.020713</td>\n",
              "      <td>0.026974</td>\n",
              "      <td>0.030190</td>\n",
              "      <td>0.030831</td>\n",
              "      <td>0.029559</td>\n",
              "      <td>0.027102</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.035003</td>\n",
              "      <td>-0.034647</td>\n",
              "      <td>-0.033418</td>\n",
              "      <td>-0.031305</td>\n",
              "      <td>-0.028545</td>\n",
              "      <td>-0.025565</td>\n",
              "      <td>-0.022868</td>\n",
              "      <td>-0.020891</td>\n",
              "      <td>-0.019891</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.019872</td>\n",
              "      <td>-0.020594</td>\n",
              "      <td>-0.021637</td>\n",
              "      <td>-0.022515</td>\n",
              "      <td>-0.022798</td>\n",
              "      <td>-0.022202</td>\n",
              "      <td>-0.020644</td>\n",
              "      <td>-0.018236</td>\n",
              "      <td>-0.015233</td>\n",
              "      <td>-0.011971</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.072854</td>\n",
              "      <td>-0.070401</td>\n",
              "      <td>-0.067539</td>\n",
              "      <td>-0.064716</td>\n",
              "      <td>-0.062285</td>\n",
              "      <td>-0.060443</td>\n",
              "      <td>-0.059208</td>\n",
              "      <td>-0.058448</td>\n",
              "      <td>-0.057940</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.057454</td>\n",
              "      <td>-0.056822</td>\n",
              "      <td>-0.055984</td>\n",
              "      <td>-0.054985</td>\n",
              "      <td>-0.053945</td>\n",
              "      <td>-0.052999</td>\n",
              "      <td>-0.052250</td>\n",
              "      <td>-0.051733</td>\n",
              "      <td>-0.051414</td>\n",
              "      <td>-0.051213</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059447</td>\n",
              "      <td>-0.057278</td>\n",
              "      <td>-0.056011</td>\n",
              "      <td>-0.055424</td>\n",
              "      <td>-0.055246</td>\n",
              "      <td>-0.055239</td>\n",
              "      <td>-0.055275</td>\n",
              "      <td>-0.055352</td>\n",
              "      <td>-0.055577</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.056099</td>\n",
              "      <td>-0.057035</td>\n",
              "      <td>-0.058395</td>\n",
              "      <td>-0.060043</td>\n",
              "      <td>-0.061694</td>\n",
              "      <td>-0.062967</td>\n",
              "      <td>-0.063465</td>\n",
              "      <td>-0.062887</td>\n",
              "      <td>-0.061116</td>\n",
              "      <td>-0.058272</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.071806</td>\n",
              "      <td>-0.071741</td>\n",
              "      <td>-0.071302</td>\n",
              "      <td>-0.070367</td>\n",
              "      <td>-0.068861</td>\n",
              "      <td>-0.066758</td>\n",
              "      <td>-0.064085</td>\n",
              "      <td>-0.060936</td>\n",
              "      <td>-0.057487</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.053295</td>\n",
              "      <td>0.053439</td>\n",
              "      <td>0.055066</td>\n",
              "      <td>0.059409</td>\n",
              "      <td>0.067278</td>\n",
              "      <td>0.078961</td>\n",
              "      <td>0.094216</td>\n",
              "      <td>0.112361</td>\n",
              "      <td>0.132422</td>\n",
              "      <td>0.153321</td>\n",
              "      <td>...</td>\n",
              "      <td>0.150072</td>\n",
              "      <td>0.164082</td>\n",
              "      <td>0.180535</td>\n",
              "      <td>0.199168</td>\n",
              "      <td>0.219491</td>\n",
              "      <td>0.240843</td>\n",
              "      <td>0.262473</td>\n",
              "      <td>0.283635</td>\n",
              "      <td>0.303673</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>0.015685</td>\n",
              "      <td>0.016545</td>\n",
              "      <td>0.014765</td>\n",
              "      <td>0.010665</td>\n",
              "      <td>0.004884</td>\n",
              "      <td>-0.001771</td>\n",
              "      <td>-0.008494</td>\n",
              "      <td>-0.014652</td>\n",
              "      <td>-0.019878</td>\n",
              "      <td>-0.024092</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.052522</td>\n",
              "      <td>-0.020671</td>\n",
              "      <td>0.001335</td>\n",
              "      <td>0.013226</td>\n",
              "      <td>0.016606</td>\n",
              "      <td>0.014270</td>\n",
              "      <td>0.009428</td>\n",
              "      <td>0.004988</td>\n",
              "      <td>0.003041</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>-0.171624</td>\n",
              "      <td>-0.175496</td>\n",
              "      <td>-0.177258</td>\n",
              "      <td>-0.176626</td>\n",
              "      <td>-0.173694</td>\n",
              "      <td>-0.168915</td>\n",
              "      <td>-0.163017</td>\n",
              "      <td>-0.156862</td>\n",
              "      <td>-0.151287</td>\n",
              "      <td>-0.146943</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013368</td>\n",
              "      <td>0.016800</td>\n",
              "      <td>0.019352</td>\n",
              "      <td>0.020889</td>\n",
              "      <td>0.021392</td>\n",
              "      <td>0.020985</td>\n",
              "      <td>0.019940</td>\n",
              "      <td>0.018650</td>\n",
              "      <td>0.017569</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>0.000168</td>\n",
              "      <td>-0.001110</td>\n",
              "      <td>-0.003542</td>\n",
              "      <td>-0.006028</td>\n",
              "      <td>-0.007548</td>\n",
              "      <td>-0.007396</td>\n",
              "      <td>-0.005302</td>\n",
              "      <td>-0.001433</td>\n",
              "      <td>0.003712</td>\n",
              "      <td>0.009473</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.072272</td>\n",
              "      <td>-0.071268</td>\n",
              "      <td>-0.070220</td>\n",
              "      <td>-0.069094</td>\n",
              "      <td>-0.067885</td>\n",
              "      <td>-0.066618</td>\n",
              "      <td>-0.065335</td>\n",
              "      <td>-0.064074</td>\n",
              "      <td>-0.062856</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>-0.033347</td>\n",
              "      <td>-0.035287</td>\n",
              "      <td>-0.036169</td>\n",
              "      <td>-0.036014</td>\n",
              "      <td>-0.035070</td>\n",
              "      <td>-0.033744</td>\n",
              "      <td>-0.032503</td>\n",
              "      <td>-0.031760</td>\n",
              "      <td>-0.031802</td>\n",
              "      <td>-0.032746</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.036757</td>\n",
              "      <td>-0.033683</td>\n",
              "      <td>-0.032034</td>\n",
              "      <td>-0.031757</td>\n",
              "      <td>-0.032584</td>\n",
              "      <td>-0.034107</td>\n",
              "      <td>-0.035874</td>\n",
              "      <td>-0.037486</td>\n",
              "      <td>-0.038665</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>-0.041533</td>\n",
              "      <td>-0.041870</td>\n",
              "      <td>-0.042836</td>\n",
              "      <td>-0.044782</td>\n",
              "      <td>-0.047871</td>\n",
              "      <td>-0.052004</td>\n",
              "      <td>-0.056828</td>\n",
              "      <td>-0.061806</td>\n",
              "      <td>-0.066332</td>\n",
              "      <td>-0.069845</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007247</td>\n",
              "      <td>0.056263</td>\n",
              "      <td>0.107776</td>\n",
              "      <td>0.154395</td>\n",
              "      <td>0.188125</td>\n",
              "      <td>0.201986</td>\n",
              "      <td>0.191623</td>\n",
              "      <td>0.156499</td>\n",
              "      <td>0.100301</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36000 rows × 257 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdca647a-841a-4e46-872c-6b85f026a599')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdca647a-841a-4e46-872c-6b85f026a599 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdca647a-841a-4e46-872c-6b85f026a599');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_total=data_total.sample(frac=1)"
      ],
      "metadata": {
        "id": "zuAljzhlSxO0"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train=data_total.iloc[0:24000, :]\n",
        "data_val=data_total.iloc[24000:30000, :]\n",
        "data_test=data_total.iloc[30000:36000,:]"
      ],
      "metadata": {
        "id": "dAO2XTRKS938"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "R03ForgAUEFw",
        "outputId": "e38cced6-7855-4917-dc60-1a93a11489f2"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "8186  -0.037284 -0.048329 -0.058503 -0.066508 -0.071368 -0.072684 -0.070804   \n",
              "22366 -0.048650 -0.046037 -0.044587 -0.044697 -0.046334 -0.049051 -0.052100   \n",
              "2073  -0.053469 -0.053767 -0.054011 -0.053957 -0.053552 -0.052913 -0.052275   \n",
              "2362   0.014389  0.006160 -0.003319 -0.013071 -0.022208 -0.030060 -0.036255   \n",
              "20763 -0.058815 -0.053162 -0.050717 -0.052377 -0.058015 -0.066290 -0.074691   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "1355   0.057892  0.093805  0.125524  0.147787  0.156261  0.148579  0.125013   \n",
              "12473  0.103140  0.109886  0.118222  0.127966  0.138690  0.149822  0.160802   \n",
              "4511   0.146784  0.158052  0.169187  0.180183  0.190975  0.201434  0.211381   \n",
              "14092  0.050343  0.046299  0.043145  0.041575  0.041935  0.044167  0.047860   \n",
              "5994  -0.076106 -0.073883 -0.070127 -0.065592 -0.061188 -0.057876 -0.056557   \n",
              "\n",
              "            7         8         9    ...       247       248       249  \\\n",
              "8186  -0.066825 -0.062381 -0.059243  ... -0.021985 -0.025304 -0.025911   \n",
              "22366 -0.054617 -0.055818 -0.055133  ... -0.049419 -0.054545 -0.059189   \n",
              "2073  -0.051902 -0.052026 -0.052796  ... -0.064871 -0.063712 -0.063389   \n",
              "2362  -0.040736 -0.043698 -0.045473  ... -0.011709 -0.006964 -0.001897   \n",
              "20763 -0.079874 -0.078268 -0.066847  ...  0.187426  0.202641  0.217023   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "1355   0.088562  0.044412 -0.001104  ...  0.149146  0.150563  0.149662   \n",
              "12473  0.171216  0.180884  0.189845  ... -0.070612 -0.071272 -0.071076   \n",
              "4511   0.220605  0.228876  0.235954  ... -0.081064 -0.078343 -0.076061   \n",
              "14092  0.052387  0.057080  0.061397  ... -0.059215 -0.056776 -0.055660   \n",
              "5994  -0.057928 -0.062336 -0.069607  ...  0.083443  0.088238  0.093848   \n",
              "\n",
              "            250       251       252       253       254       255    256  \n",
              "8186  -0.023381 -0.018003 -0.010586 -0.002185  0.006173  0.013717   35.0  \n",
              "22366 -0.063132 -0.066046 -0.067585 -0.067532 -0.065958 -0.063339   94.0  \n",
              "2073  -0.063397 -0.063330 -0.063018 -0.062562 -0.062272 -0.062536   35.0  \n",
              "2362   0.002268  0.004178  0.002571 -0.003447 -0.014101 -0.028685   10.0  \n",
              "20763  0.230066  0.241300  0.250288  0.256632  0.259989  0.260097   87.0  \n",
              "...         ...       ...       ...       ...       ...       ...    ...  \n",
              "1355   0.146883  0.142828  0.138163  0.133499  0.129270  0.125641   23.0  \n",
              "12473 -0.069987 -0.068142 -0.065822 -0.063398 -0.061259 -0.059726   52.0  \n",
              "4511  -0.074344 -0.073239 -0.072720 -0.072703 -0.073073 -0.073707   19.0  \n",
              "14092 -0.055843 -0.057051 -0.058847 -0.060763 -0.062417 -0.063609   59.0  \n",
              "5994   0.100724  0.109082  0.118882  0.129882  0.141742  0.154144  100.0  \n",
              "\n",
              "[24000 rows x 257 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd97230c-9fa0-4de2-a277-b504d735201f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8186</th>\n",
              "      <td>-0.037284</td>\n",
              "      <td>-0.048329</td>\n",
              "      <td>-0.058503</td>\n",
              "      <td>-0.066508</td>\n",
              "      <td>-0.071368</td>\n",
              "      <td>-0.072684</td>\n",
              "      <td>-0.070804</td>\n",
              "      <td>-0.066825</td>\n",
              "      <td>-0.062381</td>\n",
              "      <td>-0.059243</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.021985</td>\n",
              "      <td>-0.025304</td>\n",
              "      <td>-0.025911</td>\n",
              "      <td>-0.023381</td>\n",
              "      <td>-0.018003</td>\n",
              "      <td>-0.010586</td>\n",
              "      <td>-0.002185</td>\n",
              "      <td>0.006173</td>\n",
              "      <td>0.013717</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22366</th>\n",
              "      <td>-0.048650</td>\n",
              "      <td>-0.046037</td>\n",
              "      <td>-0.044587</td>\n",
              "      <td>-0.044697</td>\n",
              "      <td>-0.046334</td>\n",
              "      <td>-0.049051</td>\n",
              "      <td>-0.052100</td>\n",
              "      <td>-0.054617</td>\n",
              "      <td>-0.055818</td>\n",
              "      <td>-0.055133</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049419</td>\n",
              "      <td>-0.054545</td>\n",
              "      <td>-0.059189</td>\n",
              "      <td>-0.063132</td>\n",
              "      <td>-0.066046</td>\n",
              "      <td>-0.067585</td>\n",
              "      <td>-0.067532</td>\n",
              "      <td>-0.065958</td>\n",
              "      <td>-0.063339</td>\n",
              "      <td>94.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2073</th>\n",
              "      <td>-0.053469</td>\n",
              "      <td>-0.053767</td>\n",
              "      <td>-0.054011</td>\n",
              "      <td>-0.053957</td>\n",
              "      <td>-0.053552</td>\n",
              "      <td>-0.052913</td>\n",
              "      <td>-0.052275</td>\n",
              "      <td>-0.051902</td>\n",
              "      <td>-0.052026</td>\n",
              "      <td>-0.052796</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.064871</td>\n",
              "      <td>-0.063712</td>\n",
              "      <td>-0.063389</td>\n",
              "      <td>-0.063397</td>\n",
              "      <td>-0.063330</td>\n",
              "      <td>-0.063018</td>\n",
              "      <td>-0.062562</td>\n",
              "      <td>-0.062272</td>\n",
              "      <td>-0.062536</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2362</th>\n",
              "      <td>0.014389</td>\n",
              "      <td>0.006160</td>\n",
              "      <td>-0.003319</td>\n",
              "      <td>-0.013071</td>\n",
              "      <td>-0.022208</td>\n",
              "      <td>-0.030060</td>\n",
              "      <td>-0.036255</td>\n",
              "      <td>-0.040736</td>\n",
              "      <td>-0.043698</td>\n",
              "      <td>-0.045473</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.011709</td>\n",
              "      <td>-0.006964</td>\n",
              "      <td>-0.001897</td>\n",
              "      <td>0.002268</td>\n",
              "      <td>0.004178</td>\n",
              "      <td>0.002571</td>\n",
              "      <td>-0.003447</td>\n",
              "      <td>-0.014101</td>\n",
              "      <td>-0.028685</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20763</th>\n",
              "      <td>-0.058815</td>\n",
              "      <td>-0.053162</td>\n",
              "      <td>-0.050717</td>\n",
              "      <td>-0.052377</td>\n",
              "      <td>-0.058015</td>\n",
              "      <td>-0.066290</td>\n",
              "      <td>-0.074691</td>\n",
              "      <td>-0.079874</td>\n",
              "      <td>-0.078268</td>\n",
              "      <td>-0.066847</td>\n",
              "      <td>...</td>\n",
              "      <td>0.187426</td>\n",
              "      <td>0.202641</td>\n",
              "      <td>0.217023</td>\n",
              "      <td>0.230066</td>\n",
              "      <td>0.241300</td>\n",
              "      <td>0.250288</td>\n",
              "      <td>0.256632</td>\n",
              "      <td>0.259989</td>\n",
              "      <td>0.260097</td>\n",
              "      <td>87.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1355</th>\n",
              "      <td>0.057892</td>\n",
              "      <td>0.093805</td>\n",
              "      <td>0.125524</td>\n",
              "      <td>0.147787</td>\n",
              "      <td>0.156261</td>\n",
              "      <td>0.148579</td>\n",
              "      <td>0.125013</td>\n",
              "      <td>0.088562</td>\n",
              "      <td>0.044412</td>\n",
              "      <td>-0.001104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.149146</td>\n",
              "      <td>0.150563</td>\n",
              "      <td>0.149662</td>\n",
              "      <td>0.146883</td>\n",
              "      <td>0.142828</td>\n",
              "      <td>0.138163</td>\n",
              "      <td>0.133499</td>\n",
              "      <td>0.129270</td>\n",
              "      <td>0.125641</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12473</th>\n",
              "      <td>0.103140</td>\n",
              "      <td>0.109886</td>\n",
              "      <td>0.118222</td>\n",
              "      <td>0.127966</td>\n",
              "      <td>0.138690</td>\n",
              "      <td>0.149822</td>\n",
              "      <td>0.160802</td>\n",
              "      <td>0.171216</td>\n",
              "      <td>0.180884</td>\n",
              "      <td>0.189845</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.070612</td>\n",
              "      <td>-0.071272</td>\n",
              "      <td>-0.071076</td>\n",
              "      <td>-0.069987</td>\n",
              "      <td>-0.068142</td>\n",
              "      <td>-0.065822</td>\n",
              "      <td>-0.063398</td>\n",
              "      <td>-0.061259</td>\n",
              "      <td>-0.059726</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4511</th>\n",
              "      <td>0.146784</td>\n",
              "      <td>0.158052</td>\n",
              "      <td>0.169187</td>\n",
              "      <td>0.180183</td>\n",
              "      <td>0.190975</td>\n",
              "      <td>0.201434</td>\n",
              "      <td>0.211381</td>\n",
              "      <td>0.220605</td>\n",
              "      <td>0.228876</td>\n",
              "      <td>0.235954</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.081064</td>\n",
              "      <td>-0.078343</td>\n",
              "      <td>-0.076061</td>\n",
              "      <td>-0.074344</td>\n",
              "      <td>-0.073239</td>\n",
              "      <td>-0.072720</td>\n",
              "      <td>-0.072703</td>\n",
              "      <td>-0.073073</td>\n",
              "      <td>-0.073707</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14092</th>\n",
              "      <td>0.050343</td>\n",
              "      <td>0.046299</td>\n",
              "      <td>0.043145</td>\n",
              "      <td>0.041575</td>\n",
              "      <td>0.041935</td>\n",
              "      <td>0.044167</td>\n",
              "      <td>0.047860</td>\n",
              "      <td>0.052387</td>\n",
              "      <td>0.057080</td>\n",
              "      <td>0.061397</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.059215</td>\n",
              "      <td>-0.056776</td>\n",
              "      <td>-0.055660</td>\n",
              "      <td>-0.055843</td>\n",
              "      <td>-0.057051</td>\n",
              "      <td>-0.058847</td>\n",
              "      <td>-0.060763</td>\n",
              "      <td>-0.062417</td>\n",
              "      <td>-0.063609</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5994</th>\n",
              "      <td>-0.076106</td>\n",
              "      <td>-0.073883</td>\n",
              "      <td>-0.070127</td>\n",
              "      <td>-0.065592</td>\n",
              "      <td>-0.061188</td>\n",
              "      <td>-0.057876</td>\n",
              "      <td>-0.056557</td>\n",
              "      <td>-0.057928</td>\n",
              "      <td>-0.062336</td>\n",
              "      <td>-0.069607</td>\n",
              "      <td>...</td>\n",
              "      <td>0.083443</td>\n",
              "      <td>0.088238</td>\n",
              "      <td>0.093848</td>\n",
              "      <td>0.100724</td>\n",
              "      <td>0.109082</td>\n",
              "      <td>0.118882</td>\n",
              "      <td>0.129882</td>\n",
              "      <td>0.141742</td>\n",
              "      <td>0.154144</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24000 rows × 257 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd97230c-9fa0-4de2-a277-b504d735201f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd97230c-9fa0-4de2-a277-b504d735201f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd97230c-9fa0-4de2-a277-b504d735201f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 따로 섞기"
      ],
      "metadata": {
        "id": "Lzt1SMEoSshL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = data_train.sample(frac=1).reset_index(drop=True)\n",
        "data_test = data_test.sample(frac=1).reset_index(drop=True)\n",
        "data_val = data_val.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "rpmNEC3Z0gtl"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ovruSUp41EA8",
        "outputId": "e071d1b2-f4ad-4b00-cf90-3a013213ee23"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "0      0.013167  0.017490  0.018646  0.016446  0.011114  0.003245 -0.006287   \n",
              "1     -0.115512 -0.115289 -0.113396 -0.110355 -0.106877 -0.103780 -0.101890   \n",
              "2     -0.009042 -0.008103 -0.008920 -0.010897 -0.013278 -0.015248 -0.016029   \n",
              "3      0.402142  0.302911  0.185292  0.066715 -0.037182 -0.115259 -0.162345   \n",
              "4     -0.007963  0.005535  0.017452  0.026380  0.031221  0.031279  0.026293   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "23995 -0.109838 -0.112002 -0.113641 -0.114621 -0.114863 -0.114353 -0.113177   \n",
              "23996 -0.040675 -0.054378 -0.068501 -0.081380 -0.091338 -0.096999 -0.097585   \n",
              "23997 -0.019681 -0.041208 -0.061138 -0.078153 -0.091414 -0.100656 -0.106163   \n",
              "23998  0.003074 -0.012424 -0.024224 -0.032849 -0.039069 -0.043762 -0.047765   \n",
              "23999 -0.016414 -0.019264 -0.023513 -0.029241 -0.036146 -0.043594 -0.050755   \n",
              "\n",
              "            7         8         9    ...       247       248       249  \\\n",
              "0     -0.016464 -0.026283 -0.034921  ... -0.004174 -0.002091  0.000968   \n",
              "1     -0.101913 -0.104281 -0.108999  ...  0.008242  0.022894  0.039154   \n",
              "2     -0.014967 -0.011609 -0.005777  ... -0.041403 -0.040630 -0.041345   \n",
              "3     -0.179306 -0.171868 -0.148656  ... -0.079294 -0.081055 -0.082744   \n",
              "4      0.016416  0.002152 -0.015730  ...  0.008343 -0.091526 -0.188443   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "23995 -0.111554 -0.109847 -0.108525  ... -0.108024 -0.108699 -0.108706   \n",
              "23996 -0.093149 -0.084687 -0.074089  ...  0.001157  0.069442  0.143595   \n",
              "23997 -0.108632 -0.108992 -0.108220  ... -0.045588 -0.048637 -0.051353   \n",
              "23998 -0.051742 -0.056075 -0.060821  ... -0.119279 -0.118505 -0.116912   \n",
              "23999 -0.056785 -0.061007 -0.063049  ... -0.090826 -0.090601 -0.087764   \n",
              "\n",
              "            250       251       252       253       254       255   256  \n",
              "0      0.004741  0.008918  0.013208  0.017364  0.021204  0.024627  72.0  \n",
              "1      0.056616  0.074825  0.093340  0.111823  0.130108  0.148236  54.0  \n",
              "2     -0.043381 -0.046298 -0.049451 -0.052130 -0.053720 -0.053853  61.0  \n",
              "3     -0.083994 -0.084521 -0.084185 -0.083029 -0.081281 -0.079306  40.0  \n",
              "4     -0.269607 -0.325108 -0.349555 -0.342722 -0.309150 -0.256869   9.0  \n",
              "...         ...       ...       ...       ...       ...       ...   ...  \n",
              "23995 -0.108044 -0.106867 -0.105405 -0.103864 -0.102335 -0.100754  62.0  \n",
              "23996  0.214329  0.271583  0.306394  0.312725  0.288831  0.237771  41.0  \n",
              "23997 -0.053427 -0.054666 -0.054988 -0.054436 -0.053175 -0.051491  35.0  \n",
              "23998 -0.114928 -0.113008 -0.111522 -0.110699 -0.110611 -0.111212  98.0  \n",
              "23999 -0.082253 -0.074366 -0.064672 -0.053875 -0.042684 -0.031708  81.0  \n",
              "\n",
              "[24000 rows x 257 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20518848-deb8-470c-bef6-2095db7f43fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013167</td>\n",
              "      <td>0.017490</td>\n",
              "      <td>0.018646</td>\n",
              "      <td>0.016446</td>\n",
              "      <td>0.011114</td>\n",
              "      <td>0.003245</td>\n",
              "      <td>-0.006287</td>\n",
              "      <td>-0.016464</td>\n",
              "      <td>-0.026283</td>\n",
              "      <td>-0.034921</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004174</td>\n",
              "      <td>-0.002091</td>\n",
              "      <td>0.000968</td>\n",
              "      <td>0.004741</td>\n",
              "      <td>0.008918</td>\n",
              "      <td>0.013208</td>\n",
              "      <td>0.017364</td>\n",
              "      <td>0.021204</td>\n",
              "      <td>0.024627</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.115512</td>\n",
              "      <td>-0.115289</td>\n",
              "      <td>-0.113396</td>\n",
              "      <td>-0.110355</td>\n",
              "      <td>-0.106877</td>\n",
              "      <td>-0.103780</td>\n",
              "      <td>-0.101890</td>\n",
              "      <td>-0.101913</td>\n",
              "      <td>-0.104281</td>\n",
              "      <td>-0.108999</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008242</td>\n",
              "      <td>0.022894</td>\n",
              "      <td>0.039154</td>\n",
              "      <td>0.056616</td>\n",
              "      <td>0.074825</td>\n",
              "      <td>0.093340</td>\n",
              "      <td>0.111823</td>\n",
              "      <td>0.130108</td>\n",
              "      <td>0.148236</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.009042</td>\n",
              "      <td>-0.008103</td>\n",
              "      <td>-0.008920</td>\n",
              "      <td>-0.010897</td>\n",
              "      <td>-0.013278</td>\n",
              "      <td>-0.015248</td>\n",
              "      <td>-0.016029</td>\n",
              "      <td>-0.014967</td>\n",
              "      <td>-0.011609</td>\n",
              "      <td>-0.005777</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.041403</td>\n",
              "      <td>-0.040630</td>\n",
              "      <td>-0.041345</td>\n",
              "      <td>-0.043381</td>\n",
              "      <td>-0.046298</td>\n",
              "      <td>-0.049451</td>\n",
              "      <td>-0.052130</td>\n",
              "      <td>-0.053720</td>\n",
              "      <td>-0.053853</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.402142</td>\n",
              "      <td>0.302911</td>\n",
              "      <td>0.185292</td>\n",
              "      <td>0.066715</td>\n",
              "      <td>-0.037182</td>\n",
              "      <td>-0.115259</td>\n",
              "      <td>-0.162345</td>\n",
              "      <td>-0.179306</td>\n",
              "      <td>-0.171868</td>\n",
              "      <td>-0.148656</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.079294</td>\n",
              "      <td>-0.081055</td>\n",
              "      <td>-0.082744</td>\n",
              "      <td>-0.083994</td>\n",
              "      <td>-0.084521</td>\n",
              "      <td>-0.084185</td>\n",
              "      <td>-0.083029</td>\n",
              "      <td>-0.081281</td>\n",
              "      <td>-0.079306</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.007963</td>\n",
              "      <td>0.005535</td>\n",
              "      <td>0.017452</td>\n",
              "      <td>0.026380</td>\n",
              "      <td>0.031221</td>\n",
              "      <td>0.031279</td>\n",
              "      <td>0.026293</td>\n",
              "      <td>0.016416</td>\n",
              "      <td>0.002152</td>\n",
              "      <td>-0.015730</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008343</td>\n",
              "      <td>-0.091526</td>\n",
              "      <td>-0.188443</td>\n",
              "      <td>-0.269607</td>\n",
              "      <td>-0.325108</td>\n",
              "      <td>-0.349555</td>\n",
              "      <td>-0.342722</td>\n",
              "      <td>-0.309150</td>\n",
              "      <td>-0.256869</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23995</th>\n",
              "      <td>-0.109838</td>\n",
              "      <td>-0.112002</td>\n",
              "      <td>-0.113641</td>\n",
              "      <td>-0.114621</td>\n",
              "      <td>-0.114863</td>\n",
              "      <td>-0.114353</td>\n",
              "      <td>-0.113177</td>\n",
              "      <td>-0.111554</td>\n",
              "      <td>-0.109847</td>\n",
              "      <td>-0.108525</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108024</td>\n",
              "      <td>-0.108699</td>\n",
              "      <td>-0.108706</td>\n",
              "      <td>-0.108044</td>\n",
              "      <td>-0.106867</td>\n",
              "      <td>-0.105405</td>\n",
              "      <td>-0.103864</td>\n",
              "      <td>-0.102335</td>\n",
              "      <td>-0.100754</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23996</th>\n",
              "      <td>-0.040675</td>\n",
              "      <td>-0.054378</td>\n",
              "      <td>-0.068501</td>\n",
              "      <td>-0.081380</td>\n",
              "      <td>-0.091338</td>\n",
              "      <td>-0.096999</td>\n",
              "      <td>-0.097585</td>\n",
              "      <td>-0.093149</td>\n",
              "      <td>-0.084687</td>\n",
              "      <td>-0.074089</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001157</td>\n",
              "      <td>0.069442</td>\n",
              "      <td>0.143595</td>\n",
              "      <td>0.214329</td>\n",
              "      <td>0.271583</td>\n",
              "      <td>0.306394</td>\n",
              "      <td>0.312725</td>\n",
              "      <td>0.288831</td>\n",
              "      <td>0.237771</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23997</th>\n",
              "      <td>-0.019681</td>\n",
              "      <td>-0.041208</td>\n",
              "      <td>-0.061138</td>\n",
              "      <td>-0.078153</td>\n",
              "      <td>-0.091414</td>\n",
              "      <td>-0.100656</td>\n",
              "      <td>-0.106163</td>\n",
              "      <td>-0.108632</td>\n",
              "      <td>-0.108992</td>\n",
              "      <td>-0.108220</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.045588</td>\n",
              "      <td>-0.048637</td>\n",
              "      <td>-0.051353</td>\n",
              "      <td>-0.053427</td>\n",
              "      <td>-0.054666</td>\n",
              "      <td>-0.054988</td>\n",
              "      <td>-0.054436</td>\n",
              "      <td>-0.053175</td>\n",
              "      <td>-0.051491</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23998</th>\n",
              "      <td>0.003074</td>\n",
              "      <td>-0.012424</td>\n",
              "      <td>-0.024224</td>\n",
              "      <td>-0.032849</td>\n",
              "      <td>-0.039069</td>\n",
              "      <td>-0.043762</td>\n",
              "      <td>-0.047765</td>\n",
              "      <td>-0.051742</td>\n",
              "      <td>-0.056075</td>\n",
              "      <td>-0.060821</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.119279</td>\n",
              "      <td>-0.118505</td>\n",
              "      <td>-0.116912</td>\n",
              "      <td>-0.114928</td>\n",
              "      <td>-0.113008</td>\n",
              "      <td>-0.111522</td>\n",
              "      <td>-0.110699</td>\n",
              "      <td>-0.110611</td>\n",
              "      <td>-0.111212</td>\n",
              "      <td>98.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23999</th>\n",
              "      <td>-0.016414</td>\n",
              "      <td>-0.019264</td>\n",
              "      <td>-0.023513</td>\n",
              "      <td>-0.029241</td>\n",
              "      <td>-0.036146</td>\n",
              "      <td>-0.043594</td>\n",
              "      <td>-0.050755</td>\n",
              "      <td>-0.056785</td>\n",
              "      <td>-0.061007</td>\n",
              "      <td>-0.063049</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090826</td>\n",
              "      <td>-0.090601</td>\n",
              "      <td>-0.087764</td>\n",
              "      <td>-0.082253</td>\n",
              "      <td>-0.074366</td>\n",
              "      <td>-0.064672</td>\n",
              "      <td>-0.053875</td>\n",
              "      <td>-0.042684</td>\n",
              "      <td>-0.031708</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24000 rows × 257 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20518848-deb8-470c-bef6-2095db7f43fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20518848-deb8-470c-bef6-2095db7f43fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20518848-deb8-470c-bef6-2095db7f43fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리"
      ],
      "metadata": {
        "id": "JQBBj0ypT8T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(data_train[256])\n",
        "y_test = to_categorical(data_test[256])\n",
        "y_val = to_categorical(data_val[256])\n",
        "# y_train = to_categorical(arr)\n",
        "# y_test = to_categorical(arr_t)\n",
        "# y_val = to_categorical(arr_v)\n",
        "y_train[23999]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koQxh6-XfrG1",
        "outputId": "0fb3314a-5e9c-4994-b82c-df7d413d29a9"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.drop([256], axis=1, inplace=True)\n",
        "data_test.drop([256], axis=1, inplace=True)\n",
        "data_val.drop([256], axis=1, inplace=True)\n",
        "data_train"
      ],
      "metadata": {
        "id": "QJUFXwCRkGhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=data_train.values\n",
        "X_test=data_test.values\n",
        "X_val=data_val.values"
      ],
      "metadata": {
        "id": "EK7Q96RZtwZl"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwfh9AwhjkMM",
        "outputId": "f83a9203-9d02-4235-edc4-2215fa19047c"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24000, 256)\n",
            "(6000, 256)\n",
            "(6000, 256)\n",
            "(24000, 101)\n",
            "(6000, 101)\n",
            "(6000, 101)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = X_train.reshape(1, 256, 24000)\n",
        "# X_test = X_test.reshape(1, 256, 6000)\n",
        "# X_val = X_val.reshape(1, 256, 6000)\n",
        "X_train = X_train.reshape(24000, 256, 1)\n",
        "X_test = X_test.reshape(6000, 256, 1)\n",
        "X_val = X_val.reshape(6000, 256, 1)\n",
        "X_train.shape, X_test.shape, X_val.shape"
      ],
      "metadata": {
        "id": "50YyZlL9htW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcb5abd-bacf-442e-b985-a9b5c8d35015"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((24000, 256, 1), (6000, 256, 1), (6000, 256, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cnn-lstm 모델"
      ],
      "metadata": {
        "id": "EgfaelmnXe04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
        "                    padding='same', input_shape=(256, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # adding a pooling layer\n",
        "    model.add(MaxPooling1D(pool_size=(3), strides=2, padding='same'))\n",
        "    \n",
        "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
        "                    padding='same', input_shape=(256, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=(3), strides=2, padding='same'))\n",
        "    \n",
        "    model.add(Conv1D(filters=64, kernel_size=6, activation='relu', \n",
        "                    padding='same', input_shape=(256, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=(3), strides=2, padding='same'))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    #model.add(Dense(64, activation='relu'))\n",
        "    #model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(101, activation='softmax'))\n",
        "    \n",
        "    model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "DqFKm7PSQS3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "wum-FyK7QVUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2397946-5a7a-4f1f-e09b-f35229db7ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_17 (Conv1D)          (None, 256, 64)           448       \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 256, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_17 (MaxPoolin  (None, 128, 64)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_18 (Conv1D)          (None, 128, 64)           24640     \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 128, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_18 (MaxPoolin  (None, 64, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 64, 64)            24640     \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 64, 64)           256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_19 (MaxPoolin  (None, 32, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 100)               204900    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 255,396\n",
            "Trainable params: 255,012\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cnn-gru 모델"
      ],
      "metadata": {
        "id": "m-Hm3lsWXkbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, GRU, LSTM, MaxPooling1D, GlobalMaxPool1D, CuDNNGRU\n",
        "from keras.layers import Dropout, Dense, Activation, Flatten, Conv1D, SpatialDropout1D\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(filters=64, kernel_size=6, activation='relu', padding='same', input_shape=(256, 1)))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(MaxPooling1D(4))\n",
        "model.add(CuDNNGRU(64))\n",
        "\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(101, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXzfgBF75uk-",
        "outputId": "33f77877-e599-4ded-8400-373f5cec14bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_13 (Conv1D)          (None, 256, 64)           448       \n",
            "                                                                 \n",
            " spatial_dropout1d_4 (Spatia  (None, 256, 64)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " max_pooling1d_13 (MaxPoolin  (None, 64, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " cu_dnngru_4 (CuDNNGRU)      (None, 64)                24960     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 101)               6565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,973\n",
            "Trainable params: 31,973\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gru모델"
      ],
      "metadata": {
        "id": "Na73oRb9Xq69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(GRU(units=100, return_sequences=True, input_shape=(256,1))) #shape[1]=열\n",
        "model.add(GRU(units=50, return_sequences=True))\n",
        "model.add(GRU(units=50, return_sequences=True))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(101, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWyVmfGGXar5",
        "outputId": "cef9ae44-7e51-4157-b336-8c77bebfb08b"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_3 (GRU)                 (None, 256, 100)          30900     \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (None, 256, 50)           22800     \n",
            "                                                                 \n",
            " gru_5 (GRU)                 (None, 256, 50)           15300     \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 12800)             0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 12800)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 101)               1292901   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,361,901\n",
            "Trainable params: 1,361,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "DBnTIBCDGX94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(units=100, return_sequences=True, input_shape=(256,1))) #shape[1]=열\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(101, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jbh5mP0GWh5",
        "outputId": "8055881e-f18e-4941-e7d3-1d853b39d2e3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 256, 100)          40800     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 256, 50)           30200     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 256, 50)           20200     \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 12800)             0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 12800)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 101)               1292901   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,384,101\n",
            "Trainable params: 1,384,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN모델"
      ],
      "metadata": {
        "id": "mLO6GGJ5Nn9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, GRU, LSTM, SimpleRNN, MaxPooling1D, GlobalMaxPool1D, CuDNNGRU\n",
        "from keras.layers import Dropout, Dense, Activation, Flatten, Conv1D, SpatialDropout1D\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(units=100, return_sequences=True, input_shape=(256,1))) #shape[1]=열\n",
        "model.add(SimpleRNN(units=50, return_sequences=True))\n",
        "model.add(SimpleRNN(units=50, return_sequences=True))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(101, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHOArXJVNnd0",
        "outputId": "4f56aa04-4c34-4860-fc44-299596d4f96f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_12 (SimpleRNN)   (None, 256, 100)          10200     \n",
            "                                                                 \n",
            " simple_rnn_13 (SimpleRNN)   (None, 256, 50)           7550      \n",
            "                                                                 \n",
            " simple_rnn_14 (SimpleRNN)   (None, 256, 50)           5050      \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 12800)             0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 12800)             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 101)               1292901   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,315,701\n",
            "Trainable params: 1,315,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델학습/평가"
      ],
      "metadata": {
        "id": "bWixFuhvKbcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, batch_size = 512, epochs = 400, verbose = 1, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "t-UtiKqRQYVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3203b3a8-40d9-4bc1-c0dc-9f112ed7b3ea"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "47/47 [==============================] - 9s 93ms/step - loss: 0.0098 - accuracy: 0.0105 - val_loss: 0.0098 - val_accuracy: 0.0102\n",
            "Epoch 2/400\n",
            "47/47 [==============================] - 3s 74ms/step - loss: 0.0098 - accuracy: 0.0106 - val_loss: 0.0098 - val_accuracy: 0.0070\n",
            "Epoch 3/400\n",
            "47/47 [==============================] - 3s 74ms/step - loss: 0.0098 - accuracy: 0.0113 - val_loss: 0.0098 - val_accuracy: 0.0087\n",
            "Epoch 4/400\n",
            "47/47 [==============================] - 3s 74ms/step - loss: 0.0098 - accuracy: 0.0123 - val_loss: 0.0098 - val_accuracy: 0.0112\n",
            "Epoch 5/400\n",
            "47/47 [==============================] - 3s 75ms/step - loss: 0.0098 - accuracy: 0.0160 - val_loss: 0.0098 - val_accuracy: 0.0118\n",
            "Epoch 6/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0098 - accuracy: 0.0202 - val_loss: 0.0098 - val_accuracy: 0.0250\n",
            "Epoch 7/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0098 - accuracy: 0.0343 - val_loss: 0.0098 - val_accuracy: 0.0315\n",
            "Epoch 8/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 0.0097 - accuracy: 0.0506 - val_loss: 0.0098 - val_accuracy: 0.0410\n",
            "Epoch 9/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 0.0097 - accuracy: 0.0647 - val_loss: 0.0097 - val_accuracy: 0.0525\n",
            "Epoch 10/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 0.0097 - accuracy: 0.0777 - val_loss: 0.0097 - val_accuracy: 0.0610\n",
            "Epoch 11/400\n",
            "47/47 [==============================] - 4s 77ms/step - loss: 0.0096 - accuracy: 0.0932 - val_loss: 0.0097 - val_accuracy: 0.0697\n",
            "Epoch 12/400\n",
            "47/47 [==============================] - 4s 77ms/step - loss: 0.0095 - accuracy: 0.1045 - val_loss: 0.0097 - val_accuracy: 0.0880\n",
            "Epoch 13/400\n",
            "47/47 [==============================] - 4s 77ms/step - loss: 0.0094 - accuracy: 0.1277 - val_loss: 0.0096 - val_accuracy: 0.1038\n",
            "Epoch 14/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 0.0093 - accuracy: 0.1513 - val_loss: 0.0095 - val_accuracy: 0.1185\n",
            "Epoch 15/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 0.0092 - accuracy: 0.1717 - val_loss: 0.0095 - val_accuracy: 0.1320\n",
            "Epoch 16/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0091 - accuracy: 0.1935 - val_loss: 0.0093 - val_accuracy: 0.1502\n",
            "Epoch 17/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0089 - accuracy: 0.2163 - val_loss: 0.0093 - val_accuracy: 0.1723\n",
            "Epoch 18/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0087 - accuracy: 0.2407 - val_loss: 0.0092 - val_accuracy: 0.1820\n",
            "Epoch 19/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0085 - accuracy: 0.2677 - val_loss: 0.0090 - val_accuracy: 0.2070\n",
            "Epoch 20/400\n",
            "47/47 [==============================] - 3s 75ms/step - loss: 0.0082 - accuracy: 0.3047 - val_loss: 0.0088 - val_accuracy: 0.2460\n",
            "Epoch 21/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0080 - accuracy: 0.3371 - val_loss: 0.0086 - val_accuracy: 0.2705\n",
            "Epoch 22/400\n",
            "47/47 [==============================] - 3s 74ms/step - loss: 0.0076 - accuracy: 0.3764 - val_loss: 0.0084 - val_accuracy: 0.3028\n",
            "Epoch 23/400\n",
            "47/47 [==============================] - 3s 75ms/step - loss: 0.0073 - accuracy: 0.4117 - val_loss: 0.0081 - val_accuracy: 0.3358\n",
            "Epoch 24/400\n",
            "47/47 [==============================] - 3s 74ms/step - loss: 0.0069 - accuracy: 0.4482 - val_loss: 0.0079 - val_accuracy: 0.3637\n",
            "Epoch 25/400\n",
            "47/47 [==============================] - 3s 74ms/step - loss: 0.0066 - accuracy: 0.4827 - val_loss: 0.0076 - val_accuracy: 0.3858\n",
            "Epoch 26/400\n",
            "47/47 [==============================] - 3s 74ms/step - loss: 0.0063 - accuracy: 0.5088 - val_loss: 0.0073 - val_accuracy: 0.4097\n",
            "Epoch 27/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0059 - accuracy: 0.5446 - val_loss: 0.0072 - val_accuracy: 0.4355\n",
            "Epoch 28/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0057 - accuracy: 0.5677 - val_loss: 0.0068 - val_accuracy: 0.4740\n",
            "Epoch 29/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0053 - accuracy: 0.5976 - val_loss: 0.0066 - val_accuracy: 0.4995\n",
            "Epoch 30/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0051 - accuracy: 0.6238 - val_loss: 0.0063 - val_accuracy: 0.5228\n",
            "Epoch 31/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0047 - accuracy: 0.6514 - val_loss: 0.0060 - val_accuracy: 0.5432\n",
            "Epoch 32/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 0.0045 - accuracy: 0.6724 - val_loss: 0.0059 - val_accuracy: 0.5625\n",
            "Epoch 33/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0042 - accuracy: 0.6898 - val_loss: 0.0057 - val_accuracy: 0.5777\n",
            "Epoch 34/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0039 - accuracy: 0.7153 - val_loss: 0.0054 - val_accuracy: 0.5967\n",
            "Epoch 35/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0037 - accuracy: 0.7369 - val_loss: 0.0052 - val_accuracy: 0.6205\n",
            "Epoch 36/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0035 - accuracy: 0.7489 - val_loss: 0.0052 - val_accuracy: 0.6302\n",
            "Epoch 37/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 0.0033 - accuracy: 0.7625 - val_loss: 0.0049 - val_accuracy: 0.6473\n",
            "Epoch 38/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0031 - accuracy: 0.7788 - val_loss: 0.0047 - val_accuracy: 0.6660\n",
            "Epoch 39/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0029 - accuracy: 0.7946 - val_loss: 0.0046 - val_accuracy: 0.6707\n",
            "Epoch 40/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 0.0027 - accuracy: 0.8067 - val_loss: 0.0046 - val_accuracy: 0.6820\n",
            "Epoch 41/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0026 - accuracy: 0.8205 - val_loss: 0.0044 - val_accuracy: 0.6945\n",
            "Epoch 42/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0024 - accuracy: 0.8320 - val_loss: 0.0041 - val_accuracy: 0.7093\n",
            "Epoch 43/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0023 - accuracy: 0.8402 - val_loss: 0.0041 - val_accuracy: 0.7150\n",
            "Epoch 44/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0022 - accuracy: 0.8499 - val_loss: 0.0039 - val_accuracy: 0.7298\n",
            "Epoch 45/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0020 - accuracy: 0.8596 - val_loss: 0.0038 - val_accuracy: 0.7322\n",
            "Epoch 46/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0019 - accuracy: 0.8696 - val_loss: 0.0037 - val_accuracy: 0.7442\n",
            "Epoch 47/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0018 - accuracy: 0.8750 - val_loss: 0.0037 - val_accuracy: 0.7478\n",
            "Epoch 48/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0017 - accuracy: 0.8814 - val_loss: 0.0036 - val_accuracy: 0.7592\n",
            "Epoch 49/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0016 - accuracy: 0.8917 - val_loss: 0.0035 - val_accuracy: 0.7610\n",
            "Epoch 50/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0015 - accuracy: 0.8966 - val_loss: 0.0033 - val_accuracy: 0.7743\n",
            "Epoch 51/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0014 - accuracy: 0.9060 - val_loss: 0.0032 - val_accuracy: 0.7800\n",
            "Epoch 52/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0013 - accuracy: 0.9110 - val_loss: 0.0031 - val_accuracy: 0.7883\n",
            "Epoch 53/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0013 - accuracy: 0.9120 - val_loss: 0.0032 - val_accuracy: 0.7803\n",
            "Epoch 54/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0012 - accuracy: 0.9190 - val_loss: 0.0031 - val_accuracy: 0.7912\n",
            "Epoch 55/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0011 - accuracy: 0.9220 - val_loss: 0.0030 - val_accuracy: 0.7998\n",
            "Epoch 56/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0011 - accuracy: 0.9227 - val_loss: 0.0030 - val_accuracy: 0.8012\n",
            "Epoch 57/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0011 - accuracy: 0.9260 - val_loss: 0.0030 - val_accuracy: 0.7962\n",
            "Epoch 58/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 0.0010 - accuracy: 0.9285 - val_loss: 0.0029 - val_accuracy: 0.8022\n",
            "Epoch 59/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 9.6881e-04 - accuracy: 0.9339 - val_loss: 0.0029 - val_accuracy: 0.8083\n",
            "Epoch 60/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 9.3942e-04 - accuracy: 0.9357 - val_loss: 0.0029 - val_accuracy: 0.8063\n",
            "Epoch 61/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 9.0831e-04 - accuracy: 0.9374 - val_loss: 0.0029 - val_accuracy: 0.8108\n",
            "Epoch 62/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 8.5150e-04 - accuracy: 0.9421 - val_loss: 0.0027 - val_accuracy: 0.8202\n",
            "Epoch 63/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 8.2099e-04 - accuracy: 0.9428 - val_loss: 0.0027 - val_accuracy: 0.8150\n",
            "Epoch 64/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 8.3676e-04 - accuracy: 0.9425 - val_loss: 0.0028 - val_accuracy: 0.8133\n",
            "Epoch 65/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 8.0253e-04 - accuracy: 0.9441 - val_loss: 0.0027 - val_accuracy: 0.8205\n",
            "Epoch 66/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 7.9533e-04 - accuracy: 0.9454 - val_loss: 0.0027 - val_accuracy: 0.8207\n",
            "Epoch 67/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 7.7226e-04 - accuracy: 0.9472 - val_loss: 0.0026 - val_accuracy: 0.8242\n",
            "Epoch 68/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 7.4696e-04 - accuracy: 0.9482 - val_loss: 0.0026 - val_accuracy: 0.8283\n",
            "Epoch 69/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 7.1629e-04 - accuracy: 0.9503 - val_loss: 0.0026 - val_accuracy: 0.8268\n",
            "Epoch 70/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 6.8289e-04 - accuracy: 0.9532 - val_loss: 0.0027 - val_accuracy: 0.8203\n",
            "Epoch 71/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 6.8760e-04 - accuracy: 0.9531 - val_loss: 0.0026 - val_accuracy: 0.8252\n",
            "Epoch 72/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 6.9446e-04 - accuracy: 0.9523 - val_loss: 0.0026 - val_accuracy: 0.8290\n",
            "Epoch 73/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 6.8372e-04 - accuracy: 0.9544 - val_loss: 0.0027 - val_accuracy: 0.8258\n",
            "Epoch 74/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 6.2616e-04 - accuracy: 0.9574 - val_loss: 0.0026 - val_accuracy: 0.8283\n",
            "Epoch 75/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 6.1001e-04 - accuracy: 0.9588 - val_loss: 0.0026 - val_accuracy: 0.8290\n",
            "Epoch 76/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 6.4270e-04 - accuracy: 0.9563 - val_loss: 0.0026 - val_accuracy: 0.8253\n",
            "Epoch 77/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 6.3488e-04 - accuracy: 0.9569 - val_loss: 0.0025 - val_accuracy: 0.8330\n",
            "Epoch 78/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 6.2499e-04 - accuracy: 0.9577 - val_loss: 0.0025 - val_accuracy: 0.8358\n",
            "Epoch 79/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 6.4900e-04 - accuracy: 0.9568 - val_loss: 0.0025 - val_accuracy: 0.8335\n",
            "Epoch 80/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 6.0066e-04 - accuracy: 0.9593 - val_loss: 0.0025 - val_accuracy: 0.8320\n",
            "Epoch 81/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.7418e-04 - accuracy: 0.9612 - val_loss: 0.0025 - val_accuracy: 0.8373\n",
            "Epoch 82/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.6036e-04 - accuracy: 0.9618 - val_loss: 0.0026 - val_accuracy: 0.8318\n",
            "Epoch 83/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.7587e-04 - accuracy: 0.9611 - val_loss: 0.0025 - val_accuracy: 0.8417\n",
            "Epoch 84/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 5.5624e-04 - accuracy: 0.9622 - val_loss: 0.0024 - val_accuracy: 0.8430\n",
            "Epoch 85/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.2904e-04 - accuracy: 0.9637 - val_loss: 0.0024 - val_accuracy: 0.8422\n",
            "Epoch 86/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.1390e-04 - accuracy: 0.9640 - val_loss: 0.0024 - val_accuracy: 0.8433\n",
            "Epoch 87/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.2270e-04 - accuracy: 0.9647 - val_loss: 0.0024 - val_accuracy: 0.8420\n",
            "Epoch 88/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.0874e-04 - accuracy: 0.9655 - val_loss: 0.0025 - val_accuracy: 0.8400\n",
            "Epoch 89/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 5.0436e-04 - accuracy: 0.9657 - val_loss: 0.0023 - val_accuracy: 0.8475\n",
            "Epoch 90/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 4.9546e-04 - accuracy: 0.9660 - val_loss: 0.0024 - val_accuracy: 0.8443\n",
            "Epoch 91/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.9198e-04 - accuracy: 0.9665 - val_loss: 0.0024 - val_accuracy: 0.8438\n",
            "Epoch 92/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.9900e-04 - accuracy: 0.9655 - val_loss: 0.0024 - val_accuracy: 0.8418\n",
            "Epoch 93/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.9806e-04 - accuracy: 0.9655 - val_loss: 0.0023 - val_accuracy: 0.8473\n",
            "Epoch 94/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.8865e-04 - accuracy: 0.9665 - val_loss: 0.0023 - val_accuracy: 0.8468\n",
            "Epoch 95/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.7838e-04 - accuracy: 0.9668 - val_loss: 0.0023 - val_accuracy: 0.8530\n",
            "Epoch 96/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.7222e-04 - accuracy: 0.9675 - val_loss: 0.0024 - val_accuracy: 0.8458\n",
            "Epoch 97/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 4.6765e-04 - accuracy: 0.9677 - val_loss: 0.0023 - val_accuracy: 0.8478\n",
            "Epoch 98/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.4914e-04 - accuracy: 0.9690 - val_loss: 0.0023 - val_accuracy: 0.8455\n",
            "Epoch 99/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.4749e-04 - accuracy: 0.9695 - val_loss: 0.0023 - val_accuracy: 0.8522\n",
            "Epoch 100/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.7371e-04 - accuracy: 0.9684 - val_loss: 0.0024 - val_accuracy: 0.8442\n",
            "Epoch 101/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.7864e-04 - accuracy: 0.9677 - val_loss: 0.0023 - val_accuracy: 0.8533\n",
            "Epoch 102/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.5389e-04 - accuracy: 0.9695 - val_loss: 0.0023 - val_accuracy: 0.8533\n",
            "Epoch 103/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.5287e-04 - accuracy: 0.9691 - val_loss: 0.0022 - val_accuracy: 0.8545\n",
            "Epoch 104/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.4641e-04 - accuracy: 0.9700 - val_loss: 0.0024 - val_accuracy: 0.8473\n",
            "Epoch 105/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.2303e-04 - accuracy: 0.9652 - val_loss: 0.0024 - val_accuracy: 0.8467\n",
            "Epoch 106/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.5155e-04 - accuracy: 0.9632 - val_loss: 0.0025 - val_accuracy: 0.8355\n",
            "Epoch 107/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.5375e-04 - accuracy: 0.9632 - val_loss: 0.0027 - val_accuracy: 0.8295\n",
            "Epoch 108/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.8769e-04 - accuracy: 0.9611 - val_loss: 0.0025 - val_accuracy: 0.8420\n",
            "Epoch 109/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.3968e-04 - accuracy: 0.9639 - val_loss: 0.0025 - val_accuracy: 0.8437\n",
            "Epoch 110/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 5.1806e-04 - accuracy: 0.9654 - val_loss: 0.0024 - val_accuracy: 0.8455\n",
            "Epoch 111/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 4.5340e-04 - accuracy: 0.9698 - val_loss: 0.0024 - val_accuracy: 0.8460\n",
            "Epoch 112/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 4.8411e-04 - accuracy: 0.9682 - val_loss: 0.0024 - val_accuracy: 0.8450\n",
            "Epoch 113/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.6626e-04 - accuracy: 0.9694 - val_loss: 0.0023 - val_accuracy: 0.8503\n",
            "Epoch 114/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.2639e-04 - accuracy: 0.9718 - val_loss: 0.0023 - val_accuracy: 0.8510\n",
            "Epoch 115/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.4356e-04 - accuracy: 0.9707 - val_loss: 0.0023 - val_accuracy: 0.8562\n",
            "Epoch 116/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.9082e-04 - accuracy: 0.9742 - val_loss: 0.0022 - val_accuracy: 0.8595\n",
            "Epoch 117/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.8498e-04 - accuracy: 0.9745 - val_loss: 0.0021 - val_accuracy: 0.8628\n",
            "Epoch 118/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.6881e-04 - accuracy: 0.9755 - val_loss: 0.0022 - val_accuracy: 0.8587\n",
            "Epoch 119/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.8014e-04 - accuracy: 0.9746 - val_loss: 0.0021 - val_accuracy: 0.8618\n",
            "Epoch 120/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.8002e-04 - accuracy: 0.9748 - val_loss: 0.0022 - val_accuracy: 0.8610\n",
            "Epoch 121/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.7863e-04 - accuracy: 0.9747 - val_loss: 0.0022 - val_accuracy: 0.8615\n",
            "Epoch 122/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.7369e-04 - accuracy: 0.9750 - val_loss: 0.0023 - val_accuracy: 0.8523\n",
            "Epoch 123/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.9468e-04 - accuracy: 0.9741 - val_loss: 0.0024 - val_accuracy: 0.8522\n",
            "Epoch 124/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.7793e-04 - accuracy: 0.9747 - val_loss: 0.0022 - val_accuracy: 0.8615\n",
            "Epoch 125/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.6950e-04 - accuracy: 0.9755 - val_loss: 0.0023 - val_accuracy: 0.8560\n",
            "Epoch 126/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.5666e-04 - accuracy: 0.9763 - val_loss: 0.0021 - val_accuracy: 0.8645\n",
            "Epoch 127/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.5095e-04 - accuracy: 0.9768 - val_loss: 0.0020 - val_accuracy: 0.8715\n",
            "Epoch 128/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.4552e-04 - accuracy: 0.9771 - val_loss: 0.0022 - val_accuracy: 0.8588\n",
            "Epoch 129/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.4953e-04 - accuracy: 0.9767 - val_loss: 0.0021 - val_accuracy: 0.8668\n",
            "Epoch 130/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.6987e-04 - accuracy: 0.9751 - val_loss: 0.0021 - val_accuracy: 0.8667\n",
            "Epoch 131/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.8384e-04 - accuracy: 0.9747 - val_loss: 0.0023 - val_accuracy: 0.8600\n",
            "Epoch 132/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.1790e-04 - accuracy: 0.9725 - val_loss: 0.0023 - val_accuracy: 0.8587\n",
            "Epoch 133/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.8874e-04 - accuracy: 0.9746 - val_loss: 0.0023 - val_accuracy: 0.8562\n",
            "Epoch 134/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.4636e-04 - accuracy: 0.9707 - val_loss: 0.0024 - val_accuracy: 0.8512\n",
            "Epoch 135/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.8854e-04 - accuracy: 0.9748 - val_loss: 0.0022 - val_accuracy: 0.8607\n",
            "Epoch 136/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.7279e-04 - accuracy: 0.9757 - val_loss: 0.0021 - val_accuracy: 0.8633\n",
            "Epoch 137/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.6374e-04 - accuracy: 0.9761 - val_loss: 0.0023 - val_accuracy: 0.8552\n",
            "Epoch 138/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.7181e-04 - accuracy: 0.9758 - val_loss: 0.0022 - val_accuracy: 0.8567\n",
            "Epoch 139/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.8358e-04 - accuracy: 0.9755 - val_loss: 0.0021 - val_accuracy: 0.8658\n",
            "Epoch 140/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.2125e-04 - accuracy: 0.9730 - val_loss: 0.0023 - val_accuracy: 0.8545\n",
            "Epoch 141/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.7925e-04 - accuracy: 0.9755 - val_loss: 0.0022 - val_accuracy: 0.8637\n",
            "Epoch 142/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.6515e-04 - accuracy: 0.9705 - val_loss: 0.0023 - val_accuracy: 0.8575\n",
            "Epoch 143/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.9626e-04 - accuracy: 0.9747 - val_loss: 0.0021 - val_accuracy: 0.8663\n",
            "Epoch 144/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.2419e-04 - accuracy: 0.9793 - val_loss: 0.0021 - val_accuracy: 0.8668\n",
            "Epoch 145/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.1911e-04 - accuracy: 0.9797 - val_loss: 0.0020 - val_accuracy: 0.8717\n",
            "Epoch 146/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.9210e-04 - accuracy: 0.9746 - val_loss: 0.0022 - val_accuracy: 0.8605\n",
            "Epoch 147/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.3989e-04 - accuracy: 0.9782 - val_loss: 0.0021 - val_accuracy: 0.8693\n",
            "Epoch 148/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.2258e-04 - accuracy: 0.9795 - val_loss: 0.0022 - val_accuracy: 0.8628\n",
            "Epoch 149/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.3561e-04 - accuracy: 0.9785 - val_loss: 0.0021 - val_accuracy: 0.8712\n",
            "Epoch 150/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.1514e-04 - accuracy: 0.9799 - val_loss: 0.0022 - val_accuracy: 0.8635\n",
            "Epoch 151/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.2100e-04 - accuracy: 0.9795 - val_loss: 0.0020 - val_accuracy: 0.8750\n",
            "Epoch 152/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.3730e-04 - accuracy: 0.9788 - val_loss: 0.0021 - val_accuracy: 0.8717\n",
            "Epoch 153/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.3111e-04 - accuracy: 0.9790 - val_loss: 0.0022 - val_accuracy: 0.8615\n",
            "Epoch 154/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.3635e-04 - accuracy: 0.9788 - val_loss: 0.0021 - val_accuracy: 0.8718\n",
            "Epoch 155/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.0386e-04 - accuracy: 0.9805 - val_loss: 0.0020 - val_accuracy: 0.8772\n",
            "Epoch 156/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.9316e-04 - accuracy: 0.9812 - val_loss: 0.0021 - val_accuracy: 0.8707\n",
            "Epoch 157/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.9749e-04 - accuracy: 0.9812 - val_loss: 0.0021 - val_accuracy: 0.8667\n",
            "Epoch 158/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.2545e-04 - accuracy: 0.9792 - val_loss: 0.0020 - val_accuracy: 0.8747\n",
            "Epoch 159/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.1019e-04 - accuracy: 0.9801 - val_loss: 0.0021 - val_accuracy: 0.8688\n",
            "Epoch 160/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.0625e-04 - accuracy: 0.9805 - val_loss: 0.0020 - val_accuracy: 0.8742\n",
            "Epoch 161/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.0566e-04 - accuracy: 0.9807 - val_loss: 0.0020 - val_accuracy: 0.8762\n",
            "Epoch 162/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.1432e-04 - accuracy: 0.9798 - val_loss: 0.0021 - val_accuracy: 0.8727\n",
            "Epoch 163/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.1960e-04 - accuracy: 0.9794 - val_loss: 0.0020 - val_accuracy: 0.8742\n",
            "Epoch 164/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.2803e-04 - accuracy: 0.9792 - val_loss: 0.0021 - val_accuracy: 0.8707\n",
            "Epoch 165/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 3.3621e-04 - accuracy: 0.9786 - val_loss: 0.0021 - val_accuracy: 0.8697\n",
            "Epoch 166/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.2026e-04 - accuracy: 0.9797 - val_loss: 0.0021 - val_accuracy: 0.8703\n",
            "Epoch 167/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.3225e-04 - accuracy: 0.9790 - val_loss: 0.0021 - val_accuracy: 0.8702\n",
            "Epoch 168/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 4.1505e-04 - accuracy: 0.9731 - val_loss: 0.0023 - val_accuracy: 0.8622\n",
            "Epoch 169/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.7552e-04 - accuracy: 0.9761 - val_loss: 0.0022 - val_accuracy: 0.8627\n",
            "Epoch 170/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.6429e-04 - accuracy: 0.9771 - val_loss: 0.0022 - val_accuracy: 0.8640\n",
            "Epoch 171/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.5210e-04 - accuracy: 0.9780 - val_loss: 0.0021 - val_accuracy: 0.8680\n",
            "Epoch 172/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.4236e-04 - accuracy: 0.9784 - val_loss: 0.0020 - val_accuracy: 0.8805\n",
            "Epoch 173/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.0891e-04 - accuracy: 0.9809 - val_loss: 0.0020 - val_accuracy: 0.8805\n",
            "Epoch 174/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.0036e-04 - accuracy: 0.9812 - val_loss: 0.0019 - val_accuracy: 0.8833\n",
            "Epoch 175/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.9164e-04 - accuracy: 0.9818 - val_loss: 0.0020 - val_accuracy: 0.8797\n",
            "Epoch 176/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.1667e-04 - accuracy: 0.9805 - val_loss: 0.0021 - val_accuracy: 0.8707\n",
            "Epoch 177/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.3825e-04 - accuracy: 0.9787 - val_loss: 0.0022 - val_accuracy: 0.8643\n",
            "Epoch 178/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.4657e-04 - accuracy: 0.9784 - val_loss: 0.0023 - val_accuracy: 0.8570\n",
            "Epoch 179/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.7216e-04 - accuracy: 0.9764 - val_loss: 0.0021 - val_accuracy: 0.8715\n",
            "Epoch 180/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.3559e-04 - accuracy: 0.9793 - val_loss: 0.0020 - val_accuracy: 0.8753\n",
            "Epoch 181/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.1846e-04 - accuracy: 0.9799 - val_loss: 0.0020 - val_accuracy: 0.8775\n",
            "Epoch 182/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.0801e-04 - accuracy: 0.9808 - val_loss: 0.0020 - val_accuracy: 0.8735\n",
            "Epoch 183/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.1595e-04 - accuracy: 0.9803 - val_loss: 0.0019 - val_accuracy: 0.8815\n",
            "Epoch 184/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.9074e-04 - accuracy: 0.9817 - val_loss: 0.0018 - val_accuracy: 0.8843\n",
            "Epoch 185/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.8751e-04 - accuracy: 0.9821 - val_loss: 0.0020 - val_accuracy: 0.8788\n",
            "Epoch 186/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.9599e-04 - accuracy: 0.9816 - val_loss: 0.0018 - val_accuracy: 0.8887\n",
            "Epoch 187/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.8851e-04 - accuracy: 0.9822 - val_loss: 0.0019 - val_accuracy: 0.8828\n",
            "Epoch 188/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.8585e-04 - accuracy: 0.9822 - val_loss: 0.0020 - val_accuracy: 0.8797\n",
            "Epoch 189/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.0198e-04 - accuracy: 0.9808 - val_loss: 0.0019 - val_accuracy: 0.8822\n",
            "Epoch 190/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.9819e-04 - accuracy: 0.9812 - val_loss: 0.0020 - val_accuracy: 0.8762\n",
            "Epoch 191/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.1716e-04 - accuracy: 0.9804 - val_loss: 0.0021 - val_accuracy: 0.8752\n",
            "Epoch 192/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.4360e-04 - accuracy: 0.9780 - val_loss: 0.0021 - val_accuracy: 0.8720\n",
            "Epoch 193/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.4437e-04 - accuracy: 0.9786 - val_loss: 0.0019 - val_accuracy: 0.8833\n",
            "Epoch 194/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.1074e-04 - accuracy: 0.9807 - val_loss: 0.0020 - val_accuracy: 0.8803\n",
            "Epoch 195/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.3601e-04 - accuracy: 0.9790 - val_loss: 0.0021 - val_accuracy: 0.8730\n",
            "Epoch 196/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.3767e-04 - accuracy: 0.9790 - val_loss: 0.0020 - val_accuracy: 0.8750\n",
            "Epoch 197/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.6497e-04 - accuracy: 0.9775 - val_loss: 0.0022 - val_accuracy: 0.8652\n",
            "Epoch 198/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.2188e-04 - accuracy: 0.9798 - val_loss: 0.0020 - val_accuracy: 0.8757\n",
            "Epoch 199/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.3076e-04 - accuracy: 0.9792 - val_loss: 0.0022 - val_accuracy: 0.8675\n",
            "Epoch 200/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.2892e-04 - accuracy: 0.9797 - val_loss: 0.0020 - val_accuracy: 0.8790\n",
            "Epoch 201/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.2112e-04 - accuracy: 0.9802 - val_loss: 0.0019 - val_accuracy: 0.8857\n",
            "Epoch 202/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.9053e-04 - accuracy: 0.9819 - val_loss: 0.0019 - val_accuracy: 0.8827\n",
            "Epoch 203/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.8886e-04 - accuracy: 0.9821 - val_loss: 0.0020 - val_accuracy: 0.8828\n",
            "Epoch 204/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7917e-04 - accuracy: 0.9829 - val_loss: 0.0020 - val_accuracy: 0.8790\n",
            "Epoch 205/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.1057e-04 - accuracy: 0.9808 - val_loss: 0.0019 - val_accuracy: 0.8802\n",
            "Epoch 206/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.0590e-04 - accuracy: 0.9812 - val_loss: 0.0021 - val_accuracy: 0.8710\n",
            "Epoch 207/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.8682e-04 - accuracy: 0.9827 - val_loss: 0.0019 - val_accuracy: 0.8867\n",
            "Epoch 208/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7165e-04 - accuracy: 0.9831 - val_loss: 0.0020 - val_accuracy: 0.8810\n",
            "Epoch 209/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.9395e-04 - accuracy: 0.9820 - val_loss: 0.0020 - val_accuracy: 0.8818\n",
            "Epoch 210/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.9547e-04 - accuracy: 0.9816 - val_loss: 0.0020 - val_accuracy: 0.8808\n",
            "Epoch 211/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.0822e-04 - accuracy: 0.9812 - val_loss: 0.0019 - val_accuracy: 0.8860\n",
            "Epoch 212/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7522e-04 - accuracy: 0.9831 - val_loss: 0.0019 - val_accuracy: 0.8860\n",
            "Epoch 213/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.6760e-04 - accuracy: 0.9840 - val_loss: 0.0018 - val_accuracy: 0.8910\n",
            "Epoch 214/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5801e-04 - accuracy: 0.9842 - val_loss: 0.0018 - val_accuracy: 0.8880\n",
            "Epoch 215/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7481e-04 - accuracy: 0.9832 - val_loss: 0.0022 - val_accuracy: 0.8700\n",
            "Epoch 216/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.0195e-04 - accuracy: 0.9818 - val_loss: 0.0019 - val_accuracy: 0.8857\n",
            "Epoch 217/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7171e-04 - accuracy: 0.9835 - val_loss: 0.0019 - val_accuracy: 0.8872\n",
            "Epoch 218/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7235e-04 - accuracy: 0.9835 - val_loss: 0.0019 - val_accuracy: 0.8858\n",
            "Epoch 219/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7093e-04 - accuracy: 0.9837 - val_loss: 0.0018 - val_accuracy: 0.8913\n",
            "Epoch 220/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5846e-04 - accuracy: 0.9845 - val_loss: 0.0019 - val_accuracy: 0.8865\n",
            "Epoch 221/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.0775e-04 - accuracy: 0.9813 - val_loss: 0.0020 - val_accuracy: 0.8818\n",
            "Epoch 222/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.6400e-04 - accuracy: 0.9776 - val_loss: 0.0019 - val_accuracy: 0.8843\n",
            "Epoch 223/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.6678e-04 - accuracy: 0.9772 - val_loss: 0.0021 - val_accuracy: 0.8730\n",
            "Epoch 224/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.4781e-04 - accuracy: 0.9782 - val_loss: 0.0021 - val_accuracy: 0.8768\n",
            "Epoch 225/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.2593e-04 - accuracy: 0.9802 - val_loss: 0.0020 - val_accuracy: 0.8837\n",
            "Epoch 226/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7466e-04 - accuracy: 0.9833 - val_loss: 0.0019 - val_accuracy: 0.8892\n",
            "Epoch 227/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7941e-04 - accuracy: 0.9829 - val_loss: 0.0019 - val_accuracy: 0.8862\n",
            "Epoch 228/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.6173e-04 - accuracy: 0.9840 - val_loss: 0.0019 - val_accuracy: 0.8842\n",
            "Epoch 229/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7217e-04 - accuracy: 0.9834 - val_loss: 0.0018 - val_accuracy: 0.8897\n",
            "Epoch 230/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5239e-04 - accuracy: 0.9846 - val_loss: 0.0019 - val_accuracy: 0.8867\n",
            "Epoch 231/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4860e-04 - accuracy: 0.9851 - val_loss: 0.0018 - val_accuracy: 0.8957\n",
            "Epoch 232/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5587e-04 - accuracy: 0.9846 - val_loss: 0.0018 - val_accuracy: 0.8902\n",
            "Epoch 233/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5071e-04 - accuracy: 0.9847 - val_loss: 0.0019 - val_accuracy: 0.8872\n",
            "Epoch 234/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5725e-04 - accuracy: 0.9843 - val_loss: 0.0018 - val_accuracy: 0.8925\n",
            "Epoch 235/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.6037e-04 - accuracy: 0.9844 - val_loss: 0.0019 - val_accuracy: 0.8870\n",
            "Epoch 236/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5326e-04 - accuracy: 0.9846 - val_loss: 0.0017 - val_accuracy: 0.8953\n",
            "Epoch 237/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5614e-04 - accuracy: 0.9848 - val_loss: 0.0019 - val_accuracy: 0.8868\n",
            "Epoch 238/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.5319e-04 - accuracy: 0.9850 - val_loss: 0.0018 - val_accuracy: 0.8957\n",
            "Epoch 239/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4383e-04 - accuracy: 0.9854 - val_loss: 0.0018 - val_accuracy: 0.8940\n",
            "Epoch 240/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.6929e-04 - accuracy: 0.9838 - val_loss: 0.0019 - val_accuracy: 0.8858\n",
            "Epoch 241/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5439e-04 - accuracy: 0.9844 - val_loss: 0.0018 - val_accuracy: 0.8892\n",
            "Epoch 242/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5148e-04 - accuracy: 0.9847 - val_loss: 0.0018 - val_accuracy: 0.8933\n",
            "Epoch 243/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3233e-04 - accuracy: 0.9860 - val_loss: 0.0018 - val_accuracy: 0.8918\n",
            "Epoch 244/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5340e-04 - accuracy: 0.9850 - val_loss: 0.0018 - val_accuracy: 0.8953\n",
            "Epoch 245/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7756e-04 - accuracy: 0.9832 - val_loss: 0.0021 - val_accuracy: 0.8722\n",
            "Epoch 246/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.5474e-04 - accuracy: 0.9780 - val_loss: 0.0021 - val_accuracy: 0.8752\n",
            "Epoch 247/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.1064e-04 - accuracy: 0.9808 - val_loss: 0.0022 - val_accuracy: 0.8672\n",
            "Epoch 248/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 3.1918e-04 - accuracy: 0.9805 - val_loss: 0.0021 - val_accuracy: 0.8713\n",
            "Epoch 249/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.8495e-04 - accuracy: 0.9826 - val_loss: 0.0019 - val_accuracy: 0.8850\n",
            "Epoch 250/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.6122e-04 - accuracy: 0.9842 - val_loss: 0.0019 - val_accuracy: 0.8840\n",
            "Epoch 251/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.6771e-04 - accuracy: 0.9837 - val_loss: 0.0020 - val_accuracy: 0.8787\n",
            "Epoch 252/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7904e-04 - accuracy: 0.9828 - val_loss: 0.0020 - val_accuracy: 0.8812\n",
            "Epoch 253/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5446e-04 - accuracy: 0.9845 - val_loss: 0.0018 - val_accuracy: 0.8920\n",
            "Epoch 254/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3905e-04 - accuracy: 0.9857 - val_loss: 0.0020 - val_accuracy: 0.8848\n",
            "Epoch 255/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5924e-04 - accuracy: 0.9844 - val_loss: 0.0020 - val_accuracy: 0.8798\n",
            "Epoch 256/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.3750e-04 - accuracy: 0.9857 - val_loss: 0.0020 - val_accuracy: 0.8807\n",
            "Epoch 257/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2554e-04 - accuracy: 0.9867 - val_loss: 0.0017 - val_accuracy: 0.8967\n",
            "Epoch 258/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3401e-04 - accuracy: 0.9861 - val_loss: 0.0017 - val_accuracy: 0.8980\n",
            "Epoch 259/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1389e-04 - accuracy: 0.9871 - val_loss: 0.0017 - val_accuracy: 0.8982\n",
            "Epoch 260/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2088e-04 - accuracy: 0.9870 - val_loss: 0.0018 - val_accuracy: 0.8960\n",
            "Epoch 261/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1248e-04 - accuracy: 0.9872 - val_loss: 0.0017 - val_accuracy: 0.8975\n",
            "Epoch 262/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2255e-04 - accuracy: 0.9869 - val_loss: 0.0018 - val_accuracy: 0.8945\n",
            "Epoch 263/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3527e-04 - accuracy: 0.9860 - val_loss: 0.0019 - val_accuracy: 0.8905\n",
            "Epoch 264/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2890e-04 - accuracy: 0.9868 - val_loss: 0.0018 - val_accuracy: 0.8955\n",
            "Epoch 265/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3078e-04 - accuracy: 0.9865 - val_loss: 0.0018 - val_accuracy: 0.8943\n",
            "Epoch 266/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4007e-04 - accuracy: 0.9859 - val_loss: 0.0020 - val_accuracy: 0.8805\n",
            "Epoch 267/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4166e-04 - accuracy: 0.9857 - val_loss: 0.0020 - val_accuracy: 0.8835\n",
            "Epoch 268/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4865e-04 - accuracy: 0.9850 - val_loss: 0.0019 - val_accuracy: 0.8877\n",
            "Epoch 269/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.4016e-04 - accuracy: 0.9858 - val_loss: 0.0017 - val_accuracy: 0.8975\n",
            "Epoch 270/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3750e-04 - accuracy: 0.9861 - val_loss: 0.0018 - val_accuracy: 0.8923\n",
            "Epoch 271/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2421e-04 - accuracy: 0.9868 - val_loss: 0.0018 - val_accuracy: 0.8960\n",
            "Epoch 272/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3533e-04 - accuracy: 0.9863 - val_loss: 0.0020 - val_accuracy: 0.8827\n",
            "Epoch 273/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5557e-04 - accuracy: 0.9847 - val_loss: 0.0022 - val_accuracy: 0.8722\n",
            "Epoch 274/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4388e-04 - accuracy: 0.9857 - val_loss: 0.0020 - val_accuracy: 0.8835\n",
            "Epoch 275/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4063e-04 - accuracy: 0.9857 - val_loss: 0.0020 - val_accuracy: 0.8827\n",
            "Epoch 276/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2977e-04 - accuracy: 0.9863 - val_loss: 0.0018 - val_accuracy: 0.8965\n",
            "Epoch 277/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2290e-04 - accuracy: 0.9867 - val_loss: 0.0018 - val_accuracy: 0.8898\n",
            "Epoch 278/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4509e-04 - accuracy: 0.9854 - val_loss: 0.0018 - val_accuracy: 0.8962\n",
            "Epoch 279/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4160e-04 - accuracy: 0.9857 - val_loss: 0.0019 - val_accuracy: 0.8880\n",
            "Epoch 280/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.8200e-04 - accuracy: 0.9828 - val_loss: 0.0020 - val_accuracy: 0.8830\n",
            "Epoch 281/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7641e-04 - accuracy: 0.9832 - val_loss: 0.0019 - val_accuracy: 0.8908\n",
            "Epoch 282/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3942e-04 - accuracy: 0.9860 - val_loss: 0.0017 - val_accuracy: 0.8980\n",
            "Epoch 283/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5095e-04 - accuracy: 0.9852 - val_loss: 0.0019 - val_accuracy: 0.8870\n",
            "Epoch 284/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3499e-04 - accuracy: 0.9862 - val_loss: 0.0021 - val_accuracy: 0.8773\n",
            "Epoch 285/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5699e-04 - accuracy: 0.9847 - val_loss: 0.0019 - val_accuracy: 0.8867\n",
            "Epoch 286/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.6120e-04 - accuracy: 0.9844 - val_loss: 0.0019 - val_accuracy: 0.8870\n",
            "Epoch 287/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.4854e-04 - accuracy: 0.9850 - val_loss: 0.0019 - val_accuracy: 0.8888\n",
            "Epoch 288/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5802e-04 - accuracy: 0.9847 - val_loss: 0.0019 - val_accuracy: 0.8895\n",
            "Epoch 289/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4179e-04 - accuracy: 0.9859 - val_loss: 0.0019 - val_accuracy: 0.8913\n",
            "Epoch 290/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5203e-04 - accuracy: 0.9853 - val_loss: 0.0019 - val_accuracy: 0.8875\n",
            "Epoch 291/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3745e-04 - accuracy: 0.9859 - val_loss: 0.0018 - val_accuracy: 0.8943\n",
            "Epoch 292/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4888e-04 - accuracy: 0.9851 - val_loss: 0.0019 - val_accuracy: 0.8917\n",
            "Epoch 293/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3911e-04 - accuracy: 0.9858 - val_loss: 0.0018 - val_accuracy: 0.8917\n",
            "Epoch 294/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4051e-04 - accuracy: 0.9858 - val_loss: 0.0019 - val_accuracy: 0.8895\n",
            "Epoch 295/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.3808e-04 - accuracy: 0.9862 - val_loss: 0.0018 - val_accuracy: 0.8932\n",
            "Epoch 296/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3132e-04 - accuracy: 0.9865 - val_loss: 0.0019 - val_accuracy: 0.8878\n",
            "Epoch 297/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3831e-04 - accuracy: 0.9861 - val_loss: 0.0018 - val_accuracy: 0.8912\n",
            "Epoch 298/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3337e-04 - accuracy: 0.9864 - val_loss: 0.0018 - val_accuracy: 0.8955\n",
            "Epoch 299/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2959e-04 - accuracy: 0.9868 - val_loss: 0.0017 - val_accuracy: 0.9000\n",
            "Epoch 300/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4878e-04 - accuracy: 0.9853 - val_loss: 0.0018 - val_accuracy: 0.8918\n",
            "Epoch 301/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5381e-04 - accuracy: 0.9851 - val_loss: 0.0018 - val_accuracy: 0.8937\n",
            "Epoch 302/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2823e-04 - accuracy: 0.9870 - val_loss: 0.0017 - val_accuracy: 0.8998\n",
            "Epoch 303/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3067e-04 - accuracy: 0.9867 - val_loss: 0.0018 - val_accuracy: 0.8943\n",
            "Epoch 304/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3097e-04 - accuracy: 0.9865 - val_loss: 0.0018 - val_accuracy: 0.8937\n",
            "Epoch 305/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7027e-04 - accuracy: 0.9839 - val_loss: 0.0019 - val_accuracy: 0.8895\n",
            "Epoch 306/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4779e-04 - accuracy: 0.9857 - val_loss: 0.0018 - val_accuracy: 0.8962\n",
            "Epoch 307/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4672e-04 - accuracy: 0.9860 - val_loss: 0.0019 - val_accuracy: 0.8928\n",
            "Epoch 308/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.3728e-04 - accuracy: 0.9865 - val_loss: 0.0017 - val_accuracy: 0.8993\n",
            "Epoch 309/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3090e-04 - accuracy: 0.9865 - val_loss: 0.0017 - val_accuracy: 0.9020\n",
            "Epoch 310/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5652e-04 - accuracy: 0.9852 - val_loss: 0.0020 - val_accuracy: 0.8798\n",
            "Epoch 311/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7596e-04 - accuracy: 0.9838 - val_loss: 0.0018 - val_accuracy: 0.8933\n",
            "Epoch 312/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3078e-04 - accuracy: 0.9863 - val_loss: 0.0019 - val_accuracy: 0.8857\n",
            "Epoch 313/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3610e-04 - accuracy: 0.9862 - val_loss: 0.0017 - val_accuracy: 0.9010\n",
            "Epoch 314/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1471e-04 - accuracy: 0.9876 - val_loss: 0.0017 - val_accuracy: 0.9028\n",
            "Epoch 315/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1477e-04 - accuracy: 0.9874 - val_loss: 0.0017 - val_accuracy: 0.9008\n",
            "Epoch 316/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7085e-04 - accuracy: 0.9834 - val_loss: 0.0019 - val_accuracy: 0.8912\n",
            "Epoch 317/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4937e-04 - accuracy: 0.9852 - val_loss: 0.0020 - val_accuracy: 0.8883\n",
            "Epoch 318/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3102e-04 - accuracy: 0.9864 - val_loss: 0.0018 - val_accuracy: 0.8963\n",
            "Epoch 319/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1390e-04 - accuracy: 0.9877 - val_loss: 0.0018 - val_accuracy: 0.8967\n",
            "Epoch 320/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0603e-04 - accuracy: 0.9880 - val_loss: 0.0019 - val_accuracy: 0.8895\n",
            "Epoch 321/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.1394e-04 - accuracy: 0.9875 - val_loss: 0.0017 - val_accuracy: 0.9025\n",
            "Epoch 322/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9728e-04 - accuracy: 0.9887 - val_loss: 0.0017 - val_accuracy: 0.9007\n",
            "Epoch 323/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1053e-04 - accuracy: 0.9877 - val_loss: 0.0017 - val_accuracy: 0.8987\n",
            "Epoch 324/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2965e-04 - accuracy: 0.9867 - val_loss: 0.0018 - val_accuracy: 0.8918\n",
            "Epoch 325/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4204e-04 - accuracy: 0.9856 - val_loss: 0.0019 - val_accuracy: 0.8928\n",
            "Epoch 326/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9607e-04 - accuracy: 0.9887 - val_loss: 0.0017 - val_accuracy: 0.9018\n",
            "Epoch 327/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0203e-04 - accuracy: 0.9882 - val_loss: 0.0017 - val_accuracy: 0.8982\n",
            "Epoch 328/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9729e-04 - accuracy: 0.9887 - val_loss: 0.0016 - val_accuracy: 0.9062\n",
            "Epoch 329/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9773e-04 - accuracy: 0.9887 - val_loss: 0.0017 - val_accuracy: 0.8998\n",
            "Epoch 330/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1227e-04 - accuracy: 0.9876 - val_loss: 0.0019 - val_accuracy: 0.8937\n",
            "Epoch 331/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1501e-04 - accuracy: 0.9877 - val_loss: 0.0017 - val_accuracy: 0.8990\n",
            "Epoch 332/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0332e-04 - accuracy: 0.9883 - val_loss: 0.0018 - val_accuracy: 0.8972\n",
            "Epoch 333/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0396e-04 - accuracy: 0.9881 - val_loss: 0.0017 - val_accuracy: 0.8997\n",
            "Epoch 334/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0871e-04 - accuracy: 0.9877 - val_loss: 0.0018 - val_accuracy: 0.8952\n",
            "Epoch 335/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2699e-04 - accuracy: 0.9867 - val_loss: 0.0017 - val_accuracy: 0.9018\n",
            "Epoch 336/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0364e-04 - accuracy: 0.9883 - val_loss: 0.0017 - val_accuracy: 0.8997\n",
            "Epoch 337/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9663e-04 - accuracy: 0.9890 - val_loss: 0.0016 - val_accuracy: 0.9082\n",
            "Epoch 338/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9303e-04 - accuracy: 0.9890 - val_loss: 0.0017 - val_accuracy: 0.9023\n",
            "Epoch 339/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9722e-04 - accuracy: 0.9886 - val_loss: 0.0016 - val_accuracy: 0.9052\n",
            "Epoch 340/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1506e-04 - accuracy: 0.9872 - val_loss: 0.0018 - val_accuracy: 0.8938\n",
            "Epoch 341/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1102e-04 - accuracy: 0.9877 - val_loss: 0.0017 - val_accuracy: 0.8987\n",
            "Epoch 342/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0705e-04 - accuracy: 0.9882 - val_loss: 0.0017 - val_accuracy: 0.9048\n",
            "Epoch 343/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1761e-04 - accuracy: 0.9872 - val_loss: 0.0017 - val_accuracy: 0.9002\n",
            "Epoch 344/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9574e-04 - accuracy: 0.9887 - val_loss: 0.0017 - val_accuracy: 0.9013\n",
            "Epoch 345/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9745e-04 - accuracy: 0.9888 - val_loss: 0.0016 - val_accuracy: 0.9070\n",
            "Epoch 346/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0747e-04 - accuracy: 0.9880 - val_loss: 0.0018 - val_accuracy: 0.8973\n",
            "Epoch 347/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.1748e-04 - accuracy: 0.9875 - val_loss: 0.0018 - val_accuracy: 0.8975\n",
            "Epoch 348/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.0629e-04 - accuracy: 0.9884 - val_loss: 0.0017 - val_accuracy: 0.9035\n",
            "Epoch 349/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0741e-04 - accuracy: 0.9880 - val_loss: 0.0017 - val_accuracy: 0.8982\n",
            "Epoch 350/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2370e-04 - accuracy: 0.9872 - val_loss: 0.0018 - val_accuracy: 0.8973\n",
            "Epoch 351/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1112e-04 - accuracy: 0.9877 - val_loss: 0.0017 - val_accuracy: 0.9018\n",
            "Epoch 352/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0297e-04 - accuracy: 0.9884 - val_loss: 0.0017 - val_accuracy: 0.8997\n",
            "Epoch 353/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.2376e-04 - accuracy: 0.9870 - val_loss: 0.0017 - val_accuracy: 0.8998\n",
            "Epoch 354/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3556e-04 - accuracy: 0.9860 - val_loss: 0.0017 - val_accuracy: 0.9007\n",
            "Epoch 355/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1515e-04 - accuracy: 0.9875 - val_loss: 0.0018 - val_accuracy: 0.8945\n",
            "Epoch 356/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.5180e-04 - accuracy: 0.9852 - val_loss: 0.0018 - val_accuracy: 0.8972\n",
            "Epoch 357/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.7248e-04 - accuracy: 0.9840 - val_loss: 0.0020 - val_accuracy: 0.8842\n",
            "Epoch 358/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1870e-04 - accuracy: 0.9871 - val_loss: 0.0017 - val_accuracy: 0.9003\n",
            "Epoch 359/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3344e-04 - accuracy: 0.9865 - val_loss: 0.0018 - val_accuracy: 0.8942\n",
            "Epoch 360/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3339e-04 - accuracy: 0.9866 - val_loss: 0.0015 - val_accuracy: 0.9110\n",
            "Epoch 361/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0297e-04 - accuracy: 0.9884 - val_loss: 0.0018 - val_accuracy: 0.8968\n",
            "Epoch 362/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0933e-04 - accuracy: 0.9881 - val_loss: 0.0018 - val_accuracy: 0.8977\n",
            "Epoch 363/400\n",
            "47/47 [==============================] - 4s 76ms/step - loss: 2.1886e-04 - accuracy: 0.9876 - val_loss: 0.0016 - val_accuracy: 0.9068\n",
            "Epoch 364/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0072e-04 - accuracy: 0.9886 - val_loss: 0.0017 - val_accuracy: 0.8997\n",
            "Epoch 365/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9788e-04 - accuracy: 0.9887 - val_loss: 0.0015 - val_accuracy: 0.9108\n",
            "Epoch 366/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0444e-04 - accuracy: 0.9882 - val_loss: 0.0016 - val_accuracy: 0.9067\n",
            "Epoch 367/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0171e-04 - accuracy: 0.9883 - val_loss: 0.0017 - val_accuracy: 0.9058\n",
            "Epoch 368/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1382e-04 - accuracy: 0.9877 - val_loss: 0.0017 - val_accuracy: 0.9023\n",
            "Epoch 369/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9935e-04 - accuracy: 0.9887 - val_loss: 0.0016 - val_accuracy: 0.9108\n",
            "Epoch 370/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0038e-04 - accuracy: 0.9886 - val_loss: 0.0017 - val_accuracy: 0.9033\n",
            "Epoch 371/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9670e-04 - accuracy: 0.9889 - val_loss: 0.0018 - val_accuracy: 0.8983\n",
            "Epoch 372/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0243e-04 - accuracy: 0.9886 - val_loss: 0.0017 - val_accuracy: 0.9032\n",
            "Epoch 373/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9843e-04 - accuracy: 0.9886 - val_loss: 0.0016 - val_accuracy: 0.9057\n",
            "Epoch 374/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0798e-04 - accuracy: 0.9883 - val_loss: 0.0017 - val_accuracy: 0.9013\n",
            "Epoch 375/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.0344e-04 - accuracy: 0.9885 - val_loss: 0.0016 - val_accuracy: 0.9063\n",
            "Epoch 376/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3370e-04 - accuracy: 0.9867 - val_loss: 0.0016 - val_accuracy: 0.9068\n",
            "Epoch 377/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.1796e-04 - accuracy: 0.9876 - val_loss: 0.0018 - val_accuracy: 0.8955\n",
            "Epoch 378/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9763e-04 - accuracy: 0.9887 - val_loss: 0.0016 - val_accuracy: 0.9065\n",
            "Epoch 379/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9539e-04 - accuracy: 0.9889 - val_loss: 0.0017 - val_accuracy: 0.9030\n",
            "Epoch 380/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9407e-04 - accuracy: 0.9891 - val_loss: 0.0017 - val_accuracy: 0.9017\n",
            "Epoch 381/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.8244e-04 - accuracy: 0.9895 - val_loss: 0.0019 - val_accuracy: 0.8908\n",
            "Epoch 382/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9070e-04 - accuracy: 0.9890 - val_loss: 0.0018 - val_accuracy: 0.8960\n",
            "Epoch 383/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.8647e-04 - accuracy: 0.9897 - val_loss: 0.0018 - val_accuracy: 0.8982\n",
            "Epoch 384/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.6970e-04 - accuracy: 0.9901 - val_loss: 0.0016 - val_accuracy: 0.9055\n",
            "Epoch 385/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.7625e-04 - accuracy: 0.9899 - val_loss: 0.0016 - val_accuracy: 0.9057\n",
            "Epoch 386/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.7534e-04 - accuracy: 0.9899 - val_loss: 0.0016 - val_accuracy: 0.9100\n",
            "Epoch 387/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.7430e-04 - accuracy: 0.9902 - val_loss: 0.0016 - val_accuracy: 0.9062\n",
            "Epoch 388/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.7939e-04 - accuracy: 0.9898 - val_loss: 0.0017 - val_accuracy: 0.9015\n",
            "Epoch 389/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.7844e-04 - accuracy: 0.9896 - val_loss: 0.0019 - val_accuracy: 0.8893\n",
            "Epoch 390/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.3935e-04 - accuracy: 0.9863 - val_loss: 0.0021 - val_accuracy: 0.8815\n",
            "Epoch 391/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 2.4355e-04 - accuracy: 0.9856 - val_loss: 0.0019 - val_accuracy: 0.8935\n",
            "Epoch 392/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.9214e-04 - accuracy: 0.9888 - val_loss: 0.0016 - val_accuracy: 0.9055\n",
            "Epoch 393/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.6243e-04 - accuracy: 0.9907 - val_loss: 0.0016 - val_accuracy: 0.9080\n",
            "Epoch 394/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.5483e-04 - accuracy: 0.9913 - val_loss: 0.0018 - val_accuracy: 0.8978\n",
            "Epoch 395/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.5750e-04 - accuracy: 0.9912 - val_loss: 0.0017 - val_accuracy: 0.9057\n",
            "Epoch 396/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.6240e-04 - accuracy: 0.9909 - val_loss: 0.0015 - val_accuracy: 0.9117\n",
            "Epoch 397/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.5380e-04 - accuracy: 0.9915 - val_loss: 0.0017 - val_accuracy: 0.9055\n",
            "Epoch 398/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.5899e-04 - accuracy: 0.9907 - val_loss: 0.0015 - val_accuracy: 0.9138\n",
            "Epoch 399/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.6124e-04 - accuracy: 0.9909 - val_loss: 0.0016 - val_accuracy: 0.9107\n",
            "Epoch 400/400\n",
            "47/47 [==============================] - 4s 75ms/step - loss: 1.6062e-04 - accuracy: 0.9909 - val_loss: 0.0016 - val_accuracy: 0.9103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "HVvegAfYQjT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4acc9ad4-7e77-4390-9ae1-65bda11a931e"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0016 - accuracy: 0.9092\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0015850046183913946, 0.909166693687439]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그래프 분석"
      ],
      "metadata": {
        "id": "uLvm3XtMKYKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=history.history\n",
        "epochs = range(1, len(history['loss']) + 1)\n",
        "acc = history['accuracy']\n",
        "loss = history['loss']\n",
        "val_acc = history['val_accuracy']\n",
        "val_loss = history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(epochs, acc, label='accuracy')\n",
        "plt.plot(epochs, val_acc, label='val_acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(epochs, loss, label='loss', color='g')\n",
        "plt.plot(epochs, val_loss, label='val_loss', color='r')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "7YRFsECl7Qp0",
        "outputId": "6f079eec-c20e-46a4-888b-2409adad9b63"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc5ecd834c0>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 예측해보기(predict)"
      ],
      "metadata": {
        "id": "B7id_mnNKhHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKnoTLlLBPPN",
        "outputId": "8e06685b-4c91-4d7b-804a-f36f83b0daf8"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[44,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0, 57,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0, 65, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 68,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0, 67,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0, 57]])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_p=pd.DataFrame(y_test)\n",
        "\n",
        "for i in range(1,101):\n",
        "  y_test_p.loc[y_test_p[i] == 1.0 , 'y_test'] = i  \n",
        "y_test_p.y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8EWDyMdHpWR",
        "outputId": "348ddc8c-b4b0-4b45-9b9b-a83b87cbce28"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       59.0\n",
              "1       68.0\n",
              "2       72.0\n",
              "3        2.0\n",
              "4       57.0\n",
              "        ... \n",
              "5995     3.0\n",
              "5996    87.0\n",
              "5997    40.0\n",
              "5998    68.0\n",
              "5999    37.0\n",
              "Name: y_test, Length: 6000, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ch1 = pd.DataFrame(np.rint(y_pred))\n",
        "# for i in range(1,101):\n",
        "#   ch1.loc[ch1[i] == 1.0 , 'pred'] = i \n",
        "\n",
        " \n",
        "#predict = pd.concat([data_test,ch1['pred'], y_test_p['y_test']],axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "U6a3cpwDCkHl",
        "outputId": "35e79746-e41a-4713-b942-733f497e3b6c"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0    1    2    3    4    5    6    7    8    9  ...   92   93   94  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "3     0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "5995  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "5996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "5997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "5998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "5999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "\n",
              "       95   96   97   98   99  100  pred  \n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  59.0  \n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0  68.0  \n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0  72.0  \n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0   2.0  \n",
              "4     0.0  0.0  0.0  0.0  0.0  0.0  57.0  \n",
              "...   ...  ...  ...  ...  ...  ...   ...  \n",
              "5995  0.0  0.0  0.0  0.0  0.0  0.0   3.0  \n",
              "5996  0.0  0.0  0.0  0.0  0.0  0.0  87.0  \n",
              "5997  0.0  0.0  0.0  0.0  0.0  0.0  40.0  \n",
              "5998  0.0  0.0  0.0  0.0  0.0  0.0  68.0  \n",
              "5999  0.0  0.0  0.0  0.0  0.0  0.0  45.0  \n",
              "\n",
              "[6000 rows x 102 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d66cc86c-ae23-4a9f-8fb4-dbad40e0c5ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>87.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 102 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d66cc86c-ae23-4a9f-8fb4-dbad40e0c5ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d66cc86c-ae23-4a9f-8fb4-dbad40e0c5ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d66cc86c-ae23-4a9f-8fb4-dbad40e0c5ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex=np.argmax(y_pred, axis=1)\n",
        "ex=ex.astype('float64')\n",
        "ex=pd.DataFrame(ex)\n",
        "ex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "lI3myxchcv-Q",
        "outputId": "22f2ac13-d7ce-409c-db36-bf92c9ca0cad"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0\n",
              "0     59.0\n",
              "1     68.0\n",
              "2     72.0\n",
              "3      2.0\n",
              "4     57.0\n",
              "...    ...\n",
              "5995   3.0\n",
              "5996  87.0\n",
              "5997  40.0\n",
              "5998  68.0\n",
              "5999  45.0\n",
              "\n",
              "[6000 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>87.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ch1 = pd.DataFrame(np.rint(y_pred))\n",
        "ch1['pred'] = ex\n",
        "data_test.reset_index(inplace=True, drop=True)\n",
        "predict = pd.concat([data_test,ch1['pred'], y_test_p['y_test']],axis = 1)"
      ],
      "metadata": {
        "id": "HSPb21Y4eMAm"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict['compare'] = np.where(predict['pred']==predict['y_test'],'yes', 'no')"
      ],
      "metadata": {
        "id": "yhe54j6XJzhy"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_1 = predict[predict[\"compare\"]=='no']\n",
        "predict_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "mdgfuEehKIXX",
        "outputId": "833df983-0f21-460a-de46-668f491d18e1"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "30    0.001909  0.008317  0.014489  0.020412  0.025995  0.031137  0.035801   \n",
              "46    0.096114  0.095362  0.095047  0.095447  0.096676  0.098677  0.101247   \n",
              "54   -0.041972 -0.048778 -0.055266 -0.061636 -0.067728 -0.073065 -0.076978   \n",
              "55    0.050686  0.056807  0.061922  0.066330  0.070463  0.074831  0.079964   \n",
              "71   -0.511413 -0.507140 -0.469849 -0.408462 -0.333769 -0.256404 -0.185178   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5971  0.005315 -0.043084 -0.083200 -0.110473 -0.122973 -0.121490 -0.109050   \n",
              "5981 -0.005281 -0.018280 -0.031669 -0.042939 -0.050464 -0.053648 -0.052817   \n",
              "5992 -0.084734 -0.091664 -0.098196 -0.101411 -0.098148 -0.085744 -0.062829   \n",
              "5994  0.008461  0.011468  0.012707  0.012096  0.009875  0.006558  0.002841   \n",
              "5999  0.052145  0.038833  0.024907  0.010402 -0.004429 -0.019087 -0.032867   \n",
              "\n",
              "             7         8         9  ...       249       250       251  \\\n",
              "30    0.040075  0.044195  0.048538  ...  0.044631  0.050399  0.057432   \n",
              "46    0.104083  0.106844  0.109202  ... -0.004398 -0.008214 -0.013081   \n",
              "54   -0.078796 -0.078050 -0.074630  ... -0.102289 -0.108650 -0.114708   \n",
              "55    0.086349  0.094365  0.104239  ...  0.125449  0.136371  0.147691   \n",
              "71   -0.126038 -0.081724 -0.052058  ...  0.031533  0.034874  0.038518   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5971 -0.090022 -0.069069 -0.050204  ... -0.027012 -0.029614 -0.031356   \n",
              "5981 -0.048958 -0.043371 -0.037307  ... -0.016826 -0.013496 -0.011275   \n",
              "5992 -0.030004  0.009808  0.051498  ...  0.072150  0.081214  0.090895   \n",
              "5994 -0.000513 -0.002782 -0.003375  ... -0.048723 -0.051678 -0.052151   \n",
              "5999 -0.044991 -0.054774 -0.061789  ... -0.056943 -0.054300 -0.054324   \n",
              "\n",
              "           252       253       254       255   pred  y_test  compare  \n",
              "30    0.066046  0.076371  0.088327  0.101648   85.0    36.0       no  \n",
              "46   -0.019006 -0.025674 -0.032320 -0.037693   83.0    80.0       no  \n",
              "54   -0.119718 -0.122885 -0.123496 -0.121095   20.0    71.0       no  \n",
              "55    0.159697  0.172642  0.186692  0.201860   41.0    50.0       no  \n",
              "71    0.042180  0.045745  0.049241  0.052764    4.0    93.0       no  \n",
              "...        ...       ...       ...       ...    ...     ...      ...  \n",
              "5971 -0.033020 -0.035244 -0.038329 -0.042129   95.0    23.0       no  \n",
              "5981 -0.010594 -0.011830 -0.015208 -0.020697   52.0    40.0       no  \n",
              "5992  0.101388  0.112932  0.125713  0.139775  100.0    83.0       no  \n",
              "5994 -0.050205 -0.046318 -0.041326 -0.036264   95.0    49.0       no  \n",
              "5999 -0.058068 -0.065599 -0.075635 -0.085448   45.0    37.0       no  \n",
              "\n",
              "[545 rows x 259 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22dffb56-3200-49eb-89c1-97f537806f07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>pred</th>\n",
              "      <th>y_test</th>\n",
              "      <th>compare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.001909</td>\n",
              "      <td>0.008317</td>\n",
              "      <td>0.014489</td>\n",
              "      <td>0.020412</td>\n",
              "      <td>0.025995</td>\n",
              "      <td>0.031137</td>\n",
              "      <td>0.035801</td>\n",
              "      <td>0.040075</td>\n",
              "      <td>0.044195</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044631</td>\n",
              "      <td>0.050399</td>\n",
              "      <td>0.057432</td>\n",
              "      <td>0.066046</td>\n",
              "      <td>0.076371</td>\n",
              "      <td>0.088327</td>\n",
              "      <td>0.101648</td>\n",
              "      <td>85.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.096114</td>\n",
              "      <td>0.095362</td>\n",
              "      <td>0.095047</td>\n",
              "      <td>0.095447</td>\n",
              "      <td>0.096676</td>\n",
              "      <td>0.098677</td>\n",
              "      <td>0.101247</td>\n",
              "      <td>0.104083</td>\n",
              "      <td>0.106844</td>\n",
              "      <td>0.109202</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004398</td>\n",
              "      <td>-0.008214</td>\n",
              "      <td>-0.013081</td>\n",
              "      <td>-0.019006</td>\n",
              "      <td>-0.025674</td>\n",
              "      <td>-0.032320</td>\n",
              "      <td>-0.037693</td>\n",
              "      <td>83.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>-0.041972</td>\n",
              "      <td>-0.048778</td>\n",
              "      <td>-0.055266</td>\n",
              "      <td>-0.061636</td>\n",
              "      <td>-0.067728</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.076978</td>\n",
              "      <td>-0.078796</td>\n",
              "      <td>-0.078050</td>\n",
              "      <td>-0.074630</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.102289</td>\n",
              "      <td>-0.108650</td>\n",
              "      <td>-0.114708</td>\n",
              "      <td>-0.119718</td>\n",
              "      <td>-0.122885</td>\n",
              "      <td>-0.123496</td>\n",
              "      <td>-0.121095</td>\n",
              "      <td>20.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.050686</td>\n",
              "      <td>0.056807</td>\n",
              "      <td>0.061922</td>\n",
              "      <td>0.066330</td>\n",
              "      <td>0.070463</td>\n",
              "      <td>0.074831</td>\n",
              "      <td>0.079964</td>\n",
              "      <td>0.086349</td>\n",
              "      <td>0.094365</td>\n",
              "      <td>0.104239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.125449</td>\n",
              "      <td>0.136371</td>\n",
              "      <td>0.147691</td>\n",
              "      <td>0.159697</td>\n",
              "      <td>0.172642</td>\n",
              "      <td>0.186692</td>\n",
              "      <td>0.201860</td>\n",
              "      <td>41.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>-0.511413</td>\n",
              "      <td>-0.507140</td>\n",
              "      <td>-0.469849</td>\n",
              "      <td>-0.408462</td>\n",
              "      <td>-0.333769</td>\n",
              "      <td>-0.256404</td>\n",
              "      <td>-0.185178</td>\n",
              "      <td>-0.126038</td>\n",
              "      <td>-0.081724</td>\n",
              "      <td>-0.052058</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031533</td>\n",
              "      <td>0.034874</td>\n",
              "      <td>0.038518</td>\n",
              "      <td>0.042180</td>\n",
              "      <td>0.045745</td>\n",
              "      <td>0.049241</td>\n",
              "      <td>0.052764</td>\n",
              "      <td>4.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>0.005315</td>\n",
              "      <td>-0.043084</td>\n",
              "      <td>-0.083200</td>\n",
              "      <td>-0.110473</td>\n",
              "      <td>-0.122973</td>\n",
              "      <td>-0.121490</td>\n",
              "      <td>-0.109050</td>\n",
              "      <td>-0.090022</td>\n",
              "      <td>-0.069069</td>\n",
              "      <td>-0.050204</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.027012</td>\n",
              "      <td>-0.029614</td>\n",
              "      <td>-0.031356</td>\n",
              "      <td>-0.033020</td>\n",
              "      <td>-0.035244</td>\n",
              "      <td>-0.038329</td>\n",
              "      <td>-0.042129</td>\n",
              "      <td>95.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5981</th>\n",
              "      <td>-0.005281</td>\n",
              "      <td>-0.018280</td>\n",
              "      <td>-0.031669</td>\n",
              "      <td>-0.042939</td>\n",
              "      <td>-0.050464</td>\n",
              "      <td>-0.053648</td>\n",
              "      <td>-0.052817</td>\n",
              "      <td>-0.048958</td>\n",
              "      <td>-0.043371</td>\n",
              "      <td>-0.037307</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016826</td>\n",
              "      <td>-0.013496</td>\n",
              "      <td>-0.011275</td>\n",
              "      <td>-0.010594</td>\n",
              "      <td>-0.011830</td>\n",
              "      <td>-0.015208</td>\n",
              "      <td>-0.020697</td>\n",
              "      <td>52.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5992</th>\n",
              "      <td>-0.084734</td>\n",
              "      <td>-0.091664</td>\n",
              "      <td>-0.098196</td>\n",
              "      <td>-0.101411</td>\n",
              "      <td>-0.098148</td>\n",
              "      <td>-0.085744</td>\n",
              "      <td>-0.062829</td>\n",
              "      <td>-0.030004</td>\n",
              "      <td>0.009808</td>\n",
              "      <td>0.051498</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072150</td>\n",
              "      <td>0.081214</td>\n",
              "      <td>0.090895</td>\n",
              "      <td>0.101388</td>\n",
              "      <td>0.112932</td>\n",
              "      <td>0.125713</td>\n",
              "      <td>0.139775</td>\n",
              "      <td>100.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5994</th>\n",
              "      <td>0.008461</td>\n",
              "      <td>0.011468</td>\n",
              "      <td>0.012707</td>\n",
              "      <td>0.012096</td>\n",
              "      <td>0.009875</td>\n",
              "      <td>0.006558</td>\n",
              "      <td>0.002841</td>\n",
              "      <td>-0.000513</td>\n",
              "      <td>-0.002782</td>\n",
              "      <td>-0.003375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.048723</td>\n",
              "      <td>-0.051678</td>\n",
              "      <td>-0.052151</td>\n",
              "      <td>-0.050205</td>\n",
              "      <td>-0.046318</td>\n",
              "      <td>-0.041326</td>\n",
              "      <td>-0.036264</td>\n",
              "      <td>95.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>0.052145</td>\n",
              "      <td>0.038833</td>\n",
              "      <td>0.024907</td>\n",
              "      <td>0.010402</td>\n",
              "      <td>-0.004429</td>\n",
              "      <td>-0.019087</td>\n",
              "      <td>-0.032867</td>\n",
              "      <td>-0.044991</td>\n",
              "      <td>-0.054774</td>\n",
              "      <td>-0.061789</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.056943</td>\n",
              "      <td>-0.054300</td>\n",
              "      <td>-0.054324</td>\n",
              "      <td>-0.058068</td>\n",
              "      <td>-0.065599</td>\n",
              "      <td>-0.075635</td>\n",
              "      <td>-0.085448</td>\n",
              "      <td>45.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>545 rows × 259 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22dffb56-3200-49eb-89c1-97f537806f07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22dffb56-3200-49eb-89c1-97f537806f07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22dffb56-3200-49eb-89c1-97f537806f07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 필요없는 코드"
      ],
      "metadata": {
        "id": "2aZgEs15Kln5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class Trainer:\n",
        "#     def __init__(self, net, lr, batch_size, num_epochs):\n",
        "#         self.net = net.to(config.device)\n",
        "#         self.num_epochs = num_epochs\n",
        "#         self.criterion = nn.CrossEntropyLoss()\n",
        "#         self.optimizer = AdamW(self.net.parameters(), lr=lr)\n",
        "#         self.scheduler = CosineAnnealingLR(self.optimizer, T_max=num_epochs, eta_min=5e-6)\n",
        "#         self.best_loss = float('inf')\n",
        "#         self.phases = ['train', 'val']\n",
        "#         self.dataloaders = {\n",
        "#             phase: get_dataloader(phase, batch_size) for phase in self.phases\n",
        "#         }\n",
        "#         self.train_df_logs = pd.DataFrame()\n",
        "#         self.val_df_logs = pd.DataFrame()\n",
        "    \n",
        "#     def _train_epoch(self, phase):\n",
        "#         print(f\"{phase} mode | time: {time.strftime('%H:%M:%S')}\")\n",
        "        \n",
        "#         self.net.train() if phase == 'train' else self.net.eval()\n",
        "#         meter = Meter()\n",
        "#         meter.init_metrics()\n",
        "        \n",
        "#         for i, (data, target) in enumerate(self.dataloaders[phase]):\n",
        "#             data = data.to(config.device)\n",
        "#             target = target.to(config.device)\n",
        "            \n",
        "#             output = self.net(data)\n",
        "#             loss = self.criterion(output, target)\n",
        "                        \n",
        "#             if phase == 'train':\n",
        "#                 self.optimizer.zero_grad()\n",
        "#                 loss.backward()\n",
        "#                 self.optimizer.step()\n",
        "            \n",
        "#             meter.update(output, target, loss.item())\n",
        "            \n",
        "#         metrics = meter.get_metrics()\n",
        "#         metrics = {k:v / i for k, v in metrics.items()}\n",
        "#         df_logs = pd.DataFrame([metrics])\n",
        "#         confusion_matrix = meter.get_confusion_matrix()\n",
        "        \n",
        "#         if phase == 'train':\n",
        "#             self.train_df_logs = pd.concat([self.train_df_logs, df_logs], axis=0)\n",
        "#         else:\n",
        "#             self.val_df_logs = pd.concat([self.val_df_logs, df_logs], axis=0)\n",
        "        \n",
        "#         # show logs\n",
        "#         print('{}: {}, {}: {}, {}: {}, {}: {}, {}: {}'\n",
        "#               .format(*(x for kv in metrics.items() for x in kv))\n",
        "#              )\n",
        "#         fig, ax = plt.subplots(figsize=(5, 5))\n",
        "#         cm_ = ax.imshow(confusion_matrix, cmap='hot')\n",
        "#         ax.set_title('Confusion matrix', fontsize=15)\n",
        "#         ax.set_xlabel('Actual', fontsize=13)\n",
        "#         ax.set_ylabel('Predicted', fontsize=13)\n",
        "#         plt.colorbar(cm_)\n",
        "#         plt.show()\n",
        "        \n",
        "#         return loss\n",
        "    \n",
        "#     def run(self):\n",
        "#         for epoch in range(self.num_epochs):\n",
        "#             self._train_epoch(phase='train')\n",
        "#             with torch.no_grad():\n",
        "#                 val_loss = self._train_epoch(phase='val')\n",
        "#                 self.scheduler.step()\n",
        "            \n",
        "#             if val_loss < self.best_loss:\n",
        "#                 self.best_loss = val_loss\n",
        "#                 print('\\nNew checkpoint\\n')\n",
        "#                 self.best_loss = val_loss\n",
        "#                 torch.save(self.net.state_dict(), f\"best_model_epoc{epoch}.pth\")\n",
        "#             #clear_output()"
      ],
      "metadata": {
        "id": "awngIGacQqOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = RNNAttentionModel(1, 64, 'gru', False)\n",
        "#model = RNNModel(1, 64, 'gru', True)"
      ],
      "metadata": {
        "id": "WvDLwLBYQ6Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer = Trainer(net=model, lr=1e-3, batch_size=96, num_epochs=10)#100)\n",
        "# trainer.run()"
      ],
      "metadata": {
        "id": "omYXiJjcRBYl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}