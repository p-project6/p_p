{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXWIFrrheAli",
        "outputId": "6c871dd1-6c3f-4802-b6ac-64961fb20fc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nize6zVDXND_"
      },
      "source": [
        "# 1.bandpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nhn3soxJQYzl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import itertools\n",
        "import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import (CosineAnnealingLR,\n",
        "                                      CosineAnnealingWarmRestarts,\n",
        "                                      StepLR,\n",
        "                                      ExponentialLR)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, auc, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88FIZSPSbA_H"
      },
      "outputs": [],
      "source": [
        "import tqdm, re, sys\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fo2pj1pSfN4N"
      },
      "outputs": [],
      "source": [
        "data_total = pd.read_csv('/content/drive/MyDrive/model_2s/total_band.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "jYUIMIVKd3yW",
        "outputId": "9afd717d-43d3-4e8b-cec9-0418739baca8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "0     -0.031820 -0.015874 -0.001172  0.011249  0.020713  0.026974  0.030190   \n",
              "1     -0.057454 -0.056822 -0.055984 -0.054985 -0.053945 -0.052999 -0.052250   \n",
              "2     -0.054004 -0.050825 -0.048322 -0.046824 -0.046532 -0.047445 -0.049330   \n",
              "3      0.053295  0.053439  0.055066  0.059409  0.067278  0.078961  0.094216   \n",
              "4      0.134007  0.088232  0.042803 -0.000932 -0.041686 -0.078336 -0.110032   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "17995 -0.087605 -0.069234 -0.058444 -0.053914 -0.053427 -0.054525 -0.055053   \n",
              "17996 -0.033347 -0.035287 -0.036169 -0.036014 -0.035070 -0.033744 -0.032503   \n",
              "17997 -0.076867 -0.083002 -0.088128 -0.091454 -0.092582 -0.091623 -0.089189   \n",
              "17998 -0.079288 -0.083358 -0.086464 -0.087995 -0.087513 -0.084880 -0.080336   \n",
              "17999 -0.041533 -0.041870 -0.042836 -0.044782 -0.047871 -0.052004 -0.056828   \n",
              "\n",
              "            7         8         9    ...       503       504       505  \\\n",
              "0      0.030831  0.029559  0.027102  ... -0.072854 -0.070401 -0.067539   \n",
              "1     -0.051733 -0.051414 -0.051213  ... -0.071806 -0.071741 -0.071302   \n",
              "2     -0.051735 -0.054058 -0.055645  ...  0.009824  0.013030  0.016239   \n",
              "3      0.112361  0.132422  0.153321  ...  0.388900  0.382609  0.370062   \n",
              "4     -0.136271 -0.156943 -0.172313  ... -0.113220 -0.141579 -0.164040   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "17995 -0.053525 -0.049262 -0.042344  ... -0.020100 -0.018824 -0.018132   \n",
              "17996 -0.031760 -0.031802 -0.032746  ... -0.060069 -0.061489 -0.061986   \n",
              "17997 -0.086281 -0.084051 -0.083490  ... -0.053679 -0.057318 -0.059515   \n",
              "17998 -0.074488 -0.068211 -0.062467  ... -0.048461 -0.044455 -0.041670   \n",
              "17999 -0.061806 -0.066332 -0.069845  ...  0.136895  0.147996  0.158825   \n",
              "\n",
              "            506       507       508       509       510       511    512  \n",
              "0     -0.064716 -0.062285 -0.060443 -0.059208 -0.058448 -0.057940    1.0  \n",
              "1     -0.070367 -0.068861 -0.066758 -0.064085 -0.060936 -0.057487    1.0  \n",
              "2      0.019380  0.022418  0.025327  0.028062  0.030516  0.032514    1.0  \n",
              "3      0.351265  0.326472  0.296135  0.260876  0.221465  0.178820    1.0  \n",
              "4     -0.180986 -0.193086 -0.201181 -0.206146 -0.208783 -0.209743    1.0  \n",
              "...         ...       ...       ...       ...       ...       ...    ...  \n",
              "17995 -0.018247 -0.019303 -0.021303 -0.024082 -0.027314 -0.030559  100.0  \n",
              "17996 -0.061385 -0.059834 -0.057803 -0.055972 -0.055062 -0.055631  100.0  \n",
              "17997 -0.061043 -0.062554 -0.064528 -0.067243 -0.070758 -0.074902  100.0  \n",
              "17998 -0.040185 -0.039799 -0.040120 -0.040694 -0.041169 -0.041409  100.0  \n",
              "17999  0.169190  0.179084  0.188748  0.198658  0.209439  0.221705  100.0  \n",
              "\n",
              "[18000 rows x 513 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49989114-c163-429d-9509-2cdfc693cd19\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.031820</td>\n",
              "      <td>-0.015874</td>\n",
              "      <td>-0.001172</td>\n",
              "      <td>0.011249</td>\n",
              "      <td>0.020713</td>\n",
              "      <td>0.026974</td>\n",
              "      <td>0.030190</td>\n",
              "      <td>0.030831</td>\n",
              "      <td>0.029559</td>\n",
              "      <td>0.027102</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.072854</td>\n",
              "      <td>-0.070401</td>\n",
              "      <td>-0.067539</td>\n",
              "      <td>-0.064716</td>\n",
              "      <td>-0.062285</td>\n",
              "      <td>-0.060443</td>\n",
              "      <td>-0.059208</td>\n",
              "      <td>-0.058448</td>\n",
              "      <td>-0.057940</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.057454</td>\n",
              "      <td>-0.056822</td>\n",
              "      <td>-0.055984</td>\n",
              "      <td>-0.054985</td>\n",
              "      <td>-0.053945</td>\n",
              "      <td>-0.052999</td>\n",
              "      <td>-0.052250</td>\n",
              "      <td>-0.051733</td>\n",
              "      <td>-0.051414</td>\n",
              "      <td>-0.051213</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.071806</td>\n",
              "      <td>-0.071741</td>\n",
              "      <td>-0.071302</td>\n",
              "      <td>-0.070367</td>\n",
              "      <td>-0.068861</td>\n",
              "      <td>-0.066758</td>\n",
              "      <td>-0.064085</td>\n",
              "      <td>-0.060936</td>\n",
              "      <td>-0.057487</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.054004</td>\n",
              "      <td>-0.050825</td>\n",
              "      <td>-0.048322</td>\n",
              "      <td>-0.046824</td>\n",
              "      <td>-0.046532</td>\n",
              "      <td>-0.047445</td>\n",
              "      <td>-0.049330</td>\n",
              "      <td>-0.051735</td>\n",
              "      <td>-0.054058</td>\n",
              "      <td>-0.055645</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009824</td>\n",
              "      <td>0.013030</td>\n",
              "      <td>0.016239</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.022418</td>\n",
              "      <td>0.025327</td>\n",
              "      <td>0.028062</td>\n",
              "      <td>0.030516</td>\n",
              "      <td>0.032514</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.053295</td>\n",
              "      <td>0.053439</td>\n",
              "      <td>0.055066</td>\n",
              "      <td>0.059409</td>\n",
              "      <td>0.067278</td>\n",
              "      <td>0.078961</td>\n",
              "      <td>0.094216</td>\n",
              "      <td>0.112361</td>\n",
              "      <td>0.132422</td>\n",
              "      <td>0.153321</td>\n",
              "      <td>...</td>\n",
              "      <td>0.388900</td>\n",
              "      <td>0.382609</td>\n",
              "      <td>0.370062</td>\n",
              "      <td>0.351265</td>\n",
              "      <td>0.326472</td>\n",
              "      <td>0.296135</td>\n",
              "      <td>0.260876</td>\n",
              "      <td>0.221465</td>\n",
              "      <td>0.178820</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.134007</td>\n",
              "      <td>0.088232</td>\n",
              "      <td>0.042803</td>\n",
              "      <td>-0.000932</td>\n",
              "      <td>-0.041686</td>\n",
              "      <td>-0.078336</td>\n",
              "      <td>-0.110032</td>\n",
              "      <td>-0.136271</td>\n",
              "      <td>-0.156943</td>\n",
              "      <td>-0.172313</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.113220</td>\n",
              "      <td>-0.141579</td>\n",
              "      <td>-0.164040</td>\n",
              "      <td>-0.180986</td>\n",
              "      <td>-0.193086</td>\n",
              "      <td>-0.201181</td>\n",
              "      <td>-0.206146</td>\n",
              "      <td>-0.208783</td>\n",
              "      <td>-0.209743</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17995</th>\n",
              "      <td>-0.087605</td>\n",
              "      <td>-0.069234</td>\n",
              "      <td>-0.058444</td>\n",
              "      <td>-0.053914</td>\n",
              "      <td>-0.053427</td>\n",
              "      <td>-0.054525</td>\n",
              "      <td>-0.055053</td>\n",
              "      <td>-0.053525</td>\n",
              "      <td>-0.049262</td>\n",
              "      <td>-0.042344</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020100</td>\n",
              "      <td>-0.018824</td>\n",
              "      <td>-0.018132</td>\n",
              "      <td>-0.018247</td>\n",
              "      <td>-0.019303</td>\n",
              "      <td>-0.021303</td>\n",
              "      <td>-0.024082</td>\n",
              "      <td>-0.027314</td>\n",
              "      <td>-0.030559</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17996</th>\n",
              "      <td>-0.033347</td>\n",
              "      <td>-0.035287</td>\n",
              "      <td>-0.036169</td>\n",
              "      <td>-0.036014</td>\n",
              "      <td>-0.035070</td>\n",
              "      <td>-0.033744</td>\n",
              "      <td>-0.032503</td>\n",
              "      <td>-0.031760</td>\n",
              "      <td>-0.031802</td>\n",
              "      <td>-0.032746</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.060069</td>\n",
              "      <td>-0.061489</td>\n",
              "      <td>-0.061986</td>\n",
              "      <td>-0.061385</td>\n",
              "      <td>-0.059834</td>\n",
              "      <td>-0.057803</td>\n",
              "      <td>-0.055972</td>\n",
              "      <td>-0.055062</td>\n",
              "      <td>-0.055631</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17997</th>\n",
              "      <td>-0.076867</td>\n",
              "      <td>-0.083002</td>\n",
              "      <td>-0.088128</td>\n",
              "      <td>-0.091454</td>\n",
              "      <td>-0.092582</td>\n",
              "      <td>-0.091623</td>\n",
              "      <td>-0.089189</td>\n",
              "      <td>-0.086281</td>\n",
              "      <td>-0.084051</td>\n",
              "      <td>-0.083490</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053679</td>\n",
              "      <td>-0.057318</td>\n",
              "      <td>-0.059515</td>\n",
              "      <td>-0.061043</td>\n",
              "      <td>-0.062554</td>\n",
              "      <td>-0.064528</td>\n",
              "      <td>-0.067243</td>\n",
              "      <td>-0.070758</td>\n",
              "      <td>-0.074902</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17998</th>\n",
              "      <td>-0.079288</td>\n",
              "      <td>-0.083358</td>\n",
              "      <td>-0.086464</td>\n",
              "      <td>-0.087995</td>\n",
              "      <td>-0.087513</td>\n",
              "      <td>-0.084880</td>\n",
              "      <td>-0.080336</td>\n",
              "      <td>-0.074488</td>\n",
              "      <td>-0.068211</td>\n",
              "      <td>-0.062467</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.048461</td>\n",
              "      <td>-0.044455</td>\n",
              "      <td>-0.041670</td>\n",
              "      <td>-0.040185</td>\n",
              "      <td>-0.039799</td>\n",
              "      <td>-0.040120</td>\n",
              "      <td>-0.040694</td>\n",
              "      <td>-0.041169</td>\n",
              "      <td>-0.041409</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17999</th>\n",
              "      <td>-0.041533</td>\n",
              "      <td>-0.041870</td>\n",
              "      <td>-0.042836</td>\n",
              "      <td>-0.044782</td>\n",
              "      <td>-0.047871</td>\n",
              "      <td>-0.052004</td>\n",
              "      <td>-0.056828</td>\n",
              "      <td>-0.061806</td>\n",
              "      <td>-0.066332</td>\n",
              "      <td>-0.069845</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136895</td>\n",
              "      <td>0.147996</td>\n",
              "      <td>0.158825</td>\n",
              "      <td>0.169190</td>\n",
              "      <td>0.179084</td>\n",
              "      <td>0.188748</td>\n",
              "      <td>0.198658</td>\n",
              "      <td>0.209439</td>\n",
              "      <td>0.221705</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18000 rows × 513 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49989114-c163-429d-9509-2cdfc693cd19')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49989114-c163-429d-9509-2cdfc693cd19 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49989114-c163-429d-9509-2cdfc693cd19');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data_total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7BNW6vLSn40"
      },
      "source": [
        "## 데이터 전체 섞기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuAljzhlSxO0"
      },
      "outputs": [],
      "source": [
        "data_total=data_total.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAO2XTRKS938"
      },
      "outputs": [],
      "source": [
        "data_train=data_total.iloc[0:14400, :]\n",
        "data_val=data_total.iloc[14400:16200, :]\n",
        "data_test=data_total.iloc[16200:18000,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "R03ForgAUEFw",
        "outputId": "cc53dcb0-ad9f-460c-bd5a-db8a04986c4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "13096 -0.050835 -0.049955 -0.047396 -0.043498 -0.038908 -0.034459 -0.031010   \n",
              "14015  0.334022  0.344068  0.352652  0.358983  0.362081  0.360883  0.354374   \n",
              "5395  -0.038915 -0.035652 -0.034952 -0.037018 -0.041736 -0.048691 -0.057248   \n",
              "3000  -0.066921 -0.062802 -0.059281 -0.056816 -0.055619 -0.055620 -0.056506   \n",
              "15994 -0.040558 -0.036159 -0.030604 -0.024281 -0.017749 -0.011654 -0.006618   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "11887 -0.132853 -0.133607 -0.134204 -0.134345 -0.133755 -0.132263 -0.129848   \n",
              "5556  -0.012407 -0.016077 -0.018572 -0.019023 -0.017072 -0.012936 -0.007314   \n",
              "3074  -0.028002 -0.030009 -0.032056 -0.033967 -0.035531 -0.036543 -0.036861   \n",
              "9894  -0.019427  0.044036  0.111657  0.185185  0.262317  0.336364  0.397391   \n",
              "13992 -0.038939 -0.039788 -0.040345 -0.040344 -0.039569 -0.037895 -0.035321   \n",
              "\n",
              "            7         8         9    ...       503       504       505  \\\n",
              "13096 -0.029260 -0.029599 -0.032018  ... -0.026675 -0.023878 -0.020451   \n",
              "14015  0.341746  0.322564  0.296894  ... -0.070968 -0.070659 -0.070806   \n",
              "5395  -0.066680 -0.076291 -0.085520  ... -0.000616 -0.010160 -0.016861   \n",
              "3000  -0.057812 -0.059031 -0.059732  ... -0.099807 -0.105695 -0.107757   \n",
              "15994 -0.003158 -0.001631 -0.002216  ... -0.052934 -0.050671 -0.047829   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "11887 -0.126636 -0.122836 -0.118636  ... -0.074517 -0.074244 -0.073707   \n",
              "5556  -0.001177  0.004477  0.008846  ...  0.022531  0.015122  0.007310   \n",
              "3074  -0.036462 -0.035490 -0.034245  ... -0.079476 -0.080127 -0.081072   \n",
              "9894   0.434547  0.438937  0.406213  ... -0.039651 -0.033872 -0.028633   \n",
              "13992 -0.032000 -0.028227 -0.024399  ...  0.247153  0.260106  0.271430   \n",
              "\n",
              "            506       507       508       509       510       511   512  \n",
              "13096 -0.016205 -0.010906 -0.004367  0.003467  0.012462  0.022282  73.0  \n",
              "14015 -0.071741 -0.073799 -0.077241 -0.082172 -0.088471 -0.095762  78.0  \n",
              "5395  -0.021242 -0.023847 -0.025205 -0.025815 -0.026107 -0.026400  30.0  \n",
              "3000  -0.106381 -0.102430 -0.097121 -0.091819 -0.087783 -0.085938  17.0  \n",
              "15994 -0.044536 -0.040964 -0.037296 -0.033688 -0.030263 -0.027107  89.0  \n",
              "...         ...       ...       ...       ...       ...       ...   ...  \n",
              "11887 -0.072962 -0.072074 -0.071107 -0.070101 -0.069058 -0.067929  67.0  \n",
              "5556   0.001304 -0.001639 -0.001279  0.001778  0.006399  0.011307  31.0  \n",
              "3074  -0.082254 -0.083592 -0.084977 -0.086274 -0.087332 -0.087999  18.0  \n",
              "9894  -0.024593 -0.022450 -0.022735 -0.025612 -0.030723 -0.037157  55.0  \n",
              "13992  0.281697  0.291521  0.301367  0.311391  0.321334  0.330485  78.0  \n",
              "\n",
              "[14400 rows x 513 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f62ab739-fba0-4fb6-9758-2ab431ed901c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13096</th>\n",
              "      <td>-0.050835</td>\n",
              "      <td>-0.049955</td>\n",
              "      <td>-0.047396</td>\n",
              "      <td>-0.043498</td>\n",
              "      <td>-0.038908</td>\n",
              "      <td>-0.034459</td>\n",
              "      <td>-0.031010</td>\n",
              "      <td>-0.029260</td>\n",
              "      <td>-0.029599</td>\n",
              "      <td>-0.032018</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026675</td>\n",
              "      <td>-0.023878</td>\n",
              "      <td>-0.020451</td>\n",
              "      <td>-0.016205</td>\n",
              "      <td>-0.010906</td>\n",
              "      <td>-0.004367</td>\n",
              "      <td>0.003467</td>\n",
              "      <td>0.012462</td>\n",
              "      <td>0.022282</td>\n",
              "      <td>73.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14015</th>\n",
              "      <td>0.334022</td>\n",
              "      <td>0.344068</td>\n",
              "      <td>0.352652</td>\n",
              "      <td>0.358983</td>\n",
              "      <td>0.362081</td>\n",
              "      <td>0.360883</td>\n",
              "      <td>0.354374</td>\n",
              "      <td>0.341746</td>\n",
              "      <td>0.322564</td>\n",
              "      <td>0.296894</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.070968</td>\n",
              "      <td>-0.070659</td>\n",
              "      <td>-0.070806</td>\n",
              "      <td>-0.071741</td>\n",
              "      <td>-0.073799</td>\n",
              "      <td>-0.077241</td>\n",
              "      <td>-0.082172</td>\n",
              "      <td>-0.088471</td>\n",
              "      <td>-0.095762</td>\n",
              "      <td>78.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5395</th>\n",
              "      <td>-0.038915</td>\n",
              "      <td>-0.035652</td>\n",
              "      <td>-0.034952</td>\n",
              "      <td>-0.037018</td>\n",
              "      <td>-0.041736</td>\n",
              "      <td>-0.048691</td>\n",
              "      <td>-0.057248</td>\n",
              "      <td>-0.066680</td>\n",
              "      <td>-0.076291</td>\n",
              "      <td>-0.085520</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000616</td>\n",
              "      <td>-0.010160</td>\n",
              "      <td>-0.016861</td>\n",
              "      <td>-0.021242</td>\n",
              "      <td>-0.023847</td>\n",
              "      <td>-0.025205</td>\n",
              "      <td>-0.025815</td>\n",
              "      <td>-0.026107</td>\n",
              "      <td>-0.026400</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3000</th>\n",
              "      <td>-0.066921</td>\n",
              "      <td>-0.062802</td>\n",
              "      <td>-0.059281</td>\n",
              "      <td>-0.056816</td>\n",
              "      <td>-0.055619</td>\n",
              "      <td>-0.055620</td>\n",
              "      <td>-0.056506</td>\n",
              "      <td>-0.057812</td>\n",
              "      <td>-0.059031</td>\n",
              "      <td>-0.059732</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.099807</td>\n",
              "      <td>-0.105695</td>\n",
              "      <td>-0.107757</td>\n",
              "      <td>-0.106381</td>\n",
              "      <td>-0.102430</td>\n",
              "      <td>-0.097121</td>\n",
              "      <td>-0.091819</td>\n",
              "      <td>-0.087783</td>\n",
              "      <td>-0.085938</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15994</th>\n",
              "      <td>-0.040558</td>\n",
              "      <td>-0.036159</td>\n",
              "      <td>-0.030604</td>\n",
              "      <td>-0.024281</td>\n",
              "      <td>-0.017749</td>\n",
              "      <td>-0.011654</td>\n",
              "      <td>-0.006618</td>\n",
              "      <td>-0.003158</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.002216</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.052934</td>\n",
              "      <td>-0.050671</td>\n",
              "      <td>-0.047829</td>\n",
              "      <td>-0.044536</td>\n",
              "      <td>-0.040964</td>\n",
              "      <td>-0.037296</td>\n",
              "      <td>-0.033688</td>\n",
              "      <td>-0.030263</td>\n",
              "      <td>-0.027107</td>\n",
              "      <td>89.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11887</th>\n",
              "      <td>-0.132853</td>\n",
              "      <td>-0.133607</td>\n",
              "      <td>-0.134204</td>\n",
              "      <td>-0.134345</td>\n",
              "      <td>-0.133755</td>\n",
              "      <td>-0.132263</td>\n",
              "      <td>-0.129848</td>\n",
              "      <td>-0.126636</td>\n",
              "      <td>-0.122836</td>\n",
              "      <td>-0.118636</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.074517</td>\n",
              "      <td>-0.074244</td>\n",
              "      <td>-0.073707</td>\n",
              "      <td>-0.072962</td>\n",
              "      <td>-0.072074</td>\n",
              "      <td>-0.071107</td>\n",
              "      <td>-0.070101</td>\n",
              "      <td>-0.069058</td>\n",
              "      <td>-0.067929</td>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5556</th>\n",
              "      <td>-0.012407</td>\n",
              "      <td>-0.016077</td>\n",
              "      <td>-0.018572</td>\n",
              "      <td>-0.019023</td>\n",
              "      <td>-0.017072</td>\n",
              "      <td>-0.012936</td>\n",
              "      <td>-0.007314</td>\n",
              "      <td>-0.001177</td>\n",
              "      <td>0.004477</td>\n",
              "      <td>0.008846</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022531</td>\n",
              "      <td>0.015122</td>\n",
              "      <td>0.007310</td>\n",
              "      <td>0.001304</td>\n",
              "      <td>-0.001639</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>0.001778</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.011307</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3074</th>\n",
              "      <td>-0.028002</td>\n",
              "      <td>-0.030009</td>\n",
              "      <td>-0.032056</td>\n",
              "      <td>-0.033967</td>\n",
              "      <td>-0.035531</td>\n",
              "      <td>-0.036543</td>\n",
              "      <td>-0.036861</td>\n",
              "      <td>-0.036462</td>\n",
              "      <td>-0.035490</td>\n",
              "      <td>-0.034245</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.079476</td>\n",
              "      <td>-0.080127</td>\n",
              "      <td>-0.081072</td>\n",
              "      <td>-0.082254</td>\n",
              "      <td>-0.083592</td>\n",
              "      <td>-0.084977</td>\n",
              "      <td>-0.086274</td>\n",
              "      <td>-0.087332</td>\n",
              "      <td>-0.087999</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9894</th>\n",
              "      <td>-0.019427</td>\n",
              "      <td>0.044036</td>\n",
              "      <td>0.111657</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>0.262317</td>\n",
              "      <td>0.336364</td>\n",
              "      <td>0.397391</td>\n",
              "      <td>0.434547</td>\n",
              "      <td>0.438937</td>\n",
              "      <td>0.406213</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.039651</td>\n",
              "      <td>-0.033872</td>\n",
              "      <td>-0.028633</td>\n",
              "      <td>-0.024593</td>\n",
              "      <td>-0.022450</td>\n",
              "      <td>-0.022735</td>\n",
              "      <td>-0.025612</td>\n",
              "      <td>-0.030723</td>\n",
              "      <td>-0.037157</td>\n",
              "      <td>55.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13992</th>\n",
              "      <td>-0.038939</td>\n",
              "      <td>-0.039788</td>\n",
              "      <td>-0.040345</td>\n",
              "      <td>-0.040344</td>\n",
              "      <td>-0.039569</td>\n",
              "      <td>-0.037895</td>\n",
              "      <td>-0.035321</td>\n",
              "      <td>-0.032000</td>\n",
              "      <td>-0.028227</td>\n",
              "      <td>-0.024399</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247153</td>\n",
              "      <td>0.260106</td>\n",
              "      <td>0.271430</td>\n",
              "      <td>0.281697</td>\n",
              "      <td>0.291521</td>\n",
              "      <td>0.301367</td>\n",
              "      <td>0.311391</td>\n",
              "      <td>0.321334</td>\n",
              "      <td>0.330485</td>\n",
              "      <td>78.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14400 rows × 513 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f62ab739-fba0-4fb6-9758-2ab431ed901c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f62ab739-fba0-4fb6-9758-2ab431ed901c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f62ab739-fba0-4fb6-9758-2ab431ed901c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQBBj0ypT8T-"
      },
      "source": [
        "## 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koQxh6-XfrG1",
        "outputId": "7b4f46bc-a41f-4e4d-ae38-8b0cefb87169"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y_train = to_categorical(data_train[512])\n",
        "y_test = to_categorical(data_test[512])\n",
        "y_val = to_categorical(data_val[512])\n",
        "y_train[14399]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "QJUFXwCRkGhC",
        "outputId": "f86448ec-101b-43cb-ef8e-69a8c0adb7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "13096 -0.050835 -0.049955 -0.047396 -0.043498 -0.038908 -0.034459 -0.031010   \n",
              "14015  0.334022  0.344068  0.352652  0.358983  0.362081  0.360883  0.354374   \n",
              "5395  -0.038915 -0.035652 -0.034952 -0.037018 -0.041736 -0.048691 -0.057248   \n",
              "3000  -0.066921 -0.062802 -0.059281 -0.056816 -0.055619 -0.055620 -0.056506   \n",
              "15994 -0.040558 -0.036159 -0.030604 -0.024281 -0.017749 -0.011654 -0.006618   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "11887 -0.132853 -0.133607 -0.134204 -0.134345 -0.133755 -0.132263 -0.129848   \n",
              "5556  -0.012407 -0.016077 -0.018572 -0.019023 -0.017072 -0.012936 -0.007314   \n",
              "3074  -0.028002 -0.030009 -0.032056 -0.033967 -0.035531 -0.036543 -0.036861   \n",
              "9894  -0.019427  0.044036  0.111657  0.185185  0.262317  0.336364  0.397391   \n",
              "13992 -0.038939 -0.039788 -0.040345 -0.040344 -0.039569 -0.037895 -0.035321   \n",
              "\n",
              "            7         8         9    ...       502       503       504  \\\n",
              "13096 -0.029260 -0.029599 -0.032018  ... -0.028909 -0.026675 -0.023878   \n",
              "14015  0.341746  0.322564  0.296894  ... -0.071463 -0.070968 -0.070659   \n",
              "5395  -0.066680 -0.076291 -0.085520  ...  0.012234 -0.000616 -0.010160   \n",
              "3000  -0.057812 -0.059031 -0.059732  ... -0.090178 -0.099807 -0.105695   \n",
              "15994 -0.003158 -0.001631 -0.002216  ... -0.054570 -0.052934 -0.050671   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "11887 -0.126636 -0.122836 -0.118636  ... -0.074498 -0.074517 -0.074244   \n",
              "5556  -0.001177  0.004477  0.008846  ...  0.026687  0.022531  0.015122   \n",
              "3074  -0.036462 -0.035490 -0.034245  ... -0.079158 -0.079476 -0.080127   \n",
              "9894   0.434547  0.438937  0.406213  ... -0.045476 -0.039651 -0.033872   \n",
              "13992 -0.032000 -0.028227 -0.024399  ...  0.232201  0.247153  0.260106   \n",
              "\n",
              "            505       506       507       508       509       510       511  \n",
              "13096 -0.020451 -0.016205 -0.010906 -0.004367  0.003467  0.012462  0.022282  \n",
              "14015 -0.070806 -0.071741 -0.073799 -0.077241 -0.082172 -0.088471 -0.095762  \n",
              "5395  -0.016861 -0.021242 -0.023847 -0.025205 -0.025815 -0.026107 -0.026400  \n",
              "3000  -0.107757 -0.106381 -0.102430 -0.097121 -0.091819 -0.087783 -0.085938  \n",
              "15994 -0.047829 -0.044536 -0.040964 -0.037296 -0.033688 -0.030263 -0.027107  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "11887 -0.073707 -0.072962 -0.072074 -0.071107 -0.070101 -0.069058 -0.067929  \n",
              "5556   0.007310  0.001304 -0.001639 -0.001279  0.001778  0.006399  0.011307  \n",
              "3074  -0.081072 -0.082254 -0.083592 -0.084977 -0.086274 -0.087332 -0.087999  \n",
              "9894  -0.028633 -0.024593 -0.022450 -0.022735 -0.025612 -0.030723 -0.037157  \n",
              "13992  0.271430  0.281697  0.291521  0.301367  0.311391  0.321334  0.330485  \n",
              "\n",
              "[14400 rows x 512 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01708320-37bf-448e-9113-27404c96c6ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13096</th>\n",
              "      <td>-0.050835</td>\n",
              "      <td>-0.049955</td>\n",
              "      <td>-0.047396</td>\n",
              "      <td>-0.043498</td>\n",
              "      <td>-0.038908</td>\n",
              "      <td>-0.034459</td>\n",
              "      <td>-0.031010</td>\n",
              "      <td>-0.029260</td>\n",
              "      <td>-0.029599</td>\n",
              "      <td>-0.032018</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028909</td>\n",
              "      <td>-0.026675</td>\n",
              "      <td>-0.023878</td>\n",
              "      <td>-0.020451</td>\n",
              "      <td>-0.016205</td>\n",
              "      <td>-0.010906</td>\n",
              "      <td>-0.004367</td>\n",
              "      <td>0.003467</td>\n",
              "      <td>0.012462</td>\n",
              "      <td>0.022282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14015</th>\n",
              "      <td>0.334022</td>\n",
              "      <td>0.344068</td>\n",
              "      <td>0.352652</td>\n",
              "      <td>0.358983</td>\n",
              "      <td>0.362081</td>\n",
              "      <td>0.360883</td>\n",
              "      <td>0.354374</td>\n",
              "      <td>0.341746</td>\n",
              "      <td>0.322564</td>\n",
              "      <td>0.296894</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.071463</td>\n",
              "      <td>-0.070968</td>\n",
              "      <td>-0.070659</td>\n",
              "      <td>-0.070806</td>\n",
              "      <td>-0.071741</td>\n",
              "      <td>-0.073799</td>\n",
              "      <td>-0.077241</td>\n",
              "      <td>-0.082172</td>\n",
              "      <td>-0.088471</td>\n",
              "      <td>-0.095762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5395</th>\n",
              "      <td>-0.038915</td>\n",
              "      <td>-0.035652</td>\n",
              "      <td>-0.034952</td>\n",
              "      <td>-0.037018</td>\n",
              "      <td>-0.041736</td>\n",
              "      <td>-0.048691</td>\n",
              "      <td>-0.057248</td>\n",
              "      <td>-0.066680</td>\n",
              "      <td>-0.076291</td>\n",
              "      <td>-0.085520</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012234</td>\n",
              "      <td>-0.000616</td>\n",
              "      <td>-0.010160</td>\n",
              "      <td>-0.016861</td>\n",
              "      <td>-0.021242</td>\n",
              "      <td>-0.023847</td>\n",
              "      <td>-0.025205</td>\n",
              "      <td>-0.025815</td>\n",
              "      <td>-0.026107</td>\n",
              "      <td>-0.026400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3000</th>\n",
              "      <td>-0.066921</td>\n",
              "      <td>-0.062802</td>\n",
              "      <td>-0.059281</td>\n",
              "      <td>-0.056816</td>\n",
              "      <td>-0.055619</td>\n",
              "      <td>-0.055620</td>\n",
              "      <td>-0.056506</td>\n",
              "      <td>-0.057812</td>\n",
              "      <td>-0.059031</td>\n",
              "      <td>-0.059732</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090178</td>\n",
              "      <td>-0.099807</td>\n",
              "      <td>-0.105695</td>\n",
              "      <td>-0.107757</td>\n",
              "      <td>-0.106381</td>\n",
              "      <td>-0.102430</td>\n",
              "      <td>-0.097121</td>\n",
              "      <td>-0.091819</td>\n",
              "      <td>-0.087783</td>\n",
              "      <td>-0.085938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15994</th>\n",
              "      <td>-0.040558</td>\n",
              "      <td>-0.036159</td>\n",
              "      <td>-0.030604</td>\n",
              "      <td>-0.024281</td>\n",
              "      <td>-0.017749</td>\n",
              "      <td>-0.011654</td>\n",
              "      <td>-0.006618</td>\n",
              "      <td>-0.003158</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>-0.002216</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054570</td>\n",
              "      <td>-0.052934</td>\n",
              "      <td>-0.050671</td>\n",
              "      <td>-0.047829</td>\n",
              "      <td>-0.044536</td>\n",
              "      <td>-0.040964</td>\n",
              "      <td>-0.037296</td>\n",
              "      <td>-0.033688</td>\n",
              "      <td>-0.030263</td>\n",
              "      <td>-0.027107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11887</th>\n",
              "      <td>-0.132853</td>\n",
              "      <td>-0.133607</td>\n",
              "      <td>-0.134204</td>\n",
              "      <td>-0.134345</td>\n",
              "      <td>-0.133755</td>\n",
              "      <td>-0.132263</td>\n",
              "      <td>-0.129848</td>\n",
              "      <td>-0.126636</td>\n",
              "      <td>-0.122836</td>\n",
              "      <td>-0.118636</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.074498</td>\n",
              "      <td>-0.074517</td>\n",
              "      <td>-0.074244</td>\n",
              "      <td>-0.073707</td>\n",
              "      <td>-0.072962</td>\n",
              "      <td>-0.072074</td>\n",
              "      <td>-0.071107</td>\n",
              "      <td>-0.070101</td>\n",
              "      <td>-0.069058</td>\n",
              "      <td>-0.067929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5556</th>\n",
              "      <td>-0.012407</td>\n",
              "      <td>-0.016077</td>\n",
              "      <td>-0.018572</td>\n",
              "      <td>-0.019023</td>\n",
              "      <td>-0.017072</td>\n",
              "      <td>-0.012936</td>\n",
              "      <td>-0.007314</td>\n",
              "      <td>-0.001177</td>\n",
              "      <td>0.004477</td>\n",
              "      <td>0.008846</td>\n",
              "      <td>...</td>\n",
              "      <td>0.026687</td>\n",
              "      <td>0.022531</td>\n",
              "      <td>0.015122</td>\n",
              "      <td>0.007310</td>\n",
              "      <td>0.001304</td>\n",
              "      <td>-0.001639</td>\n",
              "      <td>-0.001279</td>\n",
              "      <td>0.001778</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.011307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3074</th>\n",
              "      <td>-0.028002</td>\n",
              "      <td>-0.030009</td>\n",
              "      <td>-0.032056</td>\n",
              "      <td>-0.033967</td>\n",
              "      <td>-0.035531</td>\n",
              "      <td>-0.036543</td>\n",
              "      <td>-0.036861</td>\n",
              "      <td>-0.036462</td>\n",
              "      <td>-0.035490</td>\n",
              "      <td>-0.034245</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.079158</td>\n",
              "      <td>-0.079476</td>\n",
              "      <td>-0.080127</td>\n",
              "      <td>-0.081072</td>\n",
              "      <td>-0.082254</td>\n",
              "      <td>-0.083592</td>\n",
              "      <td>-0.084977</td>\n",
              "      <td>-0.086274</td>\n",
              "      <td>-0.087332</td>\n",
              "      <td>-0.087999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9894</th>\n",
              "      <td>-0.019427</td>\n",
              "      <td>0.044036</td>\n",
              "      <td>0.111657</td>\n",
              "      <td>0.185185</td>\n",
              "      <td>0.262317</td>\n",
              "      <td>0.336364</td>\n",
              "      <td>0.397391</td>\n",
              "      <td>0.434547</td>\n",
              "      <td>0.438937</td>\n",
              "      <td>0.406213</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.045476</td>\n",
              "      <td>-0.039651</td>\n",
              "      <td>-0.033872</td>\n",
              "      <td>-0.028633</td>\n",
              "      <td>-0.024593</td>\n",
              "      <td>-0.022450</td>\n",
              "      <td>-0.022735</td>\n",
              "      <td>-0.025612</td>\n",
              "      <td>-0.030723</td>\n",
              "      <td>-0.037157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13992</th>\n",
              "      <td>-0.038939</td>\n",
              "      <td>-0.039788</td>\n",
              "      <td>-0.040345</td>\n",
              "      <td>-0.040344</td>\n",
              "      <td>-0.039569</td>\n",
              "      <td>-0.037895</td>\n",
              "      <td>-0.035321</td>\n",
              "      <td>-0.032000</td>\n",
              "      <td>-0.028227</td>\n",
              "      <td>-0.024399</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232201</td>\n",
              "      <td>0.247153</td>\n",
              "      <td>0.260106</td>\n",
              "      <td>0.271430</td>\n",
              "      <td>0.281697</td>\n",
              "      <td>0.291521</td>\n",
              "      <td>0.301367</td>\n",
              "      <td>0.311391</td>\n",
              "      <td>0.321334</td>\n",
              "      <td>0.330485</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14400 rows × 512 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01708320-37bf-448e-9113-27404c96c6ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01708320-37bf-448e-9113-27404c96c6ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01708320-37bf-448e-9113-27404c96c6ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data_train.drop([512], axis=1, inplace=True)\n",
        "data_test.drop([512], axis=1, inplace=True)\n",
        "data_val.drop([512], axis=1, inplace=True)\n",
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK7Q96RZtwZl"
      },
      "outputs": [],
      "source": [
        "X_train=data_train.values\n",
        "X_test=data_test.values\n",
        "X_val=data_val.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwfh9AwhjkMM",
        "outputId": "7dc9cce3-3ea9-4870-df4a-d2e5822ab9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14400, 512)\n",
            "(1800, 512)\n",
            "(1800, 512)\n",
            "(14400, 101)\n",
            "(1800, 101)\n",
            "(1800, 101)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50YyZlL9htW3",
        "outputId": "70844004-884e-4527-b8b4-48bdc4b6e534"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14400, 512, 1), (1800, 512, 1), (1800, 512, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\n",
        "X_train = X_train.reshape(14400, 512, 1)\n",
        "X_test = X_test.reshape(1800, 512, 1)\n",
        "X_val = X_val.reshape(1800, 512, 1)\n",
        "X_train.shape, X_test.shape, X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBnTIBCDGX94"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jbh5mP0GWh5",
        "outputId": "a4d01337-d52e-450c-d3db-df037ad476c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_12 (LSTM)              (None, 512, 150)          91200     \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 512, 50)           40200     \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 512, 50)           20200     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 25600)             0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 25600)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 101)               2585701   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,737,301\n",
            "Trainable params: 2,737,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Input, Embedding, GRU, LSTM, SimpleRNN, MaxPooling1D, GlobalMaxPool1D, CuDNNGRU\n",
        "from keras.layers import Dropout, Dense, Activation, Flatten, Conv1D, SpatialDropout1D\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=150, return_sequences=True, input_shape=(512,1)))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(101, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWixFuhvKbcz"
      },
      "source": [
        "## 모델학습/평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-UtiKqRQYVv",
        "outputId": "bae9a968-c7dc-4c29-c863-ab87823aafdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 11s 449ms/step - loss: 0.0098 - accuracy: 0.0105 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 6s 386ms/step - loss: 0.0098 - accuracy: 0.0110 - val_loss: 0.0098 - val_accuracy: 0.0139\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 6s 390ms/step - loss: 0.0098 - accuracy: 0.0113 - val_loss: 0.0098 - val_accuracy: 0.0128\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 6s 393ms/step - loss: 0.0098 - accuracy: 0.0099 - val_loss: 0.0098 - val_accuracy: 0.0111\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0112 - val_loss: 0.0098 - val_accuracy: 0.0094\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0098 - accuracy: 0.0110 - val_loss: 0.0098 - val_accuracy: 0.0061\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 0.0098 - accuracy: 0.0139 - val_loss: 0.0098 - val_accuracy: 0.0044\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 0.0098 - accuracy: 0.0142 - val_loss: 0.0098 - val_accuracy: 0.0089\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 6s 404ms/step - loss: 0.0098 - accuracy: 0.0203 - val_loss: 0.0098 - val_accuracy: 0.0144\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0098 - accuracy: 0.0250 - val_loss: 0.0098 - val_accuracy: 0.0167\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0098 - accuracy: 0.0383 - val_loss: 0.0098 - val_accuracy: 0.0333\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0097 - accuracy: 0.0544 - val_loss: 0.0098 - val_accuracy: 0.0367\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 6s 395ms/step - loss: 0.0097 - accuracy: 0.0698 - val_loss: 0.0098 - val_accuracy: 0.0533\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 6s 394ms/step - loss: 0.0096 - accuracy: 0.0924 - val_loss: 0.0097 - val_accuracy: 0.0706\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 6s 394ms/step - loss: 0.0095 - accuracy: 0.1191 - val_loss: 0.0097 - val_accuracy: 0.0822\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 6s 394ms/step - loss: 0.0094 - accuracy: 0.1294 - val_loss: 0.0096 - val_accuracy: 0.1017\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 6s 395ms/step - loss: 0.0092 - accuracy: 0.1707 - val_loss: 0.0096 - val_accuracy: 0.1289\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0090 - accuracy: 0.2003 - val_loss: 0.0095 - val_accuracy: 0.1439\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0089 - accuracy: 0.2245 - val_loss: 0.0094 - val_accuracy: 0.1600\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0087 - accuracy: 0.2482 - val_loss: 0.0094 - val_accuracy: 0.1756\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0085 - accuracy: 0.2699 - val_loss: 0.0092 - val_accuracy: 0.1917\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0083 - accuracy: 0.2903 - val_loss: 0.0090 - val_accuracy: 0.2233\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0081 - accuracy: 0.3176 - val_loss: 0.0090 - val_accuracy: 0.2350\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0079 - accuracy: 0.3405 - val_loss: 0.0088 - val_accuracy: 0.2444\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0077 - accuracy: 0.3606 - val_loss: 0.0087 - val_accuracy: 0.2744\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0075 - accuracy: 0.3854 - val_loss: 0.0087 - val_accuracy: 0.2789\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0072 - accuracy: 0.4178 - val_loss: 0.0086 - val_accuracy: 0.2944\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0071 - accuracy: 0.4251 - val_loss: 0.0083 - val_accuracy: 0.3250\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0068 - accuracy: 0.4522 - val_loss: 0.0079 - val_accuracy: 0.3628\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0064 - accuracy: 0.4943 - val_loss: 0.0076 - val_accuracy: 0.3906\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0061 - accuracy: 0.5235 - val_loss: 0.0075 - val_accuracy: 0.4167\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0058 - accuracy: 0.5449 - val_loss: 0.0072 - val_accuracy: 0.4411\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0055 - accuracy: 0.5776 - val_loss: 0.0071 - val_accuracy: 0.4550\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0052 - accuracy: 0.6033 - val_loss: 0.0069 - val_accuracy: 0.4650\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0050 - accuracy: 0.6226 - val_loss: 0.0069 - val_accuracy: 0.4672\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0047 - accuracy: 0.6433 - val_loss: 0.0063 - val_accuracy: 0.5233\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0043 - accuracy: 0.6737 - val_loss: 0.0063 - val_accuracy: 0.5256\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0042 - accuracy: 0.6845 - val_loss: 0.0056 - val_accuracy: 0.5783\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0038 - accuracy: 0.7096 - val_loss: 0.0054 - val_accuracy: 0.5933\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0037 - accuracy: 0.7191 - val_loss: 0.0052 - val_accuracy: 0.6133\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0035 - accuracy: 0.7350 - val_loss: 0.0053 - val_accuracy: 0.6139\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0033 - accuracy: 0.7502 - val_loss: 0.0050 - val_accuracy: 0.6300\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0031 - accuracy: 0.7684 - val_loss: 0.0048 - val_accuracy: 0.6467\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0029 - accuracy: 0.7860 - val_loss: 0.0045 - val_accuracy: 0.6733\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0028 - accuracy: 0.7946 - val_loss: 0.0049 - val_accuracy: 0.6411\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0027 - accuracy: 0.7985 - val_loss: 0.0050 - val_accuracy: 0.6356\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0029 - accuracy: 0.7905 - val_loss: 0.0043 - val_accuracy: 0.6911\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0025 - accuracy: 0.8149 - val_loss: 0.0042 - val_accuracy: 0.6972\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0023 - accuracy: 0.8286 - val_loss: 0.0041 - val_accuracy: 0.7056\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0022 - accuracy: 0.8371 - val_loss: 0.0039 - val_accuracy: 0.7200\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0021 - accuracy: 0.8427 - val_loss: 0.0039 - val_accuracy: 0.7189\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0021 - accuracy: 0.8492 - val_loss: 0.0037 - val_accuracy: 0.7383\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0020 - accuracy: 0.8566 - val_loss: 0.0042 - val_accuracy: 0.6950\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0022 - accuracy: 0.8456 - val_loss: 0.0036 - val_accuracy: 0.7417\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0018 - accuracy: 0.8710 - val_loss: 0.0035 - val_accuracy: 0.7567\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0019 - accuracy: 0.8666 - val_loss: 0.0034 - val_accuracy: 0.7639\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0018 - accuracy: 0.8678 - val_loss: 0.0039 - val_accuracy: 0.7283\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0018 - accuracy: 0.8685 - val_loss: 0.0033 - val_accuracy: 0.7672\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0017 - accuracy: 0.8790 - val_loss: 0.0031 - val_accuracy: 0.7828\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0015 - accuracy: 0.8897 - val_loss: 0.0029 - val_accuracy: 0.7917\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0014 - accuracy: 0.8972 - val_loss: 0.0029 - val_accuracy: 0.7994\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0013 - accuracy: 0.9038 - val_loss: 0.0027 - val_accuracy: 0.8106\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0012 - accuracy: 0.9103 - val_loss: 0.0026 - val_accuracy: 0.8139\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0011 - accuracy: 0.9142 - val_loss: 0.0026 - val_accuracy: 0.8172\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0010 - accuracy: 0.9180 - val_loss: 0.0025 - val_accuracy: 0.8250\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 9.8742e-04 - accuracy: 0.9211 - val_loss: 0.0024 - val_accuracy: 0.8339\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 9.5477e-04 - accuracy: 0.9235 - val_loss: 0.0024 - val_accuracy: 0.8300\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 8.8756e-04 - accuracy: 0.9283 - val_loss: 0.0022 - val_accuracy: 0.8411\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 8.3546e-04 - accuracy: 0.9328 - val_loss: 0.0023 - val_accuracy: 0.8422\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 8.2836e-04 - accuracy: 0.9344 - val_loss: 0.0024 - val_accuracy: 0.8333\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 8.1965e-04 - accuracy: 0.9369 - val_loss: 0.0023 - val_accuracy: 0.8394\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 7.6568e-04 - accuracy: 0.9401 - val_loss: 0.0022 - val_accuracy: 0.8483\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 7.2727e-04 - accuracy: 0.9421 - val_loss: 0.0022 - val_accuracy: 0.8500\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.9593e-04 - accuracy: 0.9453 - val_loss: 0.0021 - val_accuracy: 0.8522\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.8279e-04 - accuracy: 0.9467 - val_loss: 0.0022 - val_accuracy: 0.8500\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 7.0778e-04 - accuracy: 0.9463 - val_loss: 0.0024 - val_accuracy: 0.8328\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.8816e-04 - accuracy: 0.9471 - val_loss: 0.0021 - val_accuracy: 0.8561\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.4719e-04 - accuracy: 0.9486 - val_loss: 0.0021 - val_accuracy: 0.8556\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.2303e-04 - accuracy: 0.9501 - val_loss: 0.0021 - val_accuracy: 0.8589\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 6.0979e-04 - accuracy: 0.9515 - val_loss: 0.0021 - val_accuracy: 0.8611\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.8613e-04 - accuracy: 0.9533 - val_loss: 0.0021 - val_accuracy: 0.8544\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.6761e-04 - accuracy: 0.9548 - val_loss: 0.0020 - val_accuracy: 0.8639\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.5179e-04 - accuracy: 0.9563 - val_loss: 0.0022 - val_accuracy: 0.8528\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.0237e-04 - accuracy: 0.9541 - val_loss: 0.0020 - val_accuracy: 0.8611\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.3249e-04 - accuracy: 0.9527 - val_loss: 0.0021 - val_accuracy: 0.8650\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.7455e-04 - accuracy: 0.9554 - val_loss: 0.0021 - val_accuracy: 0.8539\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.8165e-04 - accuracy: 0.9550 - val_loss: 0.0021 - val_accuracy: 0.8533\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.5453e-04 - accuracy: 0.9572 - val_loss: 0.0019 - val_accuracy: 0.8678\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.3718e-04 - accuracy: 0.9583 - val_loss: 0.0021 - val_accuracy: 0.8567\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.0965e-04 - accuracy: 0.9601 - val_loss: 0.0020 - val_accuracy: 0.8606\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.1070e-04 - accuracy: 0.9603 - val_loss: 0.0024 - val_accuracy: 0.8339\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.1104e-04 - accuracy: 0.9606 - val_loss: 0.0020 - val_accuracy: 0.8700\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 4.7104e-04 - accuracy: 0.9631 - val_loss: 0.0019 - val_accuracy: 0.8706\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.5744e-04 - accuracy: 0.9640 - val_loss: 0.0018 - val_accuracy: 0.8728\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.5500e-04 - accuracy: 0.9640 - val_loss: 0.0020 - val_accuracy: 0.8628\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.3547e-04 - accuracy: 0.9601 - val_loss: 0.0020 - val_accuracy: 0.8628\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.7423e-04 - accuracy: 0.9576 - val_loss: 0.0023 - val_accuracy: 0.8461\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 6.6833e-04 - accuracy: 0.9524 - val_loss: 0.0029 - val_accuracy: 0.8006\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0010 - accuracy: 0.9287 - val_loss: 0.0035 - val_accuracy: 0.7683\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0015 - accuracy: 0.8988 - val_loss: 0.0030 - val_accuracy: 0.8050\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0013 - accuracy: 0.9156 - val_loss: 0.0027 - val_accuracy: 0.8228\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 9.5449e-04 - accuracy: 0.9353 - val_loss: 0.0026 - val_accuracy: 0.8322\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 7.6325e-04 - accuracy: 0.9483 - val_loss: 0.0022 - val_accuracy: 0.8572\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 7.1071e-04 - accuracy: 0.9510 - val_loss: 0.0022 - val_accuracy: 0.8506\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 6.0802e-04 - accuracy: 0.9576 - val_loss: 0.0025 - val_accuracy: 0.8278\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 8.5035e-04 - accuracy: 0.9421 - val_loss: 0.0023 - val_accuracy: 0.8467\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.7219e-04 - accuracy: 0.9592 - val_loss: 0.0020 - val_accuracy: 0.8683\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.8656e-04 - accuracy: 0.9583 - val_loss: 0.0022 - val_accuracy: 0.8556\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.0405e-04 - accuracy: 0.9631 - val_loss: 0.0018 - val_accuracy: 0.8800\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 5.4512e-04 - accuracy: 0.9610 - val_loss: 0.0020 - val_accuracy: 0.8672\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 5.2096e-04 - accuracy: 0.9625 - val_loss: 0.0021 - val_accuracy: 0.8589\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.7569e-04 - accuracy: 0.9647 - val_loss: 0.0019 - val_accuracy: 0.8717\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 4.2059e-04 - accuracy: 0.9672 - val_loss: 0.0019 - val_accuracy: 0.8767\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 3.9687e-04 - accuracy: 0.9683 - val_loss: 0.0017 - val_accuracy: 0.8844\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 3.8430e-04 - accuracy: 0.9693 - val_loss: 0.0018 - val_accuracy: 0.8839\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 3.6937e-04 - accuracy: 0.9703 - val_loss: 0.0017 - val_accuracy: 0.8850\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 3.6589e-04 - accuracy: 0.9706 - val_loss: 0.0017 - val_accuracy: 0.8833\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.5960e-04 - accuracy: 0.9709 - val_loss: 0.0018 - val_accuracy: 0.8794\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 3.8481e-04 - accuracy: 0.9700 - val_loss: 0.0018 - val_accuracy: 0.8839\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.8732e-04 - accuracy: 0.9706 - val_loss: 0.0018 - val_accuracy: 0.8794\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.5150e-04 - accuracy: 0.9723 - val_loss: 0.0017 - val_accuracy: 0.8889\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.2751e-04 - accuracy: 0.9739 - val_loss: 0.0016 - val_accuracy: 0.8928\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.0005e-04 - accuracy: 0.9752 - val_loss: 0.0017 - val_accuracy: 0.8872\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.0808e-04 - accuracy: 0.9753 - val_loss: 0.0017 - val_accuracy: 0.8872\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.8507e-04 - accuracy: 0.9766 - val_loss: 0.0016 - val_accuracy: 0.8917\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.7206e-04 - accuracy: 0.9774 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 6s 404ms/step - loss: 2.6566e-04 - accuracy: 0.9775 - val_loss: 0.0016 - val_accuracy: 0.8928\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.6200e-04 - accuracy: 0.9776 - val_loss: 0.0016 - val_accuracy: 0.8906\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.5787e-04 - accuracy: 0.9778 - val_loss: 0.0015 - val_accuracy: 0.8972\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.5201e-04 - accuracy: 0.9783 - val_loss: 0.0016 - val_accuracy: 0.8956\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.4231e-04 - accuracy: 0.9792 - val_loss: 0.0016 - val_accuracy: 0.8928\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.3662e-04 - accuracy: 0.9795 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.3570e-04 - accuracy: 0.9794 - val_loss: 0.0015 - val_accuracy: 0.8967\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.3487e-04 - accuracy: 0.9794 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.3268e-04 - accuracy: 0.9796 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.3355e-04 - accuracy: 0.9795 - val_loss: 0.0015 - val_accuracy: 0.9022\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.3110e-04 - accuracy: 0.9796 - val_loss: 0.0015 - val_accuracy: 0.9017\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.2925e-04 - accuracy: 0.9797 - val_loss: 0.0015 - val_accuracy: 0.9022\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.2808e-04 - accuracy: 0.9797 - val_loss: 0.0015 - val_accuracy: 0.8994\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.2727e-04 - accuracy: 0.9797 - val_loss: 0.0014 - val_accuracy: 0.9000\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.2673e-04 - accuracy: 0.9798 - val_loss: 0.0015 - val_accuracy: 0.9006\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.2526e-04 - accuracy: 0.9799 - val_loss: 0.0015 - val_accuracy: 0.8994\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.2387e-04 - accuracy: 0.9799 - val_loss: 0.0014 - val_accuracy: 0.9022\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.2315e-04 - accuracy: 0.9799 - val_loss: 0.0014 - val_accuracy: 0.9017\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.2108e-04 - accuracy: 0.9801 - val_loss: 0.0014 - val_accuracy: 0.9017\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.1862e-04 - accuracy: 0.9803 - val_loss: 0.0014 - val_accuracy: 0.9039\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.1718e-04 - accuracy: 0.9805 - val_loss: 0.0015 - val_accuracy: 0.9000\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.2675e-04 - accuracy: 0.9802 - val_loss: 0.0015 - val_accuracy: 0.9050\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 2.3546e-04 - accuracy: 0.9799 - val_loss: 0.0015 - val_accuracy: 0.8983\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.1843e-04 - accuracy: 0.9808 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 2.1055e-04 - accuracy: 0.9814 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.0253e-04 - accuracy: 0.9820 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.0826e-04 - accuracy: 0.9819 - val_loss: 0.0015 - val_accuracy: 0.9011\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.0748e-04 - accuracy: 0.9822 - val_loss: 0.0015 - val_accuracy: 0.8972\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.0307e-04 - accuracy: 0.9822 - val_loss: 0.0014 - val_accuracy: 0.9000\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9775e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9028\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9751e-04 - accuracy: 0.9825 - val_loss: 0.0013 - val_accuracy: 0.9072\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9500e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9493e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9411e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9420e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9412e-04 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 1.9453e-04 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9434e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9448e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9072\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9398e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9028\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9397e-04 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 0.9039\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9341e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9072\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9309e-04 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9307e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9264e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9170e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9117e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9155e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9135e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9303e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9039\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9189e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9115e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9100e-04 - accuracy: 0.9827 - val_loss: 0.0014 - val_accuracy: 0.9072\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9039e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.9084e-04 - accuracy: 0.9827 - val_loss: 0.0014 - val_accuracy: 0.9072\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9022e-04 - accuracy: 0.9828 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8878e-04 - accuracy: 0.9829 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8933e-04 - accuracy: 0.9828 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.8807e-04 - accuracy: 0.9829 - val_loss: 0.0014 - val_accuracy: 0.9072\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.8748e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.8645e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9111\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8590e-04 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 0.9044\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8546e-04 - accuracy: 0.9832 - val_loss: 0.0013 - val_accuracy: 0.9067\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8489e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9033\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.8443e-04 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8437e-04 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.8448e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.8440e-04 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8380e-04 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 0.9044\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.8343e-04 - accuracy: 0.9832 - val_loss: 0.0013 - val_accuracy: 0.9061\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8375e-04 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8462e-04 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 0.9028\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.8391e-04 - accuracy: 0.9832 - val_loss: 0.0014 - val_accuracy: 0.9044\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8359e-04 - accuracy: 0.9832 - val_loss: 0.0013 - val_accuracy: 0.9039\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8216e-04 - accuracy: 0.9833 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8153e-04 - accuracy: 0.9833 - val_loss: 0.0013 - val_accuracy: 0.9056\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7603e-04 - accuracy: 0.9844 - val_loss: 0.0014 - val_accuracy: 0.9028\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7109e-04 - accuracy: 0.9849 - val_loss: 0.0014 - val_accuracy: 0.9017\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.6520e-04 - accuracy: 0.9853 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.6579e-04 - accuracy: 0.9854 - val_loss: 0.0014 - val_accuracy: 0.9033\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.6400e-04 - accuracy: 0.9853 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.6450e-04 - accuracy: 0.9856 - val_loss: 0.0013 - val_accuracy: 0.9128\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.6056e-04 - accuracy: 0.9861 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5678e-04 - accuracy: 0.9860 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.6209e-04 - accuracy: 0.9860 - val_loss: 0.0014 - val_accuracy: 0.9072\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8237e-04 - accuracy: 0.9849 - val_loss: 0.0015 - val_accuracy: 0.8961\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 1.8781e-04 - accuracy: 0.9847 - val_loss: 0.0015 - val_accuracy: 0.9033\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.9616e-04 - accuracy: 0.9839 - val_loss: 0.0017 - val_accuracy: 0.8856\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.9450e-04 - accuracy: 0.9779 - val_loss: 0.0022 - val_accuracy: 0.8494\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.2665e-04 - accuracy: 0.9703 - val_loss: 0.0043 - val_accuracy: 0.7239\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0013 - accuracy: 0.9146 - val_loss: 0.0040 - val_accuracy: 0.7456\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0018 - accuracy: 0.8830 - val_loss: 0.0037 - val_accuracy: 0.7650\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0015 - accuracy: 0.9056 - val_loss: 0.0030 - val_accuracy: 0.8094\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 9.7518e-04 - accuracy: 0.9383 - val_loss: 0.0032 - val_accuracy: 0.7956\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0015 - accuracy: 0.9024 - val_loss: 0.0031 - val_accuracy: 0.8078\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0013 - accuracy: 0.9207 - val_loss: 0.0031 - val_accuracy: 0.8061\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0015 - accuracy: 0.9101 - val_loss: 0.0031 - val_accuracy: 0.8061\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 9.6621e-04 - accuracy: 0.9413 - val_loss: 0.0022 - val_accuracy: 0.8639\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 7.8960e-04 - accuracy: 0.9502 - val_loss: 0.0022 - val_accuracy: 0.8611\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.8637e-04 - accuracy: 0.9642 - val_loss: 0.0021 - val_accuracy: 0.8683\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.4744e-04 - accuracy: 0.9661 - val_loss: 0.0030 - val_accuracy: 0.8172\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.9694e-04 - accuracy: 0.9629 - val_loss: 0.0021 - val_accuracy: 0.8722\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.7843e-04 - accuracy: 0.9687 - val_loss: 0.0019 - val_accuracy: 0.8811\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.7215e-04 - accuracy: 0.9761 - val_loss: 0.0018 - val_accuracy: 0.8867\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.4664e-04 - accuracy: 0.9778 - val_loss: 0.0016 - val_accuracy: 0.9039\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.9796e-04 - accuracy: 0.9806 - val_loss: 0.0016 - val_accuracy: 0.8994\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.9465e-04 - accuracy: 0.9810 - val_loss: 0.0016 - val_accuracy: 0.8967\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.8398e-04 - accuracy: 0.9814 - val_loss: 0.0017 - val_accuracy: 0.8944\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.7010e-04 - accuracy: 0.9818 - val_loss: 0.0016 - val_accuracy: 0.9050\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.5618e-04 - accuracy: 0.9824 - val_loss: 0.0015 - val_accuracy: 0.9050\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.5269e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.4521e-04 - accuracy: 0.9828 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 2.4810e-04 - accuracy: 0.9828 - val_loss: 0.0014 - val_accuracy: 0.9094\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.4394e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9128\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.4847e-04 - accuracy: 0.9831 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 2.6038e-04 - accuracy: 0.9819 - val_loss: 0.0017 - val_accuracy: 0.8922\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.4716e-04 - accuracy: 0.9829 - val_loss: 0.0014 - val_accuracy: 0.9133\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.3519e-04 - accuracy: 0.9832 - val_loss: 0.0013 - val_accuracy: 0.9144\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.2419e-04 - accuracy: 0.9834 - val_loss: 0.0013 - val_accuracy: 0.9133\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 2.1823e-04 - accuracy: 0.9835 - val_loss: 0.0013 - val_accuracy: 0.9144\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.1896e-04 - accuracy: 0.9834 - val_loss: 0.0013 - val_accuracy: 0.9106\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 2.1665e-04 - accuracy: 0.9834 - val_loss: 0.0013 - val_accuracy: 0.9161\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.1596e-04 - accuracy: 0.9834 - val_loss: 0.0013 - val_accuracy: 0.9167\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.1447e-04 - accuracy: 0.9835 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.3055e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9133\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.2214e-04 - accuracy: 0.9834 - val_loss: 0.0014 - val_accuracy: 0.9139\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.3207e-04 - accuracy: 0.9826 - val_loss: 0.0015 - val_accuracy: 0.9028\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 2.3526e-04 - accuracy: 0.9826 - val_loss: 0.0013 - val_accuracy: 0.9172\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.3609e-04 - accuracy: 0.9824 - val_loss: 0.0020 - val_accuracy: 0.8717\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.4488e-04 - accuracy: 0.9763 - val_loss: 0.0015 - val_accuracy: 0.9044\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 2.6903e-04 - accuracy: 0.9809 - val_loss: 0.0016 - val_accuracy: 0.9017\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.4567e-04 - accuracy: 0.9826 - val_loss: 0.0017 - val_accuracy: 0.8922\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.5699e-04 - accuracy: 0.9824 - val_loss: 0.0018 - val_accuracy: 0.8844\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 3.7301e-04 - accuracy: 0.9751 - val_loss: 0.0028 - val_accuracy: 0.8261\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 5.9354e-04 - accuracy: 0.9607 - val_loss: 0.0022 - val_accuracy: 0.8611\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.7521e-04 - accuracy: 0.9622 - val_loss: 0.0021 - val_accuracy: 0.8650\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.8213e-04 - accuracy: 0.9747 - val_loss: 0.0017 - val_accuracy: 0.8900\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.8159e-04 - accuracy: 0.9808 - val_loss: 0.0016 - val_accuracy: 0.9017\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.0649e-04 - accuracy: 0.9734 - val_loss: 0.0019 - val_accuracy: 0.8761\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 3.3346e-04 - accuracy: 0.9785 - val_loss: 0.0016 - val_accuracy: 0.8939\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.8023e-04 - accuracy: 0.9810 - val_loss: 0.0015 - val_accuracy: 0.9072\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.4081e-04 - accuracy: 0.9829 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.1419e-04 - accuracy: 0.9847 - val_loss: 0.0015 - val_accuracy: 0.9056\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.0669e-04 - accuracy: 0.9848 - val_loss: 0.0014 - val_accuracy: 0.9122\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9649e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9128\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8974e-04 - accuracy: 0.9859 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8991e-04 - accuracy: 0.9859 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8685e-04 - accuracy: 0.9860 - val_loss: 0.0013 - val_accuracy: 0.9139\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8161e-04 - accuracy: 0.9861 - val_loss: 0.0014 - val_accuracy: 0.9117\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9063e-04 - accuracy: 0.9860 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8369e-04 - accuracy: 0.9861 - val_loss: 0.0014 - val_accuracy: 0.9139\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.7877e-04 - accuracy: 0.9863 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7581e-04 - accuracy: 0.9863 - val_loss: 0.0014 - val_accuracy: 0.9128\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.6877e-04 - accuracy: 0.9865 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.6525e-04 - accuracy: 0.9868 - val_loss: 0.0013 - val_accuracy: 0.9183\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.6684e-04 - accuracy: 0.9868 - val_loss: 0.0013 - val_accuracy: 0.9161\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.6302e-04 - accuracy: 0.9869 - val_loss: 0.0013 - val_accuracy: 0.9156\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5976e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9094\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.6003e-04 - accuracy: 0.9870 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7531e-04 - accuracy: 0.9864 - val_loss: 0.0015 - val_accuracy: 0.9017\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.8272e-04 - accuracy: 0.9861 - val_loss: 0.0015 - val_accuracy: 0.9006\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.7453e-04 - accuracy: 0.9867 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.7173e-04 - accuracy: 0.9868 - val_loss: 0.0013 - val_accuracy: 0.9161\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7000e-04 - accuracy: 0.9867 - val_loss: 0.0013 - val_accuracy: 0.9111\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.7850e-04 - accuracy: 0.9863 - val_loss: 0.0013 - val_accuracy: 0.9189\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7136e-04 - accuracy: 0.9868 - val_loss: 0.0013 - val_accuracy: 0.9144\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.6549e-04 - accuracy: 0.9870 - val_loss: 0.0013 - val_accuracy: 0.9206\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.6091e-04 - accuracy: 0.9871 - val_loss: 0.0012 - val_accuracy: 0.9183\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5874e-04 - accuracy: 0.9871 - val_loss: 0.0012 - val_accuracy: 0.9161\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5899e-04 - accuracy: 0.9871 - val_loss: 0.0012 - val_accuracy: 0.9167\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5851e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9122\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5761e-04 - accuracy: 0.9871 - val_loss: 0.0012 - val_accuracy: 0.9217\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5703e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9183\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.5584e-04 - accuracy: 0.9871 - val_loss: 0.0012 - val_accuracy: 0.9194\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.5594e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9167\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.5570e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9161\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5676e-04 - accuracy: 0.9871 - val_loss: 0.0012 - val_accuracy: 0.9172\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5607e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9150\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5457e-04 - accuracy: 0.9871 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5545e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9156\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5544e-04 - accuracy: 0.9871 - val_loss: 0.0012 - val_accuracy: 0.9200\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5546e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9161\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5549e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9122\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5618e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9178\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5516e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9183\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5512e-04 - accuracy: 0.9871 - val_loss: 0.0012 - val_accuracy: 0.9161\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.5586e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9150\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5568e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9150\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5805e-04 - accuracy: 0.9870 - val_loss: 0.0013 - val_accuracy: 0.9139\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5512e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9144\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5576e-04 - accuracy: 0.9871 - val_loss: 0.0013 - val_accuracy: 0.9172\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.5493e-04 - accuracy: 0.9872 - val_loss: 0.0013 - val_accuracy: 0.9150\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5510e-04 - accuracy: 0.9872 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5536e-04 - accuracy: 0.9872 - val_loss: 0.0013 - val_accuracy: 0.9144\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5436e-04 - accuracy: 0.9872 - val_loss: 0.0013 - val_accuracy: 0.9172\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5368e-04 - accuracy: 0.9872 - val_loss: 0.0012 - val_accuracy: 0.9183\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.5370e-04 - accuracy: 0.9872 - val_loss: 0.0012 - val_accuracy: 0.9172\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.5273e-04 - accuracy: 0.9872 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.5212e-04 - accuracy: 0.9873 - val_loss: 0.0013 - val_accuracy: 0.9172\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5079e-04 - accuracy: 0.9874 - val_loss: 0.0012 - val_accuracy: 0.9156\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5002e-04 - accuracy: 0.9875 - val_loss: 0.0013 - val_accuracy: 0.9128\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.4792e-04 - accuracy: 0.9876 - val_loss: 0.0013 - val_accuracy: 0.9111\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.4636e-04 - accuracy: 0.9878 - val_loss: 0.0013 - val_accuracy: 0.9111\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.4513e-04 - accuracy: 0.9878 - val_loss: 0.0013 - val_accuracy: 0.9178\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.4458e-04 - accuracy: 0.9878 - val_loss: 0.0013 - val_accuracy: 0.9167\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.4494e-04 - accuracy: 0.9878 - val_loss: 0.0013 - val_accuracy: 0.9183\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.4463e-04 - accuracy: 0.9878 - val_loss: 0.0013 - val_accuracy: 0.9167\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.4407e-04 - accuracy: 0.9878 - val_loss: 0.0012 - val_accuracy: 0.9156\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.4370e-04 - accuracy: 0.9878 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.4390e-04 - accuracy: 0.9878 - val_loss: 0.0012 - val_accuracy: 0.9150\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.4633e-04 - accuracy: 0.9877 - val_loss: 0.0014 - val_accuracy: 0.9161\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.4480e-04 - accuracy: 0.9878 - val_loss: 0.0013 - val_accuracy: 0.9122\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 6s 405ms/step - loss: 1.4360e-04 - accuracy: 0.9879 - val_loss: 0.0012 - val_accuracy: 0.9183\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.4313e-04 - accuracy: 0.9878 - val_loss: 0.0013 - val_accuracy: 0.9100\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.4375e-04 - accuracy: 0.9879 - val_loss: 0.0013 - val_accuracy: 0.9133\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.4314e-04 - accuracy: 0.9881 - val_loss: 0.0014 - val_accuracy: 0.9128\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.4203e-04 - accuracy: 0.9881 - val_loss: 0.0012 - val_accuracy: 0.9150\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.4021e-04 - accuracy: 0.9882 - val_loss: 0.0013 - val_accuracy: 0.9161\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3874e-04 - accuracy: 0.9883 - val_loss: 0.0012 - val_accuracy: 0.9150\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3777e-04 - accuracy: 0.9883 - val_loss: 0.0012 - val_accuracy: 0.9161\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3777e-04 - accuracy: 0.9882 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3669e-04 - accuracy: 0.9883 - val_loss: 0.0012 - val_accuracy: 0.9183\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3502e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9150\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3787e-04 - accuracy: 0.9883 - val_loss: 0.0012 - val_accuracy: 0.9194\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.4736e-04 - accuracy: 0.9879 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.4553e-04 - accuracy: 0.9878 - val_loss: 0.0012 - val_accuracy: 0.9194\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.4209e-04 - accuracy: 0.9883 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3964e-04 - accuracy: 0.9883 - val_loss: 0.0013 - val_accuracy: 0.9183\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3836e-04 - accuracy: 0.9883 - val_loss: 0.0012 - val_accuracy: 0.9183\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3931e-04 - accuracy: 0.9883 - val_loss: 0.0013 - val_accuracy: 0.9144\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3789e-04 - accuracy: 0.9883 - val_loss: 0.0012 - val_accuracy: 0.9172\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3603e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3558e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9161\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3506e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9200\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3545e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9167\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3521e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9200\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.3548e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9161\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3461e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9150\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3455e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9200\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3436e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3385e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9194\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3409e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9211\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3433e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9217\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3409e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9217\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3423e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9239\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3389e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9211\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3418e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9222\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3353e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9211\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3330e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3389e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9250\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3411e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9222\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3359e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9233\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3365e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9228\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3388e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9206\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3398e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9206\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3368e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9194\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3371e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9206\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3351e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9194\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3349e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9172\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3381e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3420e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3380e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9194\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3336e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9211\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3395e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9217\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3343e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9183\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3314e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9194\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3387e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9194\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3373e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9172\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.3331e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9178\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3344e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9200\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3360e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9228\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3374e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9222\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3398e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9206\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3392e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9206\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3350e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9233\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3340e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9217\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3337e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9217\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3322e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9194\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3292e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9211\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3329e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9222\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3302e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9172\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3317e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9178\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3356e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9206\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3392e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9217\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3368e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9217\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3380e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9217\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3370e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9239\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.3390e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9211\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3422e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9211\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3453e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9244\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3448e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9256\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3363e-04 - accuracy: 0.9884 - val_loss: 0.0011 - val_accuracy: 0.9244\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3367e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9206\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3347e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9228\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3359e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9200\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3381e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9211\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3338e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9217\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3376e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9211\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3351e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9206\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.3439e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3415e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9200\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3423e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9206\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3392e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9172\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3366e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9200\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3524e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9200\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3363e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9233\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3345e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9222\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3333e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9206\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3391e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9206\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3506e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9183\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3414e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9200\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3409e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9200\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.3462e-04 - accuracy: 0.9884 - val_loss: 0.0012 - val_accuracy: 0.9194\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.3641e-04 - accuracy: 0.9883 - val_loss: 0.0015 - val_accuracy: 0.9011\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.5204e-04 - accuracy: 0.9760 - val_loss: 0.0070 - val_accuracy: 0.5611\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0040 - accuracy: 0.7527 - val_loss: 0.0082 - val_accuracy: 0.5111\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0035 - accuracy: 0.7902 - val_loss: 0.0047 - val_accuracy: 0.7183\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0020 - accuracy: 0.8787 - val_loss: 0.0042 - val_accuracy: 0.7561\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0018 - accuracy: 0.8924 - val_loss: 0.0029 - val_accuracy: 0.8283\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0012 - accuracy: 0.9263 - val_loss: 0.0026 - val_accuracy: 0.8467\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 9.7540e-04 - accuracy: 0.9410 - val_loss: 0.0024 - val_accuracy: 0.8567\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 7.7390e-04 - accuracy: 0.9529 - val_loss: 0.0021 - val_accuracy: 0.8722\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.8946e-04 - accuracy: 0.9693 - val_loss: 0.0019 - val_accuracy: 0.8883\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.0265e-04 - accuracy: 0.9747 - val_loss: 0.0020 - val_accuracy: 0.8756\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.1015e-04 - accuracy: 0.9803 - val_loss: 0.0017 - val_accuracy: 0.8944\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.5836e-04 - accuracy: 0.9835 - val_loss: 0.0020 - val_accuracy: 0.8794\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.8259e-04 - accuracy: 0.9626 - val_loss: 0.0018 - val_accuracy: 0.8917\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.0206e-04 - accuracy: 0.9748 - val_loss: 0.0018 - val_accuracy: 0.8939\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.2072e-04 - accuracy: 0.9799 - val_loss: 0.0018 - val_accuracy: 0.8894\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.5990e-04 - accuracy: 0.9835 - val_loss: 0.0019 - val_accuracy: 0.8833\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.6379e-04 - accuracy: 0.9707 - val_loss: 0.0019 - val_accuracy: 0.8822\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.9878e-04 - accuracy: 0.9810 - val_loss: 0.0018 - val_accuracy: 0.8950\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.7421e-04 - accuracy: 0.9837 - val_loss: 0.0018 - val_accuracy: 0.8933\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.5990e-04 - accuracy: 0.9717 - val_loss: 0.0020 - val_accuracy: 0.8806\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.2129e-04 - accuracy: 0.9804 - val_loss: 0.0017 - val_accuracy: 0.9028\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.6301e-04 - accuracy: 0.9842 - val_loss: 0.0014 - val_accuracy: 0.9150\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 2.0661e-04 - accuracy: 0.9868 - val_loss: 0.0014 - val_accuracy: 0.9139\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 1.9330e-04 - accuracy: 0.9871 - val_loss: 0.0014 - val_accuracy: 0.9161\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.9317e-04 - accuracy: 0.9874 - val_loss: 0.0013 - val_accuracy: 0.9194\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.8212e-04 - accuracy: 0.9881 - val_loss: 0.0013 - val_accuracy: 0.9233\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9699e-04 - accuracy: 0.9877 - val_loss: 0.0014 - val_accuracy: 0.9167\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8564e-04 - accuracy: 0.9880 - val_loss: 0.0013 - val_accuracy: 0.9172\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.7193e-04 - accuracy: 0.9881 - val_loss: 0.0013 - val_accuracy: 0.9189\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7173e-04 - accuracy: 0.9879 - val_loss: 0.0015 - val_accuracy: 0.9106\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.6590e-04 - accuracy: 0.9881 - val_loss: 0.0015 - val_accuracy: 0.9061\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.6626e-04 - accuracy: 0.9823 - val_loss: 0.0016 - val_accuracy: 0.9044\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.0779e-04 - accuracy: 0.9862 - val_loss: 0.0015 - val_accuracy: 0.9072\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.9910e-04 - accuracy: 0.9866 - val_loss: 0.0014 - val_accuracy: 0.9128\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8606e-04 - accuracy: 0.9872 - val_loss: 0.0015 - val_accuracy: 0.9106\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8005e-04 - accuracy: 0.9876 - val_loss: 0.0014 - val_accuracy: 0.9133\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.7324e-04 - accuracy: 0.9878 - val_loss: 0.0014 - val_accuracy: 0.9144\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.6783e-04 - accuracy: 0.9879 - val_loss: 0.0013 - val_accuracy: 0.9161\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.6238e-04 - accuracy: 0.9879 - val_loss: 0.0013 - val_accuracy: 0.9183\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.5938e-04 - accuracy: 0.9880 - val_loss: 0.0013 - val_accuracy: 0.9183\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.5711e-04 - accuracy: 0.9880 - val_loss: 0.0012 - val_accuracy: 0.9189\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5449e-04 - accuracy: 0.9881 - val_loss: 0.0013 - val_accuracy: 0.9183\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.5230e-04 - accuracy: 0.9881 - val_loss: 0.0013 - val_accuracy: 0.9133\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5094e-04 - accuracy: 0.9881 - val_loss: 0.0013 - val_accuracy: 0.9128\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5146e-04 - accuracy: 0.9881 - val_loss: 0.0014 - val_accuracy: 0.9122\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5784e-04 - accuracy: 0.9881 - val_loss: 0.0014 - val_accuracy: 0.9128\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5632e-04 - accuracy: 0.9883 - val_loss: 0.0013 - val_accuracy: 0.9178\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5522e-04 - accuracy: 0.9882 - val_loss: 0.0013 - val_accuracy: 0.9189\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.5379e-04 - accuracy: 0.9883 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.5146e-04 - accuracy: 0.9883 - val_loss: 0.0013 - val_accuracy: 0.9117\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5718e-04 - accuracy: 0.9881 - val_loss: 0.0013 - val_accuracy: 0.9167\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.5179e-04 - accuracy: 0.9883 - val_loss: 0.0013 - val_accuracy: 0.9133\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.4990e-04 - accuracy: 0.9883 - val_loss: 0.0014 - val_accuracy: 0.9133\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5149e-04 - accuracy: 0.9882 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.5151e-04 - accuracy: 0.9883 - val_loss: 0.0015 - val_accuracy: 0.9067\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.5022e-04 - accuracy: 0.9883 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.4862e-04 - accuracy: 0.9883 - val_loss: 0.0013 - val_accuracy: 0.9117\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.4735e-04 - accuracy: 0.9883 - val_loss: 0.0013 - val_accuracy: 0.9156\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.4613e-04 - accuracy: 0.9883 - val_loss: 0.0013 - val_accuracy: 0.9139\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 1.4577e-04 - accuracy: 0.9883 - val_loss: 0.0013 - val_accuracy: 0.9144\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, batch_size =1024, epochs = 500, verbose = 1, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVvegAfYQjT2",
        "outputId": "0f820cee-968e-45e9-b0af-df0683f80ad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 1s 22ms/step - loss: 0.0014 - accuracy: 0.9094\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0014196085976436734, 0.9094444513320923]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QUI82zYxY17r"
      },
      "outputs": [],
      "source": [
        "model.save('lstm_bandpass_2s.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLvm3XtMKYKg"
      },
      "source": [
        "## 그래프 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "7YRFsECl7Qp0",
        "outputId": "941e5b91-b95e-45a0-f5b1-5d9bceed04a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0f22537460>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "history=history.history\n",
        "epochs = range(1, len(history['loss']) + 1)\n",
        "acc = history['accuracy']\n",
        "loss = history['loss']\n",
        "val_acc = history['val_accuracy']\n",
        "val_loss = history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(epochs, acc, label='accuracy')\n",
        "plt.plot(epochs, val_acc, label='val_acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(epochs, loss, label='loss', color='g')\n",
        "plt.plot(epochs, val_loss, label='val_loss', color='r')\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7id_mnNKhHg"
      },
      "source": [
        "## 예측해보기(predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델을 잊어버리고 저장을 안해놔서 해당 모델 예측해보기는 못했습니다."
      ],
      "metadata": {
        "id": "7umHbGV7Ho6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKnoTLlLBPPN",
        "outputId": "8e06685b-4c91-4d7b-804a-f36f83b0daf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "188/188 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[44,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0, 57,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0, 65, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 68,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0, 67,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0, 57]])"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8EWDyMdHpWR",
        "outputId": "348ddc8c-b4b0-4b45-9b9b-a83b87cbce28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       59.0\n",
              "1       68.0\n",
              "2       72.0\n",
              "3        2.0\n",
              "4       57.0\n",
              "        ... \n",
              "5995     3.0\n",
              "5996    87.0\n",
              "5997    40.0\n",
              "5998    68.0\n",
              "5999    37.0\n",
              "Name: y_test, Length: 6000, dtype: float64"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_p=pd.DataFrame(y_test)\n",
        "\n",
        "for i in range(1,101):\n",
        "  y_test_p.loc[y_test_p[i] == 1.0 , 'y_test'] = i  \n",
        "y_test_p.y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "lI3myxchcv-Q",
        "outputId": "22f2ac13-d7ce-409c-db36-bf92c9ca0cad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>87.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         0\n",
              "0     59.0\n",
              "1     68.0\n",
              "2     72.0\n",
              "3      2.0\n",
              "4     57.0\n",
              "...    ...\n",
              "5995   3.0\n",
              "5996  87.0\n",
              "5997  40.0\n",
              "5998  68.0\n",
              "5999  45.0\n",
              "\n",
              "[6000 rows x 1 columns]"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex=np.argmax(y_pred, axis=1)\n",
        "ex=ex.astype('float64')\n",
        "ex=pd.DataFrame(ex)\n",
        "ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSPb21Y4eMAm"
      },
      "outputs": [],
      "source": [
        "ch1 = pd.DataFrame(np.rint(y_pred))\n",
        "ch1['pred'] = ex\n",
        "data_test.reset_index(inplace=True, drop=True)\n",
        "predict = pd.concat([data_test,ch1['pred'], y_test_p['y_test']],axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhe54j6XJzhy"
      },
      "outputs": [],
      "source": [
        "predict['compare'] = np.where(predict['pred']==predict['y_test'],'yes', 'no')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "mdgfuEehKIXX",
        "outputId": "833df983-0f21-460a-de46-668f491d18e1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-22dffb56-3200-49eb-89c1-97f537806f07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>pred</th>\n",
              "      <th>y_test</th>\n",
              "      <th>compare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.001909</td>\n",
              "      <td>0.008317</td>\n",
              "      <td>0.014489</td>\n",
              "      <td>0.020412</td>\n",
              "      <td>0.025995</td>\n",
              "      <td>0.031137</td>\n",
              "      <td>0.035801</td>\n",
              "      <td>0.040075</td>\n",
              "      <td>0.044195</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044631</td>\n",
              "      <td>0.050399</td>\n",
              "      <td>0.057432</td>\n",
              "      <td>0.066046</td>\n",
              "      <td>0.076371</td>\n",
              "      <td>0.088327</td>\n",
              "      <td>0.101648</td>\n",
              "      <td>85.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.096114</td>\n",
              "      <td>0.095362</td>\n",
              "      <td>0.095047</td>\n",
              "      <td>0.095447</td>\n",
              "      <td>0.096676</td>\n",
              "      <td>0.098677</td>\n",
              "      <td>0.101247</td>\n",
              "      <td>0.104083</td>\n",
              "      <td>0.106844</td>\n",
              "      <td>0.109202</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004398</td>\n",
              "      <td>-0.008214</td>\n",
              "      <td>-0.013081</td>\n",
              "      <td>-0.019006</td>\n",
              "      <td>-0.025674</td>\n",
              "      <td>-0.032320</td>\n",
              "      <td>-0.037693</td>\n",
              "      <td>83.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>-0.041972</td>\n",
              "      <td>-0.048778</td>\n",
              "      <td>-0.055266</td>\n",
              "      <td>-0.061636</td>\n",
              "      <td>-0.067728</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.076978</td>\n",
              "      <td>-0.078796</td>\n",
              "      <td>-0.078050</td>\n",
              "      <td>-0.074630</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.102289</td>\n",
              "      <td>-0.108650</td>\n",
              "      <td>-0.114708</td>\n",
              "      <td>-0.119718</td>\n",
              "      <td>-0.122885</td>\n",
              "      <td>-0.123496</td>\n",
              "      <td>-0.121095</td>\n",
              "      <td>20.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.050686</td>\n",
              "      <td>0.056807</td>\n",
              "      <td>0.061922</td>\n",
              "      <td>0.066330</td>\n",
              "      <td>0.070463</td>\n",
              "      <td>0.074831</td>\n",
              "      <td>0.079964</td>\n",
              "      <td>0.086349</td>\n",
              "      <td>0.094365</td>\n",
              "      <td>0.104239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.125449</td>\n",
              "      <td>0.136371</td>\n",
              "      <td>0.147691</td>\n",
              "      <td>0.159697</td>\n",
              "      <td>0.172642</td>\n",
              "      <td>0.186692</td>\n",
              "      <td>0.201860</td>\n",
              "      <td>41.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>-0.511413</td>\n",
              "      <td>-0.507140</td>\n",
              "      <td>-0.469849</td>\n",
              "      <td>-0.408462</td>\n",
              "      <td>-0.333769</td>\n",
              "      <td>-0.256404</td>\n",
              "      <td>-0.185178</td>\n",
              "      <td>-0.126038</td>\n",
              "      <td>-0.081724</td>\n",
              "      <td>-0.052058</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031533</td>\n",
              "      <td>0.034874</td>\n",
              "      <td>0.038518</td>\n",
              "      <td>0.042180</td>\n",
              "      <td>0.045745</td>\n",
              "      <td>0.049241</td>\n",
              "      <td>0.052764</td>\n",
              "      <td>4.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>0.005315</td>\n",
              "      <td>-0.043084</td>\n",
              "      <td>-0.083200</td>\n",
              "      <td>-0.110473</td>\n",
              "      <td>-0.122973</td>\n",
              "      <td>-0.121490</td>\n",
              "      <td>-0.109050</td>\n",
              "      <td>-0.090022</td>\n",
              "      <td>-0.069069</td>\n",
              "      <td>-0.050204</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.027012</td>\n",
              "      <td>-0.029614</td>\n",
              "      <td>-0.031356</td>\n",
              "      <td>-0.033020</td>\n",
              "      <td>-0.035244</td>\n",
              "      <td>-0.038329</td>\n",
              "      <td>-0.042129</td>\n",
              "      <td>95.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5981</th>\n",
              "      <td>-0.005281</td>\n",
              "      <td>-0.018280</td>\n",
              "      <td>-0.031669</td>\n",
              "      <td>-0.042939</td>\n",
              "      <td>-0.050464</td>\n",
              "      <td>-0.053648</td>\n",
              "      <td>-0.052817</td>\n",
              "      <td>-0.048958</td>\n",
              "      <td>-0.043371</td>\n",
              "      <td>-0.037307</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016826</td>\n",
              "      <td>-0.013496</td>\n",
              "      <td>-0.011275</td>\n",
              "      <td>-0.010594</td>\n",
              "      <td>-0.011830</td>\n",
              "      <td>-0.015208</td>\n",
              "      <td>-0.020697</td>\n",
              "      <td>52.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5992</th>\n",
              "      <td>-0.084734</td>\n",
              "      <td>-0.091664</td>\n",
              "      <td>-0.098196</td>\n",
              "      <td>-0.101411</td>\n",
              "      <td>-0.098148</td>\n",
              "      <td>-0.085744</td>\n",
              "      <td>-0.062829</td>\n",
              "      <td>-0.030004</td>\n",
              "      <td>0.009808</td>\n",
              "      <td>0.051498</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072150</td>\n",
              "      <td>0.081214</td>\n",
              "      <td>0.090895</td>\n",
              "      <td>0.101388</td>\n",
              "      <td>0.112932</td>\n",
              "      <td>0.125713</td>\n",
              "      <td>0.139775</td>\n",
              "      <td>100.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5994</th>\n",
              "      <td>0.008461</td>\n",
              "      <td>0.011468</td>\n",
              "      <td>0.012707</td>\n",
              "      <td>0.012096</td>\n",
              "      <td>0.009875</td>\n",
              "      <td>0.006558</td>\n",
              "      <td>0.002841</td>\n",
              "      <td>-0.000513</td>\n",
              "      <td>-0.002782</td>\n",
              "      <td>-0.003375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.048723</td>\n",
              "      <td>-0.051678</td>\n",
              "      <td>-0.052151</td>\n",
              "      <td>-0.050205</td>\n",
              "      <td>-0.046318</td>\n",
              "      <td>-0.041326</td>\n",
              "      <td>-0.036264</td>\n",
              "      <td>95.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>0.052145</td>\n",
              "      <td>0.038833</td>\n",
              "      <td>0.024907</td>\n",
              "      <td>0.010402</td>\n",
              "      <td>-0.004429</td>\n",
              "      <td>-0.019087</td>\n",
              "      <td>-0.032867</td>\n",
              "      <td>-0.044991</td>\n",
              "      <td>-0.054774</td>\n",
              "      <td>-0.061789</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.056943</td>\n",
              "      <td>-0.054300</td>\n",
              "      <td>-0.054324</td>\n",
              "      <td>-0.058068</td>\n",
              "      <td>-0.065599</td>\n",
              "      <td>-0.075635</td>\n",
              "      <td>-0.085448</td>\n",
              "      <td>45.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>545 rows × 259 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22dffb56-3200-49eb-89c1-97f537806f07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22dffb56-3200-49eb-89c1-97f537806f07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22dffb56-3200-49eb-89c1-97f537806f07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "30    0.001909  0.008317  0.014489  0.020412  0.025995  0.031137  0.035801   \n",
              "46    0.096114  0.095362  0.095047  0.095447  0.096676  0.098677  0.101247   \n",
              "54   -0.041972 -0.048778 -0.055266 -0.061636 -0.067728 -0.073065 -0.076978   \n",
              "55    0.050686  0.056807  0.061922  0.066330  0.070463  0.074831  0.079964   \n",
              "71   -0.511413 -0.507140 -0.469849 -0.408462 -0.333769 -0.256404 -0.185178   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5971  0.005315 -0.043084 -0.083200 -0.110473 -0.122973 -0.121490 -0.109050   \n",
              "5981 -0.005281 -0.018280 -0.031669 -0.042939 -0.050464 -0.053648 -0.052817   \n",
              "5992 -0.084734 -0.091664 -0.098196 -0.101411 -0.098148 -0.085744 -0.062829   \n",
              "5994  0.008461  0.011468  0.012707  0.012096  0.009875  0.006558  0.002841   \n",
              "5999  0.052145  0.038833  0.024907  0.010402 -0.004429 -0.019087 -0.032867   \n",
              "\n",
              "             7         8         9  ...       249       250       251  \\\n",
              "30    0.040075  0.044195  0.048538  ...  0.044631  0.050399  0.057432   \n",
              "46    0.104083  0.106844  0.109202  ... -0.004398 -0.008214 -0.013081   \n",
              "54   -0.078796 -0.078050 -0.074630  ... -0.102289 -0.108650 -0.114708   \n",
              "55    0.086349  0.094365  0.104239  ...  0.125449  0.136371  0.147691   \n",
              "71   -0.126038 -0.081724 -0.052058  ...  0.031533  0.034874  0.038518   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5971 -0.090022 -0.069069 -0.050204  ... -0.027012 -0.029614 -0.031356   \n",
              "5981 -0.048958 -0.043371 -0.037307  ... -0.016826 -0.013496 -0.011275   \n",
              "5992 -0.030004  0.009808  0.051498  ...  0.072150  0.081214  0.090895   \n",
              "5994 -0.000513 -0.002782 -0.003375  ... -0.048723 -0.051678 -0.052151   \n",
              "5999 -0.044991 -0.054774 -0.061789  ... -0.056943 -0.054300 -0.054324   \n",
              "\n",
              "           252       253       254       255   pred  y_test  compare  \n",
              "30    0.066046  0.076371  0.088327  0.101648   85.0    36.0       no  \n",
              "46   -0.019006 -0.025674 -0.032320 -0.037693   83.0    80.0       no  \n",
              "54   -0.119718 -0.122885 -0.123496 -0.121095   20.0    71.0       no  \n",
              "55    0.159697  0.172642  0.186692  0.201860   41.0    50.0       no  \n",
              "71    0.042180  0.045745  0.049241  0.052764    4.0    93.0       no  \n",
              "...        ...       ...       ...       ...    ...     ...      ...  \n",
              "5971 -0.033020 -0.035244 -0.038329 -0.042129   95.0    23.0       no  \n",
              "5981 -0.010594 -0.011830 -0.015208 -0.020697   52.0    40.0       no  \n",
              "5992  0.101388  0.112932  0.125713  0.139775  100.0    83.0       no  \n",
              "5994 -0.050205 -0.046318 -0.041326 -0.036264   95.0    49.0       no  \n",
              "5999 -0.058068 -0.065599 -0.075635 -0.085448   45.0    37.0       no  \n",
              "\n",
              "[545 rows x 259 columns]"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_1 = predict[predict[\"compare\"]=='no']\n",
        "predict_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lghovm--XQw8"
      },
      "source": [
        "# 2.highpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqgt0YGaXQw9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import itertools\n",
        "import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import (CosineAnnealingLR,\n",
        "                                      CosineAnnealingWarmRestarts,\n",
        "                                      StepLR,\n",
        "                                      ExponentialLR)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, auc, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkszYRwkXQw9"
      },
      "outputs": [],
      "source": [
        "import tqdm, re, sys\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7yxW8Q8XQw9"
      },
      "outputs": [],
      "source": [
        "data_total = pd.read_csv('/content/drive/MyDrive/model_2s/total_high.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "4i2gD7zKXQw9",
        "outputId": "bb8370b5-3260-40ab-8822-c1ef22a24419"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "0     -0.011566  0.077466  0.083038  0.015121 -0.024216  0.026618  0.112943   \n",
              "1     -0.124635 -0.101820 -0.004986 -0.009573 -0.097080 -0.078287 -0.033934   \n",
              "2     -0.088677 -0.125790 -0.030982  0.007508 -0.029261 -0.106478 -0.080494   \n",
              "3      0.164484  0.137004  0.165505  0.176745  0.186086  0.149056  0.190527   \n",
              "4      0.152732  0.074585 -0.013711 -0.034827 -0.023673 -0.104258 -0.139073   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "17995 -0.076292 -0.111654 -0.075956 -0.069888 -0.045250 -0.063222 -0.042144   \n",
              "17996 -0.048497 -0.030079 -0.042822 -0.063725 -0.028908 -0.011291 -0.015405   \n",
              "17997 -0.017653  0.005880 -0.008398 -0.053956 -0.045114 -0.050892 -0.014791   \n",
              "17998 -0.091136 -0.072359 -0.082491 -0.096773 -0.108624 -0.106044 -0.096813   \n",
              "17999 -0.040551 -0.032769 -0.024399 -0.043038 -0.040068 -0.059028 -0.083389   \n",
              "\n",
              "            7         8         9    ...       503       504       505  \\\n",
              "0      0.067018 -0.022367  0.035899  ... -0.102607 -0.121740 -0.038993   \n",
              "1      0.011788 -0.100740 -0.105788  ... -0.074093 -0.113909 -0.113364   \n",
              "2     -0.011038 -0.021531 -0.121852  ...  0.090296 -0.007490 -0.026310   \n",
              "3      0.256168  0.278809  0.242770  ...  0.391745  0.360085  0.331456   \n",
              "4     -0.163288 -0.166813 -0.192017  ... -0.089275 -0.098827 -0.167260   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "17995 -0.062486 -0.043508 -0.019340  ... -0.062754  0.002815 -0.032905   \n",
              "17996 -0.037688 -0.033962 -0.027736  ... -0.019348 -0.078060 -0.082112   \n",
              "17997 -0.025570 -0.044989 -0.027848  ... -0.057440 -0.065800 -0.044000   \n",
              "17998 -0.094621 -0.049099 -0.103425  ... -0.064874 -0.019088 -0.028823   \n",
              "17999 -0.066660 -0.039522 -0.092334  ...  0.115293  0.154681  0.142378   \n",
              "\n",
              "            506       507       508       509       510       511    512  \n",
              "0     -0.017367 -0.083201 -0.108995 -0.055099  0.004076 -0.050829    1.0  \n",
              "1     -0.053677 -0.015389 -0.088530 -0.122749 -0.019986 -0.033522    1.0  \n",
              "2      0.053336  0.110380  0.044460 -0.027323  0.009700  0.105980    1.0  \n",
              "3      0.324828  0.310089  0.291611  0.224983  0.176666  0.166279    1.0  \n",
              "4     -0.194723 -0.183527 -0.151331 -0.188605 -0.218650 -0.179596    1.0  \n",
              "...         ...       ...       ...       ...       ...       ...    ...  \n",
              "17995 -0.016336 -0.045078  0.004621 -0.020431  0.005698 -0.048605  100.0  \n",
              "17996 -0.081604 -0.070175 -0.080676 -0.072666  0.004694 -0.046835  100.0  \n",
              "17997 -0.082399 -0.083447 -0.065335 -0.088911 -0.080017 -0.076062  100.0  \n",
              "17998 -0.049239 -0.026504 -0.037821 -0.061718 -0.066845 -0.059923  100.0  \n",
              "17999  0.226287  0.199556  0.225905  0.209185  0.220656  0.204857  100.0  \n",
              "\n",
              "[18000 rows x 513 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-752d76d2-dd9c-405f-8a6c-37e9b18e556b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.011566</td>\n",
              "      <td>0.077466</td>\n",
              "      <td>0.083038</td>\n",
              "      <td>0.015121</td>\n",
              "      <td>-0.024216</td>\n",
              "      <td>0.026618</td>\n",
              "      <td>0.112943</td>\n",
              "      <td>0.067018</td>\n",
              "      <td>-0.022367</td>\n",
              "      <td>0.035899</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.102607</td>\n",
              "      <td>-0.121740</td>\n",
              "      <td>-0.038993</td>\n",
              "      <td>-0.017367</td>\n",
              "      <td>-0.083201</td>\n",
              "      <td>-0.108995</td>\n",
              "      <td>-0.055099</td>\n",
              "      <td>0.004076</td>\n",
              "      <td>-0.050829</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.124635</td>\n",
              "      <td>-0.101820</td>\n",
              "      <td>-0.004986</td>\n",
              "      <td>-0.009573</td>\n",
              "      <td>-0.097080</td>\n",
              "      <td>-0.078287</td>\n",
              "      <td>-0.033934</td>\n",
              "      <td>0.011788</td>\n",
              "      <td>-0.100740</td>\n",
              "      <td>-0.105788</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.074093</td>\n",
              "      <td>-0.113909</td>\n",
              "      <td>-0.113364</td>\n",
              "      <td>-0.053677</td>\n",
              "      <td>-0.015389</td>\n",
              "      <td>-0.088530</td>\n",
              "      <td>-0.122749</td>\n",
              "      <td>-0.019986</td>\n",
              "      <td>-0.033522</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.088677</td>\n",
              "      <td>-0.125790</td>\n",
              "      <td>-0.030982</td>\n",
              "      <td>0.007508</td>\n",
              "      <td>-0.029261</td>\n",
              "      <td>-0.106478</td>\n",
              "      <td>-0.080494</td>\n",
              "      <td>-0.011038</td>\n",
              "      <td>-0.021531</td>\n",
              "      <td>-0.121852</td>\n",
              "      <td>...</td>\n",
              "      <td>0.090296</td>\n",
              "      <td>-0.007490</td>\n",
              "      <td>-0.026310</td>\n",
              "      <td>0.053336</td>\n",
              "      <td>0.110380</td>\n",
              "      <td>0.044460</td>\n",
              "      <td>-0.027323</td>\n",
              "      <td>0.009700</td>\n",
              "      <td>0.105980</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.164484</td>\n",
              "      <td>0.137004</td>\n",
              "      <td>0.165505</td>\n",
              "      <td>0.176745</td>\n",
              "      <td>0.186086</td>\n",
              "      <td>0.149056</td>\n",
              "      <td>0.190527</td>\n",
              "      <td>0.256168</td>\n",
              "      <td>0.278809</td>\n",
              "      <td>0.242770</td>\n",
              "      <td>...</td>\n",
              "      <td>0.391745</td>\n",
              "      <td>0.360085</td>\n",
              "      <td>0.331456</td>\n",
              "      <td>0.324828</td>\n",
              "      <td>0.310089</td>\n",
              "      <td>0.291611</td>\n",
              "      <td>0.224983</td>\n",
              "      <td>0.176666</td>\n",
              "      <td>0.166279</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.152732</td>\n",
              "      <td>0.074585</td>\n",
              "      <td>-0.013711</td>\n",
              "      <td>-0.034827</td>\n",
              "      <td>-0.023673</td>\n",
              "      <td>-0.104258</td>\n",
              "      <td>-0.139073</td>\n",
              "      <td>-0.163288</td>\n",
              "      <td>-0.166813</td>\n",
              "      <td>-0.192017</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.089275</td>\n",
              "      <td>-0.098827</td>\n",
              "      <td>-0.167260</td>\n",
              "      <td>-0.194723</td>\n",
              "      <td>-0.183527</td>\n",
              "      <td>-0.151331</td>\n",
              "      <td>-0.188605</td>\n",
              "      <td>-0.218650</td>\n",
              "      <td>-0.179596</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17995</th>\n",
              "      <td>-0.076292</td>\n",
              "      <td>-0.111654</td>\n",
              "      <td>-0.075956</td>\n",
              "      <td>-0.069888</td>\n",
              "      <td>-0.045250</td>\n",
              "      <td>-0.063222</td>\n",
              "      <td>-0.042144</td>\n",
              "      <td>-0.062486</td>\n",
              "      <td>-0.043508</td>\n",
              "      <td>-0.019340</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.062754</td>\n",
              "      <td>0.002815</td>\n",
              "      <td>-0.032905</td>\n",
              "      <td>-0.016336</td>\n",
              "      <td>-0.045078</td>\n",
              "      <td>0.004621</td>\n",
              "      <td>-0.020431</td>\n",
              "      <td>0.005698</td>\n",
              "      <td>-0.048605</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17996</th>\n",
              "      <td>-0.048497</td>\n",
              "      <td>-0.030079</td>\n",
              "      <td>-0.042822</td>\n",
              "      <td>-0.063725</td>\n",
              "      <td>-0.028908</td>\n",
              "      <td>-0.011291</td>\n",
              "      <td>-0.015405</td>\n",
              "      <td>-0.037688</td>\n",
              "      <td>-0.033962</td>\n",
              "      <td>-0.027736</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.019348</td>\n",
              "      <td>-0.078060</td>\n",
              "      <td>-0.082112</td>\n",
              "      <td>-0.081604</td>\n",
              "      <td>-0.070175</td>\n",
              "      <td>-0.080676</td>\n",
              "      <td>-0.072666</td>\n",
              "      <td>0.004694</td>\n",
              "      <td>-0.046835</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17997</th>\n",
              "      <td>-0.017653</td>\n",
              "      <td>0.005880</td>\n",
              "      <td>-0.008398</td>\n",
              "      <td>-0.053956</td>\n",
              "      <td>-0.045114</td>\n",
              "      <td>-0.050892</td>\n",
              "      <td>-0.014791</td>\n",
              "      <td>-0.025570</td>\n",
              "      <td>-0.044989</td>\n",
              "      <td>-0.027848</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.057440</td>\n",
              "      <td>-0.065800</td>\n",
              "      <td>-0.044000</td>\n",
              "      <td>-0.082399</td>\n",
              "      <td>-0.083447</td>\n",
              "      <td>-0.065335</td>\n",
              "      <td>-0.088911</td>\n",
              "      <td>-0.080017</td>\n",
              "      <td>-0.076062</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17998</th>\n",
              "      <td>-0.091136</td>\n",
              "      <td>-0.072359</td>\n",
              "      <td>-0.082491</td>\n",
              "      <td>-0.096773</td>\n",
              "      <td>-0.108624</td>\n",
              "      <td>-0.106044</td>\n",
              "      <td>-0.096813</td>\n",
              "      <td>-0.094621</td>\n",
              "      <td>-0.049099</td>\n",
              "      <td>-0.103425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.064874</td>\n",
              "      <td>-0.019088</td>\n",
              "      <td>-0.028823</td>\n",
              "      <td>-0.049239</td>\n",
              "      <td>-0.026504</td>\n",
              "      <td>-0.037821</td>\n",
              "      <td>-0.061718</td>\n",
              "      <td>-0.066845</td>\n",
              "      <td>-0.059923</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17999</th>\n",
              "      <td>-0.040551</td>\n",
              "      <td>-0.032769</td>\n",
              "      <td>-0.024399</td>\n",
              "      <td>-0.043038</td>\n",
              "      <td>-0.040068</td>\n",
              "      <td>-0.059028</td>\n",
              "      <td>-0.083389</td>\n",
              "      <td>-0.066660</td>\n",
              "      <td>-0.039522</td>\n",
              "      <td>-0.092334</td>\n",
              "      <td>...</td>\n",
              "      <td>0.115293</td>\n",
              "      <td>0.154681</td>\n",
              "      <td>0.142378</td>\n",
              "      <td>0.226287</td>\n",
              "      <td>0.199556</td>\n",
              "      <td>0.225905</td>\n",
              "      <td>0.209185</td>\n",
              "      <td>0.220656</td>\n",
              "      <td>0.204857</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18000 rows × 513 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-752d76d2-dd9c-405f-8a6c-37e9b18e556b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-752d76d2-dd9c-405f-8a6c-37e9b18e556b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-752d76d2-dd9c-405f-8a6c-37e9b18e556b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "data_total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9JcGPPTXQw-"
      },
      "source": [
        "## 데이터 전체 섞기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQoeiTSdXQw-"
      },
      "outputs": [],
      "source": [
        "data_total=data_total.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqjWqLYkXQw-"
      },
      "outputs": [],
      "source": [
        "data_train=data_total.iloc[0:14400, :]\n",
        "data_val=data_total.iloc[14400:16200, :]\n",
        "data_test=data_total.iloc[16200:18000,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "voaozdDZXQw-",
        "outputId": "583a3dab-f625-4922-d8c5-be0f28ee8458"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "11972 -0.118944 -0.097710 -0.141156 -0.121442 -0.129578 -0.100904 -0.086199   \n",
              "9485  -0.055895 -0.039202 -0.055241 -0.074049 -0.039119 -0.034539 -0.090239   \n",
              "16865 -0.021957  0.020436 -0.012769  0.007826  0.006553  0.024852  0.007381   \n",
              "15475  0.050189 -0.041782 -0.014473  0.027127 -0.052534 -0.035044 -0.057463   \n",
              "15221 -0.108148 -0.073405 -0.108082 -0.058189 -0.065407 -0.099554 -0.095312   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "1204   0.006539  0.004692 -0.002344  0.004821  0.000217  0.020083  0.034641   \n",
              "2755  -0.090322 -0.064564 -0.061915 -0.061057 -0.056179 -0.072241 -0.069663   \n",
              "1669   0.001481  0.016193 -0.019005  0.018697 -0.009921 -0.024839 -0.011968   \n",
              "1208   0.248835  0.268121  0.279817  0.295283  0.288009  0.292825  0.299892   \n",
              "1796  -0.006185 -0.022861 -0.030977 -0.017821 -0.018694 -0.023126 -0.022548   \n",
              "\n",
              "            7         8         9    ...       503       504       505  \\\n",
              "11972 -0.118905 -0.100970 -0.067876  ...  0.029167  0.051946  0.052145   \n",
              "9485  -0.036930 -0.066542 -0.035554  ... -0.022918 -0.033455 -0.051762   \n",
              "16865  0.000252 -0.028275 -0.043701  ... -0.043038 -0.045536 -0.006004   \n",
              "15475 -0.062753 -0.091102 -0.062281  ... -0.068878 -0.084586 -0.102791   \n",
              "15221 -0.100020 -0.050718 -0.053656  ... -0.069281 -0.118103 -0.076705   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "1204   0.033169  0.037178  0.049388  ... -0.086765 -0.063205 -0.073705   \n",
              "2755  -0.057076 -0.038108 -0.049821  ... -0.022459 -0.041112 -0.020717   \n",
              "1669  -0.052376 -0.007625 -0.035974  ... -0.034174 -0.018502 -0.050910   \n",
              "1208   0.317068  0.295535  0.281801  ... -0.038975 -0.045902 -0.051699   \n",
              "1796  -0.018738 -0.007357  0.010485  ... -0.001650 -0.035628  0.008493   \n",
              "\n",
              "            506       507       508       509       510       511   512  \n",
              "11972  0.032114  0.039684  0.060624  0.037964  0.085715  0.082346  67.0  \n",
              "9485  -0.060188 -0.053004 -0.069670 -0.049045 -0.102779 -0.082693  53.0  \n",
              "16865 -0.001711 -0.022649 -0.004198 -0.005766 -0.054234 -0.007852  94.0  \n",
              "15475 -0.123175 -0.068607 -0.073897 -0.124706 -0.107012 -0.109267  86.0  \n",
              "15221 -0.079157 -0.143928 -0.095539 -0.086270 -0.106641 -0.049301  85.0  \n",
              "...         ...       ...       ...       ...       ...       ...   ...  \n",
              "1204  -0.074656 -0.058118 -0.071651 -0.065574 -0.064319 -0.057024   7.0  \n",
              "2755  -0.052411 -0.030156 -0.055331 -0.089667 -0.058392 -0.038189  16.0  \n",
              "1669  -0.066058 -0.041296 -0.033853 -0.069880 -0.018448 -0.047695  10.0  \n",
              "1208  -0.059867 -0.056366 -0.079405 -0.068734 -0.090714 -0.076794   7.0  \n",
              "1796  -0.047817 -0.026078  0.002891  0.031408  0.009404 -0.036570  10.0  \n",
              "\n",
              "[14400 rows x 513 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdb1571a-79b3-4dc1-87a1-52fb33d8b057\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11972</th>\n",
              "      <td>-0.118944</td>\n",
              "      <td>-0.097710</td>\n",
              "      <td>-0.141156</td>\n",
              "      <td>-0.121442</td>\n",
              "      <td>-0.129578</td>\n",
              "      <td>-0.100904</td>\n",
              "      <td>-0.086199</td>\n",
              "      <td>-0.118905</td>\n",
              "      <td>-0.100970</td>\n",
              "      <td>-0.067876</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029167</td>\n",
              "      <td>0.051946</td>\n",
              "      <td>0.052145</td>\n",
              "      <td>0.032114</td>\n",
              "      <td>0.039684</td>\n",
              "      <td>0.060624</td>\n",
              "      <td>0.037964</td>\n",
              "      <td>0.085715</td>\n",
              "      <td>0.082346</td>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9485</th>\n",
              "      <td>-0.055895</td>\n",
              "      <td>-0.039202</td>\n",
              "      <td>-0.055241</td>\n",
              "      <td>-0.074049</td>\n",
              "      <td>-0.039119</td>\n",
              "      <td>-0.034539</td>\n",
              "      <td>-0.090239</td>\n",
              "      <td>-0.036930</td>\n",
              "      <td>-0.066542</td>\n",
              "      <td>-0.035554</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.022918</td>\n",
              "      <td>-0.033455</td>\n",
              "      <td>-0.051762</td>\n",
              "      <td>-0.060188</td>\n",
              "      <td>-0.053004</td>\n",
              "      <td>-0.069670</td>\n",
              "      <td>-0.049045</td>\n",
              "      <td>-0.102779</td>\n",
              "      <td>-0.082693</td>\n",
              "      <td>53.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16865</th>\n",
              "      <td>-0.021957</td>\n",
              "      <td>0.020436</td>\n",
              "      <td>-0.012769</td>\n",
              "      <td>0.007826</td>\n",
              "      <td>0.006553</td>\n",
              "      <td>0.024852</td>\n",
              "      <td>0.007381</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>-0.028275</td>\n",
              "      <td>-0.043701</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.043038</td>\n",
              "      <td>-0.045536</td>\n",
              "      <td>-0.006004</td>\n",
              "      <td>-0.001711</td>\n",
              "      <td>-0.022649</td>\n",
              "      <td>-0.004198</td>\n",
              "      <td>-0.005766</td>\n",
              "      <td>-0.054234</td>\n",
              "      <td>-0.007852</td>\n",
              "      <td>94.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15475</th>\n",
              "      <td>0.050189</td>\n",
              "      <td>-0.041782</td>\n",
              "      <td>-0.014473</td>\n",
              "      <td>0.027127</td>\n",
              "      <td>-0.052534</td>\n",
              "      <td>-0.035044</td>\n",
              "      <td>-0.057463</td>\n",
              "      <td>-0.062753</td>\n",
              "      <td>-0.091102</td>\n",
              "      <td>-0.062281</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.068878</td>\n",
              "      <td>-0.084586</td>\n",
              "      <td>-0.102791</td>\n",
              "      <td>-0.123175</td>\n",
              "      <td>-0.068607</td>\n",
              "      <td>-0.073897</td>\n",
              "      <td>-0.124706</td>\n",
              "      <td>-0.107012</td>\n",
              "      <td>-0.109267</td>\n",
              "      <td>86.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15221</th>\n",
              "      <td>-0.108148</td>\n",
              "      <td>-0.073405</td>\n",
              "      <td>-0.108082</td>\n",
              "      <td>-0.058189</td>\n",
              "      <td>-0.065407</td>\n",
              "      <td>-0.099554</td>\n",
              "      <td>-0.095312</td>\n",
              "      <td>-0.100020</td>\n",
              "      <td>-0.050718</td>\n",
              "      <td>-0.053656</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.069281</td>\n",
              "      <td>-0.118103</td>\n",
              "      <td>-0.076705</td>\n",
              "      <td>-0.079157</td>\n",
              "      <td>-0.143928</td>\n",
              "      <td>-0.095539</td>\n",
              "      <td>-0.086270</td>\n",
              "      <td>-0.106641</td>\n",
              "      <td>-0.049301</td>\n",
              "      <td>85.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1204</th>\n",
              "      <td>0.006539</td>\n",
              "      <td>0.004692</td>\n",
              "      <td>-0.002344</td>\n",
              "      <td>0.004821</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.020083</td>\n",
              "      <td>0.034641</td>\n",
              "      <td>0.033169</td>\n",
              "      <td>0.037178</td>\n",
              "      <td>0.049388</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.086765</td>\n",
              "      <td>-0.063205</td>\n",
              "      <td>-0.073705</td>\n",
              "      <td>-0.074656</td>\n",
              "      <td>-0.058118</td>\n",
              "      <td>-0.071651</td>\n",
              "      <td>-0.065574</td>\n",
              "      <td>-0.064319</td>\n",
              "      <td>-0.057024</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2755</th>\n",
              "      <td>-0.090322</td>\n",
              "      <td>-0.064564</td>\n",
              "      <td>-0.061915</td>\n",
              "      <td>-0.061057</td>\n",
              "      <td>-0.056179</td>\n",
              "      <td>-0.072241</td>\n",
              "      <td>-0.069663</td>\n",
              "      <td>-0.057076</td>\n",
              "      <td>-0.038108</td>\n",
              "      <td>-0.049821</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.022459</td>\n",
              "      <td>-0.041112</td>\n",
              "      <td>-0.020717</td>\n",
              "      <td>-0.052411</td>\n",
              "      <td>-0.030156</td>\n",
              "      <td>-0.055331</td>\n",
              "      <td>-0.089667</td>\n",
              "      <td>-0.058392</td>\n",
              "      <td>-0.038189</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1669</th>\n",
              "      <td>0.001481</td>\n",
              "      <td>0.016193</td>\n",
              "      <td>-0.019005</td>\n",
              "      <td>0.018697</td>\n",
              "      <td>-0.009921</td>\n",
              "      <td>-0.024839</td>\n",
              "      <td>-0.011968</td>\n",
              "      <td>-0.052376</td>\n",
              "      <td>-0.007625</td>\n",
              "      <td>-0.035974</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.034174</td>\n",
              "      <td>-0.018502</td>\n",
              "      <td>-0.050910</td>\n",
              "      <td>-0.066058</td>\n",
              "      <td>-0.041296</td>\n",
              "      <td>-0.033853</td>\n",
              "      <td>-0.069880</td>\n",
              "      <td>-0.018448</td>\n",
              "      <td>-0.047695</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>0.248835</td>\n",
              "      <td>0.268121</td>\n",
              "      <td>0.279817</td>\n",
              "      <td>0.295283</td>\n",
              "      <td>0.288009</td>\n",
              "      <td>0.292825</td>\n",
              "      <td>0.299892</td>\n",
              "      <td>0.317068</td>\n",
              "      <td>0.295535</td>\n",
              "      <td>0.281801</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038975</td>\n",
              "      <td>-0.045902</td>\n",
              "      <td>-0.051699</td>\n",
              "      <td>-0.059867</td>\n",
              "      <td>-0.056366</td>\n",
              "      <td>-0.079405</td>\n",
              "      <td>-0.068734</td>\n",
              "      <td>-0.090714</td>\n",
              "      <td>-0.076794</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>-0.006185</td>\n",
              "      <td>-0.022861</td>\n",
              "      <td>-0.030977</td>\n",
              "      <td>-0.017821</td>\n",
              "      <td>-0.018694</td>\n",
              "      <td>-0.023126</td>\n",
              "      <td>-0.022548</td>\n",
              "      <td>-0.018738</td>\n",
              "      <td>-0.007357</td>\n",
              "      <td>0.010485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001650</td>\n",
              "      <td>-0.035628</td>\n",
              "      <td>0.008493</td>\n",
              "      <td>-0.047817</td>\n",
              "      <td>-0.026078</td>\n",
              "      <td>0.002891</td>\n",
              "      <td>0.031408</td>\n",
              "      <td>0.009404</td>\n",
              "      <td>-0.036570</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14400 rows × 513 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdb1571a-79b3-4dc1-87a1-52fb33d8b057')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdb1571a-79b3-4dc1-87a1-52fb33d8b057 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdb1571a-79b3-4dc1-87a1-52fb33d8b057');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qynh1gNZXQw-"
      },
      "source": [
        "## 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzR-X6g-XQw-",
        "outputId": "1b381fad-9454-4034-d049-ea7033a26155"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "y_train = to_categorical(data_train[512])\n",
        "y_test = to_categorical(data_test[512])\n",
        "y_val = to_categorical(data_val[512])\n",
        "y_train[14399]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "PQ1i2-xkXQw-",
        "outputId": "c41031ba-ca98-4a26-fbd8-f3d5f16eac8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "11972 -0.118944 -0.097710 -0.141156 -0.121442 -0.129578 -0.100904 -0.086199   \n",
              "9485  -0.055895 -0.039202 -0.055241 -0.074049 -0.039119 -0.034539 -0.090239   \n",
              "16865 -0.021957  0.020436 -0.012769  0.007826  0.006553  0.024852  0.007381   \n",
              "15475  0.050189 -0.041782 -0.014473  0.027127 -0.052534 -0.035044 -0.057463   \n",
              "15221 -0.108148 -0.073405 -0.108082 -0.058189 -0.065407 -0.099554 -0.095312   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "1204   0.006539  0.004692 -0.002344  0.004821  0.000217  0.020083  0.034641   \n",
              "2755  -0.090322 -0.064564 -0.061915 -0.061057 -0.056179 -0.072241 -0.069663   \n",
              "1669   0.001481  0.016193 -0.019005  0.018697 -0.009921 -0.024839 -0.011968   \n",
              "1208   0.248835  0.268121  0.279817  0.295283  0.288009  0.292825  0.299892   \n",
              "1796  -0.006185 -0.022861 -0.030977 -0.017821 -0.018694 -0.023126 -0.022548   \n",
              "\n",
              "            7         8         9    ...       502       503       504  \\\n",
              "11972 -0.118905 -0.100970 -0.067876  ...  0.045639  0.029167  0.051946   \n",
              "9485  -0.036930 -0.066542 -0.035554  ... -0.009490 -0.022918 -0.033455   \n",
              "16865  0.000252 -0.028275 -0.043701  ... -0.023880 -0.043038 -0.045536   \n",
              "15475 -0.062753 -0.091102 -0.062281  ... -0.078850 -0.068878 -0.084586   \n",
              "15221 -0.100020 -0.050718 -0.053656  ... -0.061878 -0.069281 -0.118103   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "1204   0.033169  0.037178  0.049388  ... -0.049386 -0.086765 -0.063205   \n",
              "2755  -0.057076 -0.038108 -0.049821  ... -0.038055 -0.022459 -0.041112   \n",
              "1669  -0.052376 -0.007625 -0.035974  ... -0.001776 -0.034174 -0.018502   \n",
              "1208   0.317068  0.295535  0.281801  ... -0.020158 -0.038975 -0.045902   \n",
              "1796  -0.018738 -0.007357  0.010485  ... -0.010483 -0.001650 -0.035628   \n",
              "\n",
              "            505       506       507       508       509       510       511  \n",
              "11972  0.052145  0.032114  0.039684  0.060624  0.037964  0.085715  0.082346  \n",
              "9485  -0.051762 -0.060188 -0.053004 -0.069670 -0.049045 -0.102779 -0.082693  \n",
              "16865 -0.006004 -0.001711 -0.022649 -0.004198 -0.005766 -0.054234 -0.007852  \n",
              "15475 -0.102791 -0.123175 -0.068607 -0.073897 -0.124706 -0.107012 -0.109267  \n",
              "15221 -0.076705 -0.079157 -0.143928 -0.095539 -0.086270 -0.106641 -0.049301  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "1204  -0.073705 -0.074656 -0.058118 -0.071651 -0.065574 -0.064319 -0.057024  \n",
              "2755  -0.020717 -0.052411 -0.030156 -0.055331 -0.089667 -0.058392 -0.038189  \n",
              "1669  -0.050910 -0.066058 -0.041296 -0.033853 -0.069880 -0.018448 -0.047695  \n",
              "1208  -0.051699 -0.059867 -0.056366 -0.079405 -0.068734 -0.090714 -0.076794  \n",
              "1796   0.008493 -0.047817 -0.026078  0.002891  0.031408  0.009404 -0.036570  \n",
              "\n",
              "[14400 rows x 512 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2280b383-6b94-4aac-8522-1dcc21ac64f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11972</th>\n",
              "      <td>-0.118944</td>\n",
              "      <td>-0.097710</td>\n",
              "      <td>-0.141156</td>\n",
              "      <td>-0.121442</td>\n",
              "      <td>-0.129578</td>\n",
              "      <td>-0.100904</td>\n",
              "      <td>-0.086199</td>\n",
              "      <td>-0.118905</td>\n",
              "      <td>-0.100970</td>\n",
              "      <td>-0.067876</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045639</td>\n",
              "      <td>0.029167</td>\n",
              "      <td>0.051946</td>\n",
              "      <td>0.052145</td>\n",
              "      <td>0.032114</td>\n",
              "      <td>0.039684</td>\n",
              "      <td>0.060624</td>\n",
              "      <td>0.037964</td>\n",
              "      <td>0.085715</td>\n",
              "      <td>0.082346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9485</th>\n",
              "      <td>-0.055895</td>\n",
              "      <td>-0.039202</td>\n",
              "      <td>-0.055241</td>\n",
              "      <td>-0.074049</td>\n",
              "      <td>-0.039119</td>\n",
              "      <td>-0.034539</td>\n",
              "      <td>-0.090239</td>\n",
              "      <td>-0.036930</td>\n",
              "      <td>-0.066542</td>\n",
              "      <td>-0.035554</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009490</td>\n",
              "      <td>-0.022918</td>\n",
              "      <td>-0.033455</td>\n",
              "      <td>-0.051762</td>\n",
              "      <td>-0.060188</td>\n",
              "      <td>-0.053004</td>\n",
              "      <td>-0.069670</td>\n",
              "      <td>-0.049045</td>\n",
              "      <td>-0.102779</td>\n",
              "      <td>-0.082693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16865</th>\n",
              "      <td>-0.021957</td>\n",
              "      <td>0.020436</td>\n",
              "      <td>-0.012769</td>\n",
              "      <td>0.007826</td>\n",
              "      <td>0.006553</td>\n",
              "      <td>0.024852</td>\n",
              "      <td>0.007381</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>-0.028275</td>\n",
              "      <td>-0.043701</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023880</td>\n",
              "      <td>-0.043038</td>\n",
              "      <td>-0.045536</td>\n",
              "      <td>-0.006004</td>\n",
              "      <td>-0.001711</td>\n",
              "      <td>-0.022649</td>\n",
              "      <td>-0.004198</td>\n",
              "      <td>-0.005766</td>\n",
              "      <td>-0.054234</td>\n",
              "      <td>-0.007852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15475</th>\n",
              "      <td>0.050189</td>\n",
              "      <td>-0.041782</td>\n",
              "      <td>-0.014473</td>\n",
              "      <td>0.027127</td>\n",
              "      <td>-0.052534</td>\n",
              "      <td>-0.035044</td>\n",
              "      <td>-0.057463</td>\n",
              "      <td>-0.062753</td>\n",
              "      <td>-0.091102</td>\n",
              "      <td>-0.062281</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.078850</td>\n",
              "      <td>-0.068878</td>\n",
              "      <td>-0.084586</td>\n",
              "      <td>-0.102791</td>\n",
              "      <td>-0.123175</td>\n",
              "      <td>-0.068607</td>\n",
              "      <td>-0.073897</td>\n",
              "      <td>-0.124706</td>\n",
              "      <td>-0.107012</td>\n",
              "      <td>-0.109267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15221</th>\n",
              "      <td>-0.108148</td>\n",
              "      <td>-0.073405</td>\n",
              "      <td>-0.108082</td>\n",
              "      <td>-0.058189</td>\n",
              "      <td>-0.065407</td>\n",
              "      <td>-0.099554</td>\n",
              "      <td>-0.095312</td>\n",
              "      <td>-0.100020</td>\n",
              "      <td>-0.050718</td>\n",
              "      <td>-0.053656</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.061878</td>\n",
              "      <td>-0.069281</td>\n",
              "      <td>-0.118103</td>\n",
              "      <td>-0.076705</td>\n",
              "      <td>-0.079157</td>\n",
              "      <td>-0.143928</td>\n",
              "      <td>-0.095539</td>\n",
              "      <td>-0.086270</td>\n",
              "      <td>-0.106641</td>\n",
              "      <td>-0.049301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1204</th>\n",
              "      <td>0.006539</td>\n",
              "      <td>0.004692</td>\n",
              "      <td>-0.002344</td>\n",
              "      <td>0.004821</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0.020083</td>\n",
              "      <td>0.034641</td>\n",
              "      <td>0.033169</td>\n",
              "      <td>0.037178</td>\n",
              "      <td>0.049388</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.049386</td>\n",
              "      <td>-0.086765</td>\n",
              "      <td>-0.063205</td>\n",
              "      <td>-0.073705</td>\n",
              "      <td>-0.074656</td>\n",
              "      <td>-0.058118</td>\n",
              "      <td>-0.071651</td>\n",
              "      <td>-0.065574</td>\n",
              "      <td>-0.064319</td>\n",
              "      <td>-0.057024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2755</th>\n",
              "      <td>-0.090322</td>\n",
              "      <td>-0.064564</td>\n",
              "      <td>-0.061915</td>\n",
              "      <td>-0.061057</td>\n",
              "      <td>-0.056179</td>\n",
              "      <td>-0.072241</td>\n",
              "      <td>-0.069663</td>\n",
              "      <td>-0.057076</td>\n",
              "      <td>-0.038108</td>\n",
              "      <td>-0.049821</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038055</td>\n",
              "      <td>-0.022459</td>\n",
              "      <td>-0.041112</td>\n",
              "      <td>-0.020717</td>\n",
              "      <td>-0.052411</td>\n",
              "      <td>-0.030156</td>\n",
              "      <td>-0.055331</td>\n",
              "      <td>-0.089667</td>\n",
              "      <td>-0.058392</td>\n",
              "      <td>-0.038189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1669</th>\n",
              "      <td>0.001481</td>\n",
              "      <td>0.016193</td>\n",
              "      <td>-0.019005</td>\n",
              "      <td>0.018697</td>\n",
              "      <td>-0.009921</td>\n",
              "      <td>-0.024839</td>\n",
              "      <td>-0.011968</td>\n",
              "      <td>-0.052376</td>\n",
              "      <td>-0.007625</td>\n",
              "      <td>-0.035974</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001776</td>\n",
              "      <td>-0.034174</td>\n",
              "      <td>-0.018502</td>\n",
              "      <td>-0.050910</td>\n",
              "      <td>-0.066058</td>\n",
              "      <td>-0.041296</td>\n",
              "      <td>-0.033853</td>\n",
              "      <td>-0.069880</td>\n",
              "      <td>-0.018448</td>\n",
              "      <td>-0.047695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>0.248835</td>\n",
              "      <td>0.268121</td>\n",
              "      <td>0.279817</td>\n",
              "      <td>0.295283</td>\n",
              "      <td>0.288009</td>\n",
              "      <td>0.292825</td>\n",
              "      <td>0.299892</td>\n",
              "      <td>0.317068</td>\n",
              "      <td>0.295535</td>\n",
              "      <td>0.281801</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020158</td>\n",
              "      <td>-0.038975</td>\n",
              "      <td>-0.045902</td>\n",
              "      <td>-0.051699</td>\n",
              "      <td>-0.059867</td>\n",
              "      <td>-0.056366</td>\n",
              "      <td>-0.079405</td>\n",
              "      <td>-0.068734</td>\n",
              "      <td>-0.090714</td>\n",
              "      <td>-0.076794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>-0.006185</td>\n",
              "      <td>-0.022861</td>\n",
              "      <td>-0.030977</td>\n",
              "      <td>-0.017821</td>\n",
              "      <td>-0.018694</td>\n",
              "      <td>-0.023126</td>\n",
              "      <td>-0.022548</td>\n",
              "      <td>-0.018738</td>\n",
              "      <td>-0.007357</td>\n",
              "      <td>0.010485</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010483</td>\n",
              "      <td>-0.001650</td>\n",
              "      <td>-0.035628</td>\n",
              "      <td>0.008493</td>\n",
              "      <td>-0.047817</td>\n",
              "      <td>-0.026078</td>\n",
              "      <td>0.002891</td>\n",
              "      <td>0.031408</td>\n",
              "      <td>0.009404</td>\n",
              "      <td>-0.036570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14400 rows × 512 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2280b383-6b94-4aac-8522-1dcc21ac64f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2280b383-6b94-4aac-8522-1dcc21ac64f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2280b383-6b94-4aac-8522-1dcc21ac64f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "data_train.drop([512], axis=1, inplace=True)\n",
        "data_test.drop([512], axis=1, inplace=True)\n",
        "data_val.drop([512], axis=1, inplace=True)\n",
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-857ihoXQw-"
      },
      "outputs": [],
      "source": [
        "X_train=data_train.values\n",
        "X_test=data_test.values\n",
        "X_val=data_val.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkVpjofrXQw-",
        "outputId": "e243790a-291f-4778-8faa-d4bcbc8e8d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14400, 512)\n",
            "(1800, 512)\n",
            "(1800, 512)\n",
            "(14400, 101)\n",
            "(1800, 101)\n",
            "(1800, 101)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcourDAvXQw_",
        "outputId": "c6c62f79-d7b1-4ec3-b418-a08a48516b4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14400, 512, 1), (1800, 512, 1), (1800, 512, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "\n",
        "X_train = X_train.reshape(14400, 512, 1)\n",
        "X_test = X_test.reshape(1800, 512, 1)\n",
        "X_val = X_val.reshape(1800, 512, 1)\n",
        "X_train.shape, X_test.shape, X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H17aq1x5XQw_"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QSzScZpXQw_",
        "outputId": "fbb26ffd-9137-4130-cc9d-dde728349160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 512, 150)          91200     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 512, 50)           40200     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 512, 50)           20200     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25600)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 25600)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 101)               2585701   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,737,301\n",
            "Trainable params: 2,737,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Input, Embedding, GRU, LSTM, SimpleRNN, MaxPooling1D, GlobalMaxPool1D, CuDNNGRU\n",
        "from keras.layers import Dropout, Dense, Activation, Flatten, Conv1D, SpatialDropout1D\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=150, return_sequences=True, input_shape=(512,1))) #shape[1]=열\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(101, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeo7ft9TXQxA"
      },
      "source": [
        "## 모델학습/평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMpys2YKXQxA",
        "outputId": "06c27a34-b981-462d-e500-f60b9ffaa570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 15s 457ms/step - loss: 0.0098 - accuracy: 0.0100 - val_loss: 0.0098 - val_accuracy: 0.0150\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0098 - val_loss: 0.0098 - val_accuracy: 0.0056\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 6s 421ms/step - loss: 0.0098 - accuracy: 0.0096 - val_loss: 0.0098 - val_accuracy: 0.0111\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0108 - val_loss: 0.0098 - val_accuracy: 0.0067\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0098 - accuracy: 0.0114 - val_loss: 0.0098 - val_accuracy: 0.0067\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0098 - accuracy: 0.0119 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 0.0098 - accuracy: 0.0106 - val_loss: 0.0098 - val_accuracy: 0.0100\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 6s 404ms/step - loss: 0.0098 - accuracy: 0.0117 - val_loss: 0.0098 - val_accuracy: 0.0094\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 6s 407ms/step - loss: 0.0098 - accuracy: 0.0172 - val_loss: 0.0098 - val_accuracy: 0.0083\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 6s 409ms/step - loss: 0.0098 - accuracy: 0.0218 - val_loss: 0.0098 - val_accuracy: 0.0117\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0098 - accuracy: 0.0260 - val_loss: 0.0100 - val_accuracy: 0.0183\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 6s 417ms/step - loss: 0.0098 - accuracy: 0.0318 - val_loss: 0.0098 - val_accuracy: 0.0289\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 6s 419ms/step - loss: 0.0097 - accuracy: 0.0472 - val_loss: 0.0098 - val_accuracy: 0.0361\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 6s 421ms/step - loss: 0.0097 - accuracy: 0.0614 - val_loss: 0.0098 - val_accuracy: 0.0628\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 6s 420ms/step - loss: 0.0096 - accuracy: 0.0867 - val_loss: 0.0098 - val_accuracy: 0.0622\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 0.0096 - accuracy: 0.1042 - val_loss: 0.0097 - val_accuracy: 0.0667\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0095 - accuracy: 0.1126 - val_loss: 0.0097 - val_accuracy: 0.0856\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 6s 409ms/step - loss: 0.0093 - accuracy: 0.1533 - val_loss: 0.0098 - val_accuracy: 0.0950\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 6s 408ms/step - loss: 0.0092 - accuracy: 0.1802 - val_loss: 0.0095 - val_accuracy: 0.1250\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 6s 408ms/step - loss: 0.0090 - accuracy: 0.2081 - val_loss: 0.0096 - val_accuracy: 0.1422\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 6s 408ms/step - loss: 0.0089 - accuracy: 0.2226 - val_loss: 0.0094 - val_accuracy: 0.1522\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 6s 409ms/step - loss: 0.0087 - accuracy: 0.2497 - val_loss: 0.0094 - val_accuracy: 0.1578\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 0.0085 - accuracy: 0.2699 - val_loss: 0.0092 - val_accuracy: 0.1767\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0083 - accuracy: 0.2909 - val_loss: 0.0091 - val_accuracy: 0.2183\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0081 - accuracy: 0.3165 - val_loss: 0.0092 - val_accuracy: 0.2044\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 0.0080 - accuracy: 0.3233 - val_loss: 0.0092 - val_accuracy: 0.2111\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 0.0079 - accuracy: 0.3386 - val_loss: 0.0089 - val_accuracy: 0.2500\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 0.0075 - accuracy: 0.3766 - val_loss: 0.0090 - val_accuracy: 0.2350\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 0.0074 - accuracy: 0.3937 - val_loss: 0.0086 - val_accuracy: 0.2872\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 0.0070 - accuracy: 0.4334 - val_loss: 0.0082 - val_accuracy: 0.3306\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0066 - accuracy: 0.4707 - val_loss: 0.0080 - val_accuracy: 0.3561\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 0.0063 - accuracy: 0.5016 - val_loss: 0.0081 - val_accuracy: 0.3506\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 0.0060 - accuracy: 0.5247 - val_loss: 0.0073 - val_accuracy: 0.4322\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 0.0055 - accuracy: 0.5697 - val_loss: 0.0072 - val_accuracy: 0.4450\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 0.0053 - accuracy: 0.5946 - val_loss: 0.0067 - val_accuracy: 0.4761\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0048 - accuracy: 0.6253 - val_loss: 0.0065 - val_accuracy: 0.5083\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0045 - accuracy: 0.6597 - val_loss: 0.0062 - val_accuracy: 0.5283\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0043 - accuracy: 0.6808 - val_loss: 0.0068 - val_accuracy: 0.4917\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0043 - accuracy: 0.6797 - val_loss: 0.0058 - val_accuracy: 0.5711\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0039 - accuracy: 0.7130 - val_loss: 0.0056 - val_accuracy: 0.5844\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0036 - accuracy: 0.7284 - val_loss: 0.0053 - val_accuracy: 0.6072\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 0.0032 - accuracy: 0.7616 - val_loss: 0.0053 - val_accuracy: 0.6139\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0030 - accuracy: 0.7792 - val_loss: 0.0049 - val_accuracy: 0.6478\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 0.0028 - accuracy: 0.7944 - val_loss: 0.0047 - val_accuracy: 0.6578\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0026 - accuracy: 0.8109 - val_loss: 0.0044 - val_accuracy: 0.6850\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0024 - accuracy: 0.8210 - val_loss: 0.0045 - val_accuracy: 0.6811\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0024 - accuracy: 0.8274 - val_loss: 0.0043 - val_accuracy: 0.6961\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0022 - accuracy: 0.8417 - val_loss: 0.0054 - val_accuracy: 0.6217\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0024 - accuracy: 0.8308 - val_loss: 0.0044 - val_accuracy: 0.6911\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0021 - accuracy: 0.8484 - val_loss: 0.0041 - val_accuracy: 0.7017\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 0.0019 - accuracy: 0.8585 - val_loss: 0.0041 - val_accuracy: 0.7028\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0018 - accuracy: 0.8651 - val_loss: 0.0038 - val_accuracy: 0.7250\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0016 - accuracy: 0.8790 - val_loss: 0.0037 - val_accuracy: 0.7406\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0017 - accuracy: 0.8758 - val_loss: 0.0036 - val_accuracy: 0.7533\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0015 - accuracy: 0.8860 - val_loss: 0.0034 - val_accuracy: 0.7600\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0014 - accuracy: 0.8935 - val_loss: 0.0033 - val_accuracy: 0.7694\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0014 - accuracy: 0.8963 - val_loss: 0.0033 - val_accuracy: 0.7744\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0014 - accuracy: 0.8990 - val_loss: 0.0040 - val_accuracy: 0.7250\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0015 - accuracy: 0.8894 - val_loss: 0.0035 - val_accuracy: 0.7567\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0013 - accuracy: 0.9051 - val_loss: 0.0034 - val_accuracy: 0.7694\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0012 - accuracy: 0.9121 - val_loss: 0.0029 - val_accuracy: 0.8017\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0010 - accuracy: 0.9234 - val_loss: 0.0027 - val_accuracy: 0.8128\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 9.8127e-04 - accuracy: 0.9269 - val_loss: 0.0027 - val_accuracy: 0.8150\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 8.9925e-04 - accuracy: 0.9311 - val_loss: 0.0027 - val_accuracy: 0.8133\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 9.1247e-04 - accuracy: 0.9310 - val_loss: 0.0026 - val_accuracy: 0.8200\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 8.4304e-04 - accuracy: 0.9348 - val_loss: 0.0025 - val_accuracy: 0.8317\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 8.2756e-04 - accuracy: 0.9363 - val_loss: 0.0025 - val_accuracy: 0.8300\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 7.7266e-04 - accuracy: 0.9390 - val_loss: 0.0026 - val_accuracy: 0.8211\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 7.9349e-04 - accuracy: 0.9390 - val_loss: 0.0024 - val_accuracy: 0.8356\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 7.5068e-04 - accuracy: 0.9415 - val_loss: 0.0026 - val_accuracy: 0.8228\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 7.2907e-04 - accuracy: 0.9433 - val_loss: 0.0023 - val_accuracy: 0.8400\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 6.8294e-04 - accuracy: 0.9455 - val_loss: 0.0023 - val_accuracy: 0.8400\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 6.6756e-04 - accuracy: 0.9466 - val_loss: 0.0023 - val_accuracy: 0.8400\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 6.9271e-04 - accuracy: 0.9458 - val_loss: 0.0028 - val_accuracy: 0.8100\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 7.6578e-04 - accuracy: 0.9438 - val_loss: 0.0025 - val_accuracy: 0.8239\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 7.7684e-04 - accuracy: 0.9449 - val_loss: 0.0026 - val_accuracy: 0.8228\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 7.9216e-04 - accuracy: 0.9431 - val_loss: 0.0026 - val_accuracy: 0.8256\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 8.4385e-04 - accuracy: 0.9403 - val_loss: 0.0028 - val_accuracy: 0.8128\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 8.4569e-04 - accuracy: 0.9404 - val_loss: 0.0024 - val_accuracy: 0.8361\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 6.8766e-04 - accuracy: 0.9501 - val_loss: 0.0024 - val_accuracy: 0.8339\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 6.4564e-04 - accuracy: 0.9526 - val_loss: 0.0023 - val_accuracy: 0.8467\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 5.9245e-04 - accuracy: 0.9557 - val_loss: 0.0021 - val_accuracy: 0.8578\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 5.4267e-04 - accuracy: 0.9581 - val_loss: 0.0020 - val_accuracy: 0.8639\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 5.1546e-04 - accuracy: 0.9600 - val_loss: 0.0020 - val_accuracy: 0.8650\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.7960e-04 - accuracy: 0.9620 - val_loss: 0.0020 - val_accuracy: 0.8628\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.7134e-04 - accuracy: 0.9633 - val_loss: 0.0018 - val_accuracy: 0.8739\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 6s 411ms/step - loss: 4.5969e-04 - accuracy: 0.9647 - val_loss: 0.0021 - val_accuracy: 0.8578\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.5295e-04 - accuracy: 0.9656 - val_loss: 0.0019 - val_accuracy: 0.8706\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.2631e-04 - accuracy: 0.9669 - val_loss: 0.0018 - val_accuracy: 0.8761\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.0800e-04 - accuracy: 0.9681 - val_loss: 0.0018 - val_accuracy: 0.8828\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.8123e-04 - accuracy: 0.9697 - val_loss: 0.0018 - val_accuracy: 0.8856\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 3.6940e-04 - accuracy: 0.9703 - val_loss: 0.0018 - val_accuracy: 0.8800\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 3.6528e-04 - accuracy: 0.9708 - val_loss: 0.0018 - val_accuracy: 0.8822\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 3.5775e-04 - accuracy: 0.9712 - val_loss: 0.0017 - val_accuracy: 0.8800\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.4043e-04 - accuracy: 0.9722 - val_loss: 0.0017 - val_accuracy: 0.8822\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.3742e-04 - accuracy: 0.9726 - val_loss: 0.0017 - val_accuracy: 0.8833\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 3.3170e-04 - accuracy: 0.9728 - val_loss: 0.0018 - val_accuracy: 0.8833\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 3.2301e-04 - accuracy: 0.9731 - val_loss: 0.0017 - val_accuracy: 0.8872\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 3.1456e-04 - accuracy: 0.9736 - val_loss: 0.0016 - val_accuracy: 0.8978\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.3167e-04 - accuracy: 0.9728 - val_loss: 0.0017 - val_accuracy: 0.8850\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.2712e-04 - accuracy: 0.9740 - val_loss: 0.0018 - val_accuracy: 0.8833\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.3407e-04 - accuracy: 0.9739 - val_loss: 0.0017 - val_accuracy: 0.8833\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.1841e-04 - accuracy: 0.9746 - val_loss: 0.0018 - val_accuracy: 0.8728\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.3159e-04 - accuracy: 0.9743 - val_loss: 0.0018 - val_accuracy: 0.8817\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.0803e-04 - accuracy: 0.9756 - val_loss: 0.0016 - val_accuracy: 0.8889\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.0110e-04 - accuracy: 0.9760 - val_loss: 0.0017 - val_accuracy: 0.8911\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.8661e-04 - accuracy: 0.9769 - val_loss: 0.0016 - val_accuracy: 0.8961\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.7498e-04 - accuracy: 0.9772 - val_loss: 0.0016 - val_accuracy: 0.8939\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.6921e-04 - accuracy: 0.9774 - val_loss: 0.0016 - val_accuracy: 0.8972\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.6513e-04 - accuracy: 0.9775 - val_loss: 0.0016 - val_accuracy: 0.9000\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.6692e-04 - accuracy: 0.9776 - val_loss: 0.0016 - val_accuracy: 0.8867\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.6774e-04 - accuracy: 0.9777 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.7401e-04 - accuracy: 0.9774 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.7697e-04 - accuracy: 0.9776 - val_loss: 0.0020 - val_accuracy: 0.8694\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 8.5586e-04 - accuracy: 0.9401 - val_loss: 0.0032 - val_accuracy: 0.7811\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0011 - accuracy: 0.9236 - val_loss: 0.0033 - val_accuracy: 0.7822\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 0.0012 - accuracy: 0.9194 - val_loss: 0.0029 - val_accuracy: 0.8128\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 8.7797e-04 - accuracy: 0.9404 - val_loss: 0.0024 - val_accuracy: 0.8389\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 7.3946e-04 - accuracy: 0.9503 - val_loss: 0.0026 - val_accuracy: 0.8328\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 6.9958e-04 - accuracy: 0.9536 - val_loss: 0.0029 - val_accuracy: 0.8050\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0011 - accuracy: 0.9283 - val_loss: 0.0028 - val_accuracy: 0.8183\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 8.1066e-04 - accuracy: 0.9449 - val_loss: 0.0030 - val_accuracy: 0.8094\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 6.7732e-04 - accuracy: 0.9545 - val_loss: 0.0029 - val_accuracy: 0.8111\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 7.0506e-04 - accuracy: 0.9545 - val_loss: 0.0022 - val_accuracy: 0.8528\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.7739e-04 - accuracy: 0.9681 - val_loss: 0.0019 - val_accuracy: 0.8728\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 5.2141e-04 - accuracy: 0.9657 - val_loss: 0.0019 - val_accuracy: 0.8800\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 5.7299e-04 - accuracy: 0.9622 - val_loss: 0.0025 - val_accuracy: 0.8356\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 5.6754e-04 - accuracy: 0.9624 - val_loss: 0.0021 - val_accuracy: 0.8639\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.8012e-04 - accuracy: 0.9683 - val_loss: 0.0023 - val_accuracy: 0.8506\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 5.1381e-04 - accuracy: 0.9655 - val_loss: 0.0023 - val_accuracy: 0.8578\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 5.7655e-04 - accuracy: 0.9619 - val_loss: 0.0023 - val_accuracy: 0.8517\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 5.4960e-04 - accuracy: 0.9642 - val_loss: 0.0022 - val_accuracy: 0.8583\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.2151e-04 - accuracy: 0.9725 - val_loss: 0.0020 - val_accuracy: 0.8700\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 3.4944e-04 - accuracy: 0.9763 - val_loss: 0.0018 - val_accuracy: 0.8822\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 3.0441e-04 - accuracy: 0.9785 - val_loss: 0.0018 - val_accuracy: 0.8850\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.8210e-04 - accuracy: 0.9796 - val_loss: 0.0016 - val_accuracy: 0.8900\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.6995e-04 - accuracy: 0.9799 - val_loss: 0.0018 - val_accuracy: 0.8806\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.6326e-04 - accuracy: 0.9801 - val_loss: 0.0016 - val_accuracy: 0.8928\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.8499e-04 - accuracy: 0.9790 - val_loss: 0.0017 - val_accuracy: 0.8906\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.7625e-04 - accuracy: 0.9797 - val_loss: 0.0017 - val_accuracy: 0.8867\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.6723e-04 - accuracy: 0.9801 - val_loss: 0.0017 - val_accuracy: 0.8878\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.6076e-04 - accuracy: 0.9802 - val_loss: 0.0016 - val_accuracy: 0.8900\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.5498e-04 - accuracy: 0.9803 - val_loss: 0.0016 - val_accuracy: 0.8900\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.4492e-04 - accuracy: 0.9806 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.4402e-04 - accuracy: 0.9808 - val_loss: 0.0016 - val_accuracy: 0.8933\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.4996e-04 - accuracy: 0.9807 - val_loss: 0.0017 - val_accuracy: 0.8867\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.4912e-04 - accuracy: 0.9806 - val_loss: 0.0016 - val_accuracy: 0.8928\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.4180e-04 - accuracy: 0.9808 - val_loss: 0.0016 - val_accuracy: 0.8972\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.3765e-04 - accuracy: 0.9808 - val_loss: 0.0016 - val_accuracy: 0.8950\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.3635e-04 - accuracy: 0.9808 - val_loss: 0.0016 - val_accuracy: 0.8961\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.3244e-04 - accuracy: 0.9809 - val_loss: 0.0016 - val_accuracy: 0.8928\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.3014e-04 - accuracy: 0.9810 - val_loss: 0.0016 - val_accuracy: 0.8917\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.2901e-04 - accuracy: 0.9810 - val_loss: 0.0016 - val_accuracy: 0.8911\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.2622e-04 - accuracy: 0.9812 - val_loss: 0.0016 - val_accuracy: 0.8933\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.2831e-04 - accuracy: 0.9812 - val_loss: 0.0016 - val_accuracy: 0.8922\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.2346e-04 - accuracy: 0.9814 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.2212e-04 - accuracy: 0.9814 - val_loss: 0.0016 - val_accuracy: 0.8939\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.2132e-04 - accuracy: 0.9814 - val_loss: 0.0016 - val_accuracy: 0.8961\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.2069e-04 - accuracy: 0.9814 - val_loss: 0.0016 - val_accuracy: 0.8911\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.1931e-04 - accuracy: 0.9814 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1848e-04 - accuracy: 0.9815 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1682e-04 - accuracy: 0.9815 - val_loss: 0.0016 - val_accuracy: 0.8950\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.2298e-04 - accuracy: 0.9812 - val_loss: 0.0016 - val_accuracy: 0.8961\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.1872e-04 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 0.9033\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1729e-04 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 0.9022\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1542e-04 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 0.9011\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1498e-04 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 0.9000\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1551e-04 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 0.9028\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1673e-04 - accuracy: 0.9814 - val_loss: 0.0015 - val_accuracy: 0.9006\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1531e-04 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 0.9011\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1563e-04 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 0.9011\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.1404e-04 - accuracy: 0.9815 - val_loss: 0.0015 - val_accuracy: 0.9056\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1266e-04 - accuracy: 0.9817 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1134e-04 - accuracy: 0.9817 - val_loss: 0.0015 - val_accuracy: 0.9039\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1108e-04 - accuracy: 0.9817 - val_loss: 0.0015 - val_accuracy: 0.9000\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1048e-04 - accuracy: 0.9817 - val_loss: 0.0015 - val_accuracy: 0.9028\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1171e-04 - accuracy: 0.9817 - val_loss: 0.0015 - val_accuracy: 0.9044\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1309e-04 - accuracy: 0.9817 - val_loss: 0.0015 - val_accuracy: 0.9022\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1117e-04 - accuracy: 0.9817 - val_loss: 0.0015 - val_accuracy: 0.9028\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0935e-04 - accuracy: 0.9818 - val_loss: 0.0015 - val_accuracy: 0.9028\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.0799e-04 - accuracy: 0.9819 - val_loss: 0.0015 - val_accuracy: 0.9028\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0771e-04 - accuracy: 0.9819 - val_loss: 0.0014 - val_accuracy: 0.9033\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0798e-04 - accuracy: 0.9819 - val_loss: 0.0014 - val_accuracy: 0.9039\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0720e-04 - accuracy: 0.9819 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0590e-04 - accuracy: 0.9820 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0511e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9028\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0606e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0762e-04 - accuracy: 0.9820 - val_loss: 0.0015 - val_accuracy: 0.9017\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0816e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9017\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.0661e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9022\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 2.0598e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9033\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0608e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9044\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0581e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9028\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0615e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9033\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0473e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9044\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0440e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9028\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.0599e-04 - accuracy: 0.9821 - val_loss: 0.0015 - val_accuracy: 0.9011\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0628e-04 - accuracy: 0.9821 - val_loss: 0.0015 - val_accuracy: 0.9011\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.0525e-04 - accuracy: 0.9820 - val_loss: 0.0015 - val_accuracy: 0.8994\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0544e-04 - accuracy: 0.9820 - val_loss: 0.0014 - val_accuracy: 0.9006\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0513e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.8994\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0573e-04 - accuracy: 0.9821 - val_loss: 0.0015 - val_accuracy: 0.8967\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0509e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9022\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.0440e-04 - accuracy: 0.9821 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1696e-04 - accuracy: 0.9817 - val_loss: 0.0017 - val_accuracy: 0.8861\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1629e-04 - accuracy: 0.9819 - val_loss: 0.0015 - val_accuracy: 0.8994\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1425e-04 - accuracy: 0.9819 - val_loss: 0.0016 - val_accuracy: 0.8928\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0898e-04 - accuracy: 0.9821 - val_loss: 0.0014 - val_accuracy: 0.9044\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0676e-04 - accuracy: 0.9822 - val_loss: 0.0015 - val_accuracy: 0.9022\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0707e-04 - accuracy: 0.9822 - val_loss: 0.0014 - val_accuracy: 0.9028\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0692e-04 - accuracy: 0.9822 - val_loss: 0.0015 - val_accuracy: 0.9006\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0550e-04 - accuracy: 0.9822 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0426e-04 - accuracy: 0.9821 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0304e-04 - accuracy: 0.9822 - val_loss: 0.0015 - val_accuracy: 0.8972\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0347e-04 - accuracy: 0.9822 - val_loss: 0.0015 - val_accuracy: 0.9050\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0373e-04 - accuracy: 0.9821 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.0255e-04 - accuracy: 0.9822 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0249e-04 - accuracy: 0.9822 - val_loss: 0.0014 - val_accuracy: 0.9000\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0141e-04 - accuracy: 0.9823 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0139e-04 - accuracy: 0.9823 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.0093e-04 - accuracy: 0.9823 - val_loss: 0.0014 - val_accuracy: 0.9039\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0043e-04 - accuracy: 0.9823 - val_loss: 0.0014 - val_accuracy: 0.9033\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0023e-04 - accuracy: 0.9824 - val_loss: 0.0015 - val_accuracy: 0.8978\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.0100e-04 - accuracy: 0.9824 - val_loss: 0.0015 - val_accuracy: 0.9022\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0091e-04 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 0.9022\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0118e-04 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 0.9022\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.0031e-04 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 0.9022\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.0097e-04 - accuracy: 0.9824 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 2.0003e-04 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 0.9033\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9872e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9028\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9799e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9017\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9731e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9033\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9727e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9567e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9039\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9567e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9679e-04 - accuracy: 0.9824 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9517e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9526e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.9423e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9094\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9622e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9549e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9606e-04 - accuracy: 0.9825 - val_loss: 0.0014 - val_accuracy: 0.9094\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0031e-04 - accuracy: 0.9826 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9623e-04 - accuracy: 0.9828 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9517e-04 - accuracy: 0.9828 - val_loss: 0.0014 - val_accuracy: 0.9122\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9496e-04 - accuracy: 0.9828 - val_loss: 0.0013 - val_accuracy: 0.9167\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9415e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9347e-04 - accuracy: 0.9830 - val_loss: 0.0013 - val_accuracy: 0.9133\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9436e-04 - accuracy: 0.9831 - val_loss: 0.0013 - val_accuracy: 0.9122\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9451e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9271e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9374e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9410e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9418e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9363e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9214e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9237e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9384e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0680e-04 - accuracy: 0.9828 - val_loss: 0.0014 - val_accuracy: 0.9006\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0448e-04 - accuracy: 0.9829 - val_loss: 0.0014 - val_accuracy: 0.9044\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0037e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9039\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0351e-04 - accuracy: 0.9828 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9757e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9557e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9111\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.9584e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9579e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9072\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.9763e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9011\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9696e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9028\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.9603e-04 - accuracy: 0.9831 - val_loss: 0.0015 - val_accuracy: 0.9033\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0556e-04 - accuracy: 0.9831 - val_loss: 0.0015 - val_accuracy: 0.8994\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0301e-04 - accuracy: 0.9830 - val_loss: 0.0015 - val_accuracy: 0.8956\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9974e-04 - accuracy: 0.9830 - val_loss: 0.0015 - val_accuracy: 0.9028\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9949e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9033\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9638e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9072\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9722e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.9616e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9574e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9985e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9033\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.9790e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.9684e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9044\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9604e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.9893e-04 - accuracy: 0.9830 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9631e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9044\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0788e-04 - accuracy: 0.9828 - val_loss: 0.0015 - val_accuracy: 0.9050\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.0057e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9719e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9072\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.9698e-04 - accuracy: 0.9831 - val_loss: 0.0013 - val_accuracy: 0.9094\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.9494e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9094\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9686e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9474e-04 - accuracy: 0.9831 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1400e-04 - accuracy: 0.9826 - val_loss: 0.0015 - val_accuracy: 0.8972\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1759e-04 - accuracy: 0.9824 - val_loss: 0.0015 - val_accuracy: 0.8939\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0791e-04 - accuracy: 0.9830 - val_loss: 0.0015 - val_accuracy: 0.8978\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.2553e-04 - accuracy: 0.9823 - val_loss: 0.0016 - val_accuracy: 0.8939\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1693e-04 - accuracy: 0.9828 - val_loss: 0.0016 - val_accuracy: 0.8867\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 2.3840e-04 - accuracy: 0.9817 - val_loss: 0.0018 - val_accuracy: 0.8844\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 3.7613e-04 - accuracy: 0.9744 - val_loss: 0.0022 - val_accuracy: 0.8578\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 0.0011 - accuracy: 0.9267 - val_loss: 0.0044 - val_accuracy: 0.7244\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0017 - accuracy: 0.8876 - val_loss: 0.0037 - val_accuracy: 0.7744\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 0.0011 - accuracy: 0.9297 - val_loss: 0.0038 - val_accuracy: 0.7622\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 0.0016 - accuracy: 0.9011 - val_loss: 0.0037 - val_accuracy: 0.7722\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0013 - accuracy: 0.9204 - val_loss: 0.0026 - val_accuracy: 0.8372\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 9.1836e-04 - accuracy: 0.9430 - val_loss: 0.0029 - val_accuracy: 0.8189\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 9.7071e-04 - accuracy: 0.9401 - val_loss: 0.0026 - val_accuracy: 0.8433\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 8.0738e-04 - accuracy: 0.9506 - val_loss: 0.0023 - val_accuracy: 0.8583\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 6.8040e-04 - accuracy: 0.9563 - val_loss: 0.0021 - val_accuracy: 0.8711\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 6.7174e-04 - accuracy: 0.9590 - val_loss: 0.0021 - val_accuracy: 0.8706\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 5.7174e-04 - accuracy: 0.9641 - val_loss: 0.0022 - val_accuracy: 0.8578\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 5.7722e-04 - accuracy: 0.9644 - val_loss: 0.0024 - val_accuracy: 0.8544\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 4.9637e-04 - accuracy: 0.9694 - val_loss: 0.0018 - val_accuracy: 0.8872\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 3.5952e-04 - accuracy: 0.9770 - val_loss: 0.0016 - val_accuracy: 0.9033\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 3.4418e-04 - accuracy: 0.9784 - val_loss: 0.0017 - val_accuracy: 0.8956\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 3.2705e-04 - accuracy: 0.9798 - val_loss: 0.0016 - val_accuracy: 0.8994\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 4.2692e-04 - accuracy: 0.9736 - val_loss: 0.0023 - val_accuracy: 0.8622\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 3.5744e-04 - accuracy: 0.9778 - val_loss: 0.0019 - val_accuracy: 0.8861\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 3.3059e-04 - accuracy: 0.9787 - val_loss: 0.0018 - val_accuracy: 0.8917\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 4.8944e-04 - accuracy: 0.9693 - val_loss: 0.0021 - val_accuracy: 0.8728\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 3.5655e-04 - accuracy: 0.9774 - val_loss: 0.0018 - val_accuracy: 0.8911\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.8102e-04 - accuracy: 0.9823 - val_loss: 0.0015 - val_accuracy: 0.9067\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.6837e-04 - accuracy: 0.9833 - val_loss: 0.0019 - val_accuracy: 0.8867\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.5269e-04 - accuracy: 0.9719 - val_loss: 0.0019 - val_accuracy: 0.8833\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 3.1503e-04 - accuracy: 0.9800 - val_loss: 0.0018 - val_accuracy: 0.8861\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 3.1269e-04 - accuracy: 0.9801 - val_loss: 0.0017 - val_accuracy: 0.8983\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.7201e-04 - accuracy: 0.9826 - val_loss: 0.0015 - val_accuracy: 0.9056\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 3.1258e-04 - accuracy: 0.9799 - val_loss: 0.0014 - val_accuracy: 0.9139\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.7455e-04 - accuracy: 0.9826 - val_loss: 0.0016 - val_accuracy: 0.9017\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.5514e-04 - accuracy: 0.9835 - val_loss: 0.0015 - val_accuracy: 0.9078\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.4171e-04 - accuracy: 0.9845 - val_loss: 0.0015 - val_accuracy: 0.9128\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.3136e-04 - accuracy: 0.9849 - val_loss: 0.0015 - val_accuracy: 0.9089\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1815e-04 - accuracy: 0.9853 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.2470e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.9056\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.2329e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9083\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1820e-04 - accuracy: 0.9853 - val_loss: 0.0015 - val_accuracy: 0.9017\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1005e-04 - accuracy: 0.9854 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 2.1450e-04 - accuracy: 0.9853 - val_loss: 0.0015 - val_accuracy: 0.9028\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1711e-04 - accuracy: 0.9853 - val_loss: 0.0015 - val_accuracy: 0.9133\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1336e-04 - accuracy: 0.9854 - val_loss: 0.0016 - val_accuracy: 0.9028\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1530e-04 - accuracy: 0.9853 - val_loss: 0.0014 - val_accuracy: 0.9128\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0926e-04 - accuracy: 0.9856 - val_loss: 0.0015 - val_accuracy: 0.9083\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0164e-04 - accuracy: 0.9856 - val_loss: 0.0015 - val_accuracy: 0.9078\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0201e-04 - accuracy: 0.9856 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1329e-04 - accuracy: 0.9855 - val_loss: 0.0016 - val_accuracy: 0.8989\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 2.0881e-04 - accuracy: 0.9856 - val_loss: 0.0016 - val_accuracy: 0.9017\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0995e-04 - accuracy: 0.9854 - val_loss: 0.0015 - val_accuracy: 0.9089\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 2.0759e-04 - accuracy: 0.9856 - val_loss: 0.0015 - val_accuracy: 0.9039\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1913e-04 - accuracy: 0.9853 - val_loss: 0.0015 - val_accuracy: 0.9050\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 2.2150e-04 - accuracy: 0.9853 - val_loss: 0.0015 - val_accuracy: 0.9083\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 2.7449e-04 - accuracy: 0.9819 - val_loss: 0.0016 - val_accuracy: 0.9022\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 2.2894e-04 - accuracy: 0.9849 - val_loss: 0.0015 - val_accuracy: 0.9033\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1352e-04 - accuracy: 0.9854 - val_loss: 0.0015 - val_accuracy: 0.9072\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 2.7013e-04 - accuracy: 0.9822 - val_loss: 0.0018 - val_accuracy: 0.8917\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.3149e-04 - accuracy: 0.9845 - val_loss: 0.0016 - val_accuracy: 0.9061\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1895e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.9044\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1914e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8983\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 2.4176e-04 - accuracy: 0.9843 - val_loss: 0.0016 - val_accuracy: 0.8994\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.5516e-04 - accuracy: 0.9831 - val_loss: 0.0016 - val_accuracy: 0.9017\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.2809e-04 - accuracy: 0.9850 - val_loss: 0.0017 - val_accuracy: 0.8956\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.2225e-04 - accuracy: 0.9849 - val_loss: 0.0015 - val_accuracy: 0.9094\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1787e-04 - accuracy: 0.9853 - val_loss: 0.0014 - val_accuracy: 0.9172\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1326e-04 - accuracy: 0.9851 - val_loss: 0.0019 - val_accuracy: 0.8806\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 5.4765e-04 - accuracy: 0.9641 - val_loss: 0.0017 - val_accuracy: 0.9000\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 3.7583e-04 - accuracy: 0.9759 - val_loss: 0.0020 - val_accuracy: 0.8811\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.0933e-04 - accuracy: 0.9737 - val_loss: 0.0020 - val_accuracy: 0.8761\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 7.3295e-04 - accuracy: 0.9544 - val_loss: 0.0028 - val_accuracy: 0.8328\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.3219e-04 - accuracy: 0.9719 - val_loss: 0.0019 - val_accuracy: 0.8817\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 4.6547e-04 - accuracy: 0.9705 - val_loss: 0.0021 - val_accuracy: 0.8733\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 3.5529e-04 - accuracy: 0.9783 - val_loss: 0.0018 - val_accuracy: 0.8922\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 3.0716e-04 - accuracy: 0.9809 - val_loss: 0.0016 - val_accuracy: 0.9039\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.5538e-04 - accuracy: 0.9837 - val_loss: 0.0016 - val_accuracy: 0.9056\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.3038e-04 - accuracy: 0.9847 - val_loss: 0.0015 - val_accuracy: 0.9106\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.3877e-04 - accuracy: 0.9847 - val_loss: 0.0015 - val_accuracy: 0.9072\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.1976e-04 - accuracy: 0.9855 - val_loss: 0.0015 - val_accuracy: 0.9067\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1812e-04 - accuracy: 0.9854 - val_loss: 0.0013 - val_accuracy: 0.9189\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.2691e-04 - accuracy: 0.9853 - val_loss: 0.0015 - val_accuracy: 0.9083\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.2918e-04 - accuracy: 0.9851 - val_loss: 0.0014 - val_accuracy: 0.9133\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.2013e-04 - accuracy: 0.9856 - val_loss: 0.0014 - val_accuracy: 0.9133\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.1180e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9161\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 2.0736e-04 - accuracy: 0.9857 - val_loss: 0.0014 - val_accuracy: 0.9111\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0752e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9139\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 2.0125e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9161\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0145e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9161\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 2.0328e-04 - accuracy: 0.9856 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 2.0016e-04 - accuracy: 0.9856 - val_loss: 0.0014 - val_accuracy: 0.9167\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9651e-04 - accuracy: 0.9856 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9692e-04 - accuracy: 0.9857 - val_loss: 0.0015 - val_accuracy: 0.9056\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9507e-04 - accuracy: 0.9858 - val_loss: 0.0015 - val_accuracy: 0.9033\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.9410e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.9145e-04 - accuracy: 0.9858 - val_loss: 0.0015 - val_accuracy: 0.9039\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.8844e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8908e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9156\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.8781e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8657e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9161\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.9063e-04 - accuracy: 0.9857 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.8763e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.8575e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9117\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.8479e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9117\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.8322e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8239e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.8081e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9156\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7986e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7910e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9133\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8166e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9128\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8178e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9128\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8189e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9144\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8804e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8748e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9167\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8392e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9150\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.8560e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9117\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.8300e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9122\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.8446e-04 - accuracy: 0.9857 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.8538e-04 - accuracy: 0.9857 - val_loss: 0.0015 - val_accuracy: 0.9039\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.8338e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.8151e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9172\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 6s 417ms/step - loss: 1.8207e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.8192e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.8119e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7953e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9094\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7958e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7975e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9117\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7920e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9111\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7962e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9144\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7858e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9122\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.7769e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9044\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7926e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9094\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7730e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9133\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7764e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.8016e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9100\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.8039e-04 - accuracy: 0.9856 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.7749e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.7838e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.8051e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9156\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.7813e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7702e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9111\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7670e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7999e-04 - accuracy: 0.9856 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7897e-04 - accuracy: 0.9858 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.8073e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9161\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7956e-04 - accuracy: 0.9857 - val_loss: 0.0014 - val_accuracy: 0.9044\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8088e-04 - accuracy: 0.9856 - val_loss: 0.0013 - val_accuracy: 0.9178\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.7981e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9050\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8447e-04 - accuracy: 0.9857 - val_loss: 0.0013 - val_accuracy: 0.9156\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.8285e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9161\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.8125e-04 - accuracy: 0.9857 - val_loss: 0.0013 - val_accuracy: 0.9156\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.7781e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9128\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.7667e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9161\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7655e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9144\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7712e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9194\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7834e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9144\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7594e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9183\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7716e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9161\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7665e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9111\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.7530e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9144\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.7346e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9156\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7459e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7544e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9222\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7604e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9178\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7427e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9133\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7432e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9200\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.7376e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9200\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.7475e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9172\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7562e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9056\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7499e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9178\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7537e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9172\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7407e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9111\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7477e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9156\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7301e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9172\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.7232e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9128\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.7424e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9139\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7234e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9111\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7353e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9167\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7288e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7299e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9078\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7153e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9067\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7259e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7230e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9072\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7354e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9117\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.7175e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7111e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9122\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.6993e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.6930e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9139\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.7076e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9106\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7181e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9133\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7000e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9106\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.6996e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9133\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.6961e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9139\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7027e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9156\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.6993e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9122\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.6821e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.6889e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9072\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.6849e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9111\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.7065e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9128\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.6786e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9122\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 6s 412ms/step - loss: 1.6796e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9089\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.6733e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9122\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 1.6723e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9117\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.6739e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9061\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 6s 414ms/step - loss: 1.6912e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9144\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 6s 416ms/step - loss: 1.6852e-04 - accuracy: 0.9858 - val_loss: 0.0014 - val_accuracy: 0.9083\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7033e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9122\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 6s 415ms/step - loss: 1.7145e-04 - accuracy: 0.9858 - val_loss: 0.0013 - val_accuracy: 0.9128\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, batch_size =1024, epochs = 500, verbose = 1, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pBhnZ6sXQxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e40b886-f8ea-4ef9-830f-cc41dcc465ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 1s 23ms/step - loss: 0.0014 - accuracy: 0.9128\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0013802441535517573, 0.9127777814865112]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/MyDrive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ajym6RWPPYM",
        "outputId": "485c8cc5-d8ee-4c71-f6d2-b4d795e1eb22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('lstm_highpass_2s.h5')"
      ],
      "metadata": {
        "id": "_u-exUSrupS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X93IcrvXQxB"
      },
      "source": [
        "## 그래프 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1NEZobCXQxB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "136387fe-55ac-4426-f276-588d3102acc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7d8ce27cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "history=history.history\n",
        "epochs = range(1, len(history['loss']) + 1)\n",
        "acc = history['accuracy']\n",
        "loss = history['loss']\n",
        "val_acc = history['val_accuracy']\n",
        "val_loss = history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(epochs, acc, label='accuracy')\n",
        "plt.plot(epochs, val_acc, label='val_acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(epochs, loss, label='loss', color='g')\n",
        "plt.plot(epochs, val_loss, label='val_loss', color='r')\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcQ6Ov1VXQxB"
      },
      "source": [
        "## 예측해보기(predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델을 잊어버리고 저장을 안해놔서 해당 모델 예측해보기는 못했습니다."
      ],
      "metadata": {
        "id": "ph6gRCuxHidQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm9zHp-NXQxB",
        "outputId": "8e06685b-4c91-4d7b-804a-f36f83b0daf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "188/188 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[44,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0, 57,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0, 65, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 68,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0, 67,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0, 57]])"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vulS0JfoXQxB",
        "outputId": "348ddc8c-b4b0-4b45-9b9b-a83b87cbce28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       59.0\n",
              "1       68.0\n",
              "2       72.0\n",
              "3        2.0\n",
              "4       57.0\n",
              "        ... \n",
              "5995     3.0\n",
              "5996    87.0\n",
              "5997    40.0\n",
              "5998    68.0\n",
              "5999    37.0\n",
              "Name: y_test, Length: 6000, dtype: float64"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_p=pd.DataFrame(y_test)\n",
        "\n",
        "for i in range(1,101):\n",
        "  y_test_p.loc[y_test_p[i] == 1.0 , 'y_test'] = i  \n",
        "y_test_p.y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fHoV4EKnXQxB",
        "outputId": "22f2ac13-d7ce-409c-db36-bf92c9ca0cad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>87.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         0\n",
              "0     59.0\n",
              "1     68.0\n",
              "2     72.0\n",
              "3      2.0\n",
              "4     57.0\n",
              "...    ...\n",
              "5995   3.0\n",
              "5996  87.0\n",
              "5997  40.0\n",
              "5998  68.0\n",
              "5999  45.0\n",
              "\n",
              "[6000 rows x 1 columns]"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex=np.argmax(y_pred, axis=1)\n",
        "ex=ex.astype('float64')\n",
        "ex=pd.DataFrame(ex)\n",
        "ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzzM4S3tXQxC"
      },
      "outputs": [],
      "source": [
        "ch1 = pd.DataFrame(np.rint(y_pred))\n",
        "ch1['pred'] = ex\n",
        "data_test.reset_index(inplace=True, drop=True)\n",
        "predict = pd.concat([data_test,ch1['pred'], y_test_p['y_test']],axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fm4TevpXQxC"
      },
      "outputs": [],
      "source": [
        "predict['compare'] = np.where(predict['pred']==predict['y_test'],'yes', 'no')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "p4E5sLogXQxC",
        "outputId": "833df983-0f21-460a-de46-668f491d18e1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-22dffb56-3200-49eb-89c1-97f537806f07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>pred</th>\n",
              "      <th>y_test</th>\n",
              "      <th>compare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.001909</td>\n",
              "      <td>0.008317</td>\n",
              "      <td>0.014489</td>\n",
              "      <td>0.020412</td>\n",
              "      <td>0.025995</td>\n",
              "      <td>0.031137</td>\n",
              "      <td>0.035801</td>\n",
              "      <td>0.040075</td>\n",
              "      <td>0.044195</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044631</td>\n",
              "      <td>0.050399</td>\n",
              "      <td>0.057432</td>\n",
              "      <td>0.066046</td>\n",
              "      <td>0.076371</td>\n",
              "      <td>0.088327</td>\n",
              "      <td>0.101648</td>\n",
              "      <td>85.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.096114</td>\n",
              "      <td>0.095362</td>\n",
              "      <td>0.095047</td>\n",
              "      <td>0.095447</td>\n",
              "      <td>0.096676</td>\n",
              "      <td>0.098677</td>\n",
              "      <td>0.101247</td>\n",
              "      <td>0.104083</td>\n",
              "      <td>0.106844</td>\n",
              "      <td>0.109202</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004398</td>\n",
              "      <td>-0.008214</td>\n",
              "      <td>-0.013081</td>\n",
              "      <td>-0.019006</td>\n",
              "      <td>-0.025674</td>\n",
              "      <td>-0.032320</td>\n",
              "      <td>-0.037693</td>\n",
              "      <td>83.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>-0.041972</td>\n",
              "      <td>-0.048778</td>\n",
              "      <td>-0.055266</td>\n",
              "      <td>-0.061636</td>\n",
              "      <td>-0.067728</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.076978</td>\n",
              "      <td>-0.078796</td>\n",
              "      <td>-0.078050</td>\n",
              "      <td>-0.074630</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.102289</td>\n",
              "      <td>-0.108650</td>\n",
              "      <td>-0.114708</td>\n",
              "      <td>-0.119718</td>\n",
              "      <td>-0.122885</td>\n",
              "      <td>-0.123496</td>\n",
              "      <td>-0.121095</td>\n",
              "      <td>20.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.050686</td>\n",
              "      <td>0.056807</td>\n",
              "      <td>0.061922</td>\n",
              "      <td>0.066330</td>\n",
              "      <td>0.070463</td>\n",
              "      <td>0.074831</td>\n",
              "      <td>0.079964</td>\n",
              "      <td>0.086349</td>\n",
              "      <td>0.094365</td>\n",
              "      <td>0.104239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.125449</td>\n",
              "      <td>0.136371</td>\n",
              "      <td>0.147691</td>\n",
              "      <td>0.159697</td>\n",
              "      <td>0.172642</td>\n",
              "      <td>0.186692</td>\n",
              "      <td>0.201860</td>\n",
              "      <td>41.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>-0.511413</td>\n",
              "      <td>-0.507140</td>\n",
              "      <td>-0.469849</td>\n",
              "      <td>-0.408462</td>\n",
              "      <td>-0.333769</td>\n",
              "      <td>-0.256404</td>\n",
              "      <td>-0.185178</td>\n",
              "      <td>-0.126038</td>\n",
              "      <td>-0.081724</td>\n",
              "      <td>-0.052058</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031533</td>\n",
              "      <td>0.034874</td>\n",
              "      <td>0.038518</td>\n",
              "      <td>0.042180</td>\n",
              "      <td>0.045745</td>\n",
              "      <td>0.049241</td>\n",
              "      <td>0.052764</td>\n",
              "      <td>4.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>0.005315</td>\n",
              "      <td>-0.043084</td>\n",
              "      <td>-0.083200</td>\n",
              "      <td>-0.110473</td>\n",
              "      <td>-0.122973</td>\n",
              "      <td>-0.121490</td>\n",
              "      <td>-0.109050</td>\n",
              "      <td>-0.090022</td>\n",
              "      <td>-0.069069</td>\n",
              "      <td>-0.050204</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.027012</td>\n",
              "      <td>-0.029614</td>\n",
              "      <td>-0.031356</td>\n",
              "      <td>-0.033020</td>\n",
              "      <td>-0.035244</td>\n",
              "      <td>-0.038329</td>\n",
              "      <td>-0.042129</td>\n",
              "      <td>95.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5981</th>\n",
              "      <td>-0.005281</td>\n",
              "      <td>-0.018280</td>\n",
              "      <td>-0.031669</td>\n",
              "      <td>-0.042939</td>\n",
              "      <td>-0.050464</td>\n",
              "      <td>-0.053648</td>\n",
              "      <td>-0.052817</td>\n",
              "      <td>-0.048958</td>\n",
              "      <td>-0.043371</td>\n",
              "      <td>-0.037307</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016826</td>\n",
              "      <td>-0.013496</td>\n",
              "      <td>-0.011275</td>\n",
              "      <td>-0.010594</td>\n",
              "      <td>-0.011830</td>\n",
              "      <td>-0.015208</td>\n",
              "      <td>-0.020697</td>\n",
              "      <td>52.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5992</th>\n",
              "      <td>-0.084734</td>\n",
              "      <td>-0.091664</td>\n",
              "      <td>-0.098196</td>\n",
              "      <td>-0.101411</td>\n",
              "      <td>-0.098148</td>\n",
              "      <td>-0.085744</td>\n",
              "      <td>-0.062829</td>\n",
              "      <td>-0.030004</td>\n",
              "      <td>0.009808</td>\n",
              "      <td>0.051498</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072150</td>\n",
              "      <td>0.081214</td>\n",
              "      <td>0.090895</td>\n",
              "      <td>0.101388</td>\n",
              "      <td>0.112932</td>\n",
              "      <td>0.125713</td>\n",
              "      <td>0.139775</td>\n",
              "      <td>100.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5994</th>\n",
              "      <td>0.008461</td>\n",
              "      <td>0.011468</td>\n",
              "      <td>0.012707</td>\n",
              "      <td>0.012096</td>\n",
              "      <td>0.009875</td>\n",
              "      <td>0.006558</td>\n",
              "      <td>0.002841</td>\n",
              "      <td>-0.000513</td>\n",
              "      <td>-0.002782</td>\n",
              "      <td>-0.003375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.048723</td>\n",
              "      <td>-0.051678</td>\n",
              "      <td>-0.052151</td>\n",
              "      <td>-0.050205</td>\n",
              "      <td>-0.046318</td>\n",
              "      <td>-0.041326</td>\n",
              "      <td>-0.036264</td>\n",
              "      <td>95.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>0.052145</td>\n",
              "      <td>0.038833</td>\n",
              "      <td>0.024907</td>\n",
              "      <td>0.010402</td>\n",
              "      <td>-0.004429</td>\n",
              "      <td>-0.019087</td>\n",
              "      <td>-0.032867</td>\n",
              "      <td>-0.044991</td>\n",
              "      <td>-0.054774</td>\n",
              "      <td>-0.061789</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.056943</td>\n",
              "      <td>-0.054300</td>\n",
              "      <td>-0.054324</td>\n",
              "      <td>-0.058068</td>\n",
              "      <td>-0.065599</td>\n",
              "      <td>-0.075635</td>\n",
              "      <td>-0.085448</td>\n",
              "      <td>45.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>545 rows × 259 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22dffb56-3200-49eb-89c1-97f537806f07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22dffb56-3200-49eb-89c1-97f537806f07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22dffb56-3200-49eb-89c1-97f537806f07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "30    0.001909  0.008317  0.014489  0.020412  0.025995  0.031137  0.035801   \n",
              "46    0.096114  0.095362  0.095047  0.095447  0.096676  0.098677  0.101247   \n",
              "54   -0.041972 -0.048778 -0.055266 -0.061636 -0.067728 -0.073065 -0.076978   \n",
              "55    0.050686  0.056807  0.061922  0.066330  0.070463  0.074831  0.079964   \n",
              "71   -0.511413 -0.507140 -0.469849 -0.408462 -0.333769 -0.256404 -0.185178   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5971  0.005315 -0.043084 -0.083200 -0.110473 -0.122973 -0.121490 -0.109050   \n",
              "5981 -0.005281 -0.018280 -0.031669 -0.042939 -0.050464 -0.053648 -0.052817   \n",
              "5992 -0.084734 -0.091664 -0.098196 -0.101411 -0.098148 -0.085744 -0.062829   \n",
              "5994  0.008461  0.011468  0.012707  0.012096  0.009875  0.006558  0.002841   \n",
              "5999  0.052145  0.038833  0.024907  0.010402 -0.004429 -0.019087 -0.032867   \n",
              "\n",
              "             7         8         9  ...       249       250       251  \\\n",
              "30    0.040075  0.044195  0.048538  ...  0.044631  0.050399  0.057432   \n",
              "46    0.104083  0.106844  0.109202  ... -0.004398 -0.008214 -0.013081   \n",
              "54   -0.078796 -0.078050 -0.074630  ... -0.102289 -0.108650 -0.114708   \n",
              "55    0.086349  0.094365  0.104239  ...  0.125449  0.136371  0.147691   \n",
              "71   -0.126038 -0.081724 -0.052058  ...  0.031533  0.034874  0.038518   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5971 -0.090022 -0.069069 -0.050204  ... -0.027012 -0.029614 -0.031356   \n",
              "5981 -0.048958 -0.043371 -0.037307  ... -0.016826 -0.013496 -0.011275   \n",
              "5992 -0.030004  0.009808  0.051498  ...  0.072150  0.081214  0.090895   \n",
              "5994 -0.000513 -0.002782 -0.003375  ... -0.048723 -0.051678 -0.052151   \n",
              "5999 -0.044991 -0.054774 -0.061789  ... -0.056943 -0.054300 -0.054324   \n",
              "\n",
              "           252       253       254       255   pred  y_test  compare  \n",
              "30    0.066046  0.076371  0.088327  0.101648   85.0    36.0       no  \n",
              "46   -0.019006 -0.025674 -0.032320 -0.037693   83.0    80.0       no  \n",
              "54   -0.119718 -0.122885 -0.123496 -0.121095   20.0    71.0       no  \n",
              "55    0.159697  0.172642  0.186692  0.201860   41.0    50.0       no  \n",
              "71    0.042180  0.045745  0.049241  0.052764    4.0    93.0       no  \n",
              "...        ...       ...       ...       ...    ...     ...      ...  \n",
              "5971 -0.033020 -0.035244 -0.038329 -0.042129   95.0    23.0       no  \n",
              "5981 -0.010594 -0.011830 -0.015208 -0.020697   52.0    40.0       no  \n",
              "5992  0.101388  0.112932  0.125713  0.139775  100.0    83.0       no  \n",
              "5994 -0.050205 -0.046318 -0.041326 -0.036264   95.0    49.0       no  \n",
              "5999 -0.058068 -0.065599 -0.075635 -0.085448   45.0    37.0       no  \n",
              "\n",
              "[545 rows x 259 columns]"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_1 = predict[predict[\"compare\"]=='no']\n",
        "predict_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNFZsfEjCqM8"
      },
      "source": [
        "# 3.lowpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMx8PcCaCqM9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import itertools\n",
        "import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import (CosineAnnealingLR,\n",
        "                                      CosineAnnealingWarmRestarts,\n",
        "                                      StepLR,\n",
        "                                      ExponentialLR)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, auc, f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5De8og7-CqM-"
      },
      "outputs": [],
      "source": [
        "import tqdm, re, sys\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, Flatten, BatchNormalization, Dense\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AILwNQqCqM-"
      },
      "outputs": [],
      "source": [
        "data_total = pd.read_csv('/content/drive/MyDrive/model_2s/total_low.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "fd7e2e78-6b75-4027-88b3-cb52d220b842",
        "id": "PAiyJ0wNCqM-"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "0      1.697478  1.713703  1.728594  1.741144  1.750717  1.757105  1.760490   \n",
              "1      1.709674  1.710317  1.711171  1.712183  1.713227  1.714166  1.714897   \n",
              "2      1.757857  1.761049  1.763568  1.765083  1.765388  1.764480  1.762595   \n",
              "3      1.889883  1.889929  1.891485  1.895719  1.903396  1.914786  1.929653   \n",
              "4      1.876008  1.830252  1.784833  1.741100  1.700343  1.663689  1.631993   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "17995  1.562186  1.580260  1.590865  1.595333  1.595857  1.594849  1.594406   \n",
              "17996  1.597548  1.595698  1.594912  1.595167  1.596213  1.597637  1.598970   \n",
              "17997  1.520984  1.516451  1.512894  1.510777  1.510324  1.511420  1.513570   \n",
              "17998  1.575260  1.571225  1.568130  1.566590  1.567050  1.569659  1.574187   \n",
              "17999  1.599834  1.599558  1.598638  1.596714  1.593627  1.589487  1.584661   \n",
              "\n",
              "            7         8         9    ...       503       504       505  \\\n",
              "0      1.761353  1.760349  1.758191  ...  1.694451  1.696899  1.699745   \n",
              "1      1.715389  1.715680  1.715858  ...  1.739826  1.739925  1.740406   \n",
              "2      1.760185  1.757859  1.756279  ...  1.701614  1.704703  1.707794   \n",
              "3      1.947339  1.966906  1.987309  ...  2.130833  2.124523  2.111957   \n",
              "4      1.605760  1.585105  1.569759  ...  1.641277  1.612898  1.590416   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "17995  1.595965  1.600169  1.606928  ...  1.609903  1.611269  1.612058   \n",
              "17996  1.599797  1.599838  1.598980  ...  1.595455  1.593952  1.593380   \n",
              "17997  1.515967  1.517666  1.517848  ...  1.600670  1.597018  1.594806   \n",
              "17998  1.580032  1.586320  1.592084  ...  1.592516  1.596574  1.599401   \n",
              "17999  1.579703  1.575233  1.571814  ...  1.801024  1.812046  1.822807   \n",
              "\n",
              "            506       507       508       509       510       511    512  \n",
              "0      1.702543  1.704941  1.706748  1.707952  1.708690  1.709187    1.0  \n",
              "1      1.741383  1.742927  1.745059  1.747751  1.750910  1.754365    1.0  \n",
              "2      1.710813  1.713725  1.716508  1.719121  1.721462  1.723356    1.0  \n",
              "3      2.093147  2.068352  2.038026  2.002789  1.963408  1.920794    1.0  \n",
              "4      1.573456  1.561349  1.553256  1.548297  1.545665  1.544707    1.0  \n",
              "...         ...       ...       ...       ...       ...       ...    ...  \n",
              "17995  1.612049  1.611103  1.609213  1.606538  1.603402  1.600248  100.0  \n",
              "17996  1.593925  1.595443  1.597461  1.599283  1.600176  1.599565  100.0  \n",
              "17997  1.593269  1.591762  1.589812  1.587139  1.583680  1.579595  100.0  \n",
              "17998  1.600918  1.601328  1.601033  1.600493  1.600067  1.599890  100.0  \n",
              "17999  1.833107  1.842928  1.852499  1.862298  1.872954  1.885091  100.0  \n",
              "\n",
              "[18000 rows x 513 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1825f66-bb9e-4959-a44a-f233bf2f51dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.697478</td>\n",
              "      <td>1.713703</td>\n",
              "      <td>1.728594</td>\n",
              "      <td>1.741144</td>\n",
              "      <td>1.750717</td>\n",
              "      <td>1.757105</td>\n",
              "      <td>1.760490</td>\n",
              "      <td>1.761353</td>\n",
              "      <td>1.760349</td>\n",
              "      <td>1.758191</td>\n",
              "      <td>...</td>\n",
              "      <td>1.694451</td>\n",
              "      <td>1.696899</td>\n",
              "      <td>1.699745</td>\n",
              "      <td>1.702543</td>\n",
              "      <td>1.704941</td>\n",
              "      <td>1.706748</td>\n",
              "      <td>1.707952</td>\n",
              "      <td>1.708690</td>\n",
              "      <td>1.709187</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.709674</td>\n",
              "      <td>1.710317</td>\n",
              "      <td>1.711171</td>\n",
              "      <td>1.712183</td>\n",
              "      <td>1.713227</td>\n",
              "      <td>1.714166</td>\n",
              "      <td>1.714897</td>\n",
              "      <td>1.715389</td>\n",
              "      <td>1.715680</td>\n",
              "      <td>1.715858</td>\n",
              "      <td>...</td>\n",
              "      <td>1.739826</td>\n",
              "      <td>1.739925</td>\n",
              "      <td>1.740406</td>\n",
              "      <td>1.741383</td>\n",
              "      <td>1.742927</td>\n",
              "      <td>1.745059</td>\n",
              "      <td>1.747751</td>\n",
              "      <td>1.750910</td>\n",
              "      <td>1.754365</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.757857</td>\n",
              "      <td>1.761049</td>\n",
              "      <td>1.763568</td>\n",
              "      <td>1.765083</td>\n",
              "      <td>1.765388</td>\n",
              "      <td>1.764480</td>\n",
              "      <td>1.762595</td>\n",
              "      <td>1.760185</td>\n",
              "      <td>1.757859</td>\n",
              "      <td>1.756279</td>\n",
              "      <td>...</td>\n",
              "      <td>1.701614</td>\n",
              "      <td>1.704703</td>\n",
              "      <td>1.707794</td>\n",
              "      <td>1.710813</td>\n",
              "      <td>1.713725</td>\n",
              "      <td>1.716508</td>\n",
              "      <td>1.719121</td>\n",
              "      <td>1.721462</td>\n",
              "      <td>1.723356</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.889883</td>\n",
              "      <td>1.889929</td>\n",
              "      <td>1.891485</td>\n",
              "      <td>1.895719</td>\n",
              "      <td>1.903396</td>\n",
              "      <td>1.914786</td>\n",
              "      <td>1.929653</td>\n",
              "      <td>1.947339</td>\n",
              "      <td>1.966906</td>\n",
              "      <td>1.987309</td>\n",
              "      <td>...</td>\n",
              "      <td>2.130833</td>\n",
              "      <td>2.124523</td>\n",
              "      <td>2.111957</td>\n",
              "      <td>2.093147</td>\n",
              "      <td>2.068352</td>\n",
              "      <td>2.038026</td>\n",
              "      <td>2.002789</td>\n",
              "      <td>1.963408</td>\n",
              "      <td>1.920794</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.876008</td>\n",
              "      <td>1.830252</td>\n",
              "      <td>1.784833</td>\n",
              "      <td>1.741100</td>\n",
              "      <td>1.700343</td>\n",
              "      <td>1.663689</td>\n",
              "      <td>1.631993</td>\n",
              "      <td>1.605760</td>\n",
              "      <td>1.585105</td>\n",
              "      <td>1.569759</td>\n",
              "      <td>...</td>\n",
              "      <td>1.641277</td>\n",
              "      <td>1.612898</td>\n",
              "      <td>1.590416</td>\n",
              "      <td>1.573456</td>\n",
              "      <td>1.561349</td>\n",
              "      <td>1.553256</td>\n",
              "      <td>1.548297</td>\n",
              "      <td>1.545665</td>\n",
              "      <td>1.544707</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17995</th>\n",
              "      <td>1.562186</td>\n",
              "      <td>1.580260</td>\n",
              "      <td>1.590865</td>\n",
              "      <td>1.595333</td>\n",
              "      <td>1.595857</td>\n",
              "      <td>1.594849</td>\n",
              "      <td>1.594406</td>\n",
              "      <td>1.595965</td>\n",
              "      <td>1.600169</td>\n",
              "      <td>1.606928</td>\n",
              "      <td>...</td>\n",
              "      <td>1.609903</td>\n",
              "      <td>1.611269</td>\n",
              "      <td>1.612058</td>\n",
              "      <td>1.612049</td>\n",
              "      <td>1.611103</td>\n",
              "      <td>1.609213</td>\n",
              "      <td>1.606538</td>\n",
              "      <td>1.603402</td>\n",
              "      <td>1.600248</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17996</th>\n",
              "      <td>1.597548</td>\n",
              "      <td>1.595698</td>\n",
              "      <td>1.594912</td>\n",
              "      <td>1.595167</td>\n",
              "      <td>1.596213</td>\n",
              "      <td>1.597637</td>\n",
              "      <td>1.598970</td>\n",
              "      <td>1.599797</td>\n",
              "      <td>1.599838</td>\n",
              "      <td>1.598980</td>\n",
              "      <td>...</td>\n",
              "      <td>1.595455</td>\n",
              "      <td>1.593952</td>\n",
              "      <td>1.593380</td>\n",
              "      <td>1.593925</td>\n",
              "      <td>1.595443</td>\n",
              "      <td>1.597461</td>\n",
              "      <td>1.599283</td>\n",
              "      <td>1.600176</td>\n",
              "      <td>1.599565</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17997</th>\n",
              "      <td>1.520984</td>\n",
              "      <td>1.516451</td>\n",
              "      <td>1.512894</td>\n",
              "      <td>1.510777</td>\n",
              "      <td>1.510324</td>\n",
              "      <td>1.511420</td>\n",
              "      <td>1.513570</td>\n",
              "      <td>1.515967</td>\n",
              "      <td>1.517666</td>\n",
              "      <td>1.517848</td>\n",
              "      <td>...</td>\n",
              "      <td>1.600670</td>\n",
              "      <td>1.597018</td>\n",
              "      <td>1.594806</td>\n",
              "      <td>1.593269</td>\n",
              "      <td>1.591762</td>\n",
              "      <td>1.589812</td>\n",
              "      <td>1.587139</td>\n",
              "      <td>1.583680</td>\n",
              "      <td>1.579595</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17998</th>\n",
              "      <td>1.575260</td>\n",
              "      <td>1.571225</td>\n",
              "      <td>1.568130</td>\n",
              "      <td>1.566590</td>\n",
              "      <td>1.567050</td>\n",
              "      <td>1.569659</td>\n",
              "      <td>1.574187</td>\n",
              "      <td>1.580032</td>\n",
              "      <td>1.586320</td>\n",
              "      <td>1.592084</td>\n",
              "      <td>...</td>\n",
              "      <td>1.592516</td>\n",
              "      <td>1.596574</td>\n",
              "      <td>1.599401</td>\n",
              "      <td>1.600918</td>\n",
              "      <td>1.601328</td>\n",
              "      <td>1.601033</td>\n",
              "      <td>1.600493</td>\n",
              "      <td>1.600067</td>\n",
              "      <td>1.599890</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17999</th>\n",
              "      <td>1.599834</td>\n",
              "      <td>1.599558</td>\n",
              "      <td>1.598638</td>\n",
              "      <td>1.596714</td>\n",
              "      <td>1.593627</td>\n",
              "      <td>1.589487</td>\n",
              "      <td>1.584661</td>\n",
              "      <td>1.579703</td>\n",
              "      <td>1.575233</td>\n",
              "      <td>1.571814</td>\n",
              "      <td>...</td>\n",
              "      <td>1.801024</td>\n",
              "      <td>1.812046</td>\n",
              "      <td>1.822807</td>\n",
              "      <td>1.833107</td>\n",
              "      <td>1.842928</td>\n",
              "      <td>1.852499</td>\n",
              "      <td>1.862298</td>\n",
              "      <td>1.872954</td>\n",
              "      <td>1.885091</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18000 rows × 513 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1825f66-bb9e-4959-a44a-f233bf2f51dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1825f66-bb9e-4959-a44a-f233bf2f51dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1825f66-bb9e-4959-a44a-f233bf2f51dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data_total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZmjq-7MCqM_"
      },
      "source": [
        "## 데이터 전체 섞기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J84TcZF6CqM_"
      },
      "outputs": [],
      "source": [
        "data_total=data_total.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqXIK4xUCqM_"
      },
      "outputs": [],
      "source": [
        "data_train=data_total.iloc[0:14400, :]\n",
        "data_val=data_total.iloc[14400:16200, :]\n",
        "data_test=data_total.iloc[16200:18000,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "b8c27775-0339-41d4-94a8-ea2f792cb738",
        "id": "BPr60O7dCqNA"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "16001  1.678120  1.660007  1.643138  1.627678  1.613974  1.602444  1.593452   \n",
              "2233   1.996164  1.983022  1.966811  1.948035  1.927268  1.905082  1.881997   \n",
              "17135  1.612881  1.606697  1.600482  1.595338  1.592100  1.591197  1.592595   \n",
              "11925  1.584283  1.594660  1.604398  1.612894  1.619760  1.624874  1.628378   \n",
              "14461  1.578565  1.575550  1.572518  1.569882  1.567996  1.567088  1.567223   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "13380  1.299977  1.296961  1.295929  1.296972  1.299345  1.301509  1.301453   \n",
              "13951  1.789448  1.807071  1.825282  1.843602  1.861601  1.878967  1.895518   \n",
              "12825  1.627521  1.610135  1.594244  1.581089  1.571523  1.565896  1.564017   \n",
              "6703   1.587773  1.590579  1.594525  1.599089  1.603409  1.606451  1.607252   \n",
              "2718   1.656508  1.674532  1.690911  1.704241  1.713723  1.719277  1.721463   \n",
              "\n",
              "            7         8         9    ...       503       504       505  \\\n",
              "16001  1.587184  1.583566  1.582257  ...  1.687150  1.690127  1.692782   \n",
              "2233   1.858458  1.834857  1.811564  ...  1.491928  1.491751  1.492468   \n",
              "17135  1.595829  1.600118  1.604540  ...  1.595881  1.598186  1.600275   \n",
              "11925  1.630633  1.632150  1.633497  ...  1.531495  1.536493  1.543003   \n",
              "14461  1.568295  1.570050  1.572136  ...  1.526607  1.601567  1.658287   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "13380  1.297275  1.287903  1.273758  ...  1.796426  1.800927  1.804598   \n",
              "13951  1.911169  1.925849  1.939395  ...  1.543197  1.546292  1.550653   \n",
              "12825  1.565204  1.568431  1.572525  ...  1.589589  1.590863  1.593416   \n",
              "6703   1.605169  1.600082  1.592489  ...  1.698117  1.679718  1.659785   \n",
              "2718   1.721291  1.719958  1.718605  ...  1.754088  1.751801  1.750791   \n",
              "\n",
              "            506       507       508       509       510       511   512  \n",
              "16001  1.694982  1.696698  1.698019  1.699140  1.700320  1.701844  89.0  \n",
              "2233   1.493888  1.495770  1.497849  1.499865  1.501605  1.502939  13.0  \n",
              "17135  1.601689  1.602073  1.601255  1.599290  1.596464  1.593253  96.0  \n",
              "11925  1.551048  1.560367  1.570395  1.580319  1.589172  1.595977  67.0  \n",
              "14461  1.697719  1.723120  1.739021  1.750113  1.760301  1.772099  81.0  \n",
              "...         ...       ...       ...       ...       ...       ...   ...  \n",
              "13380  1.807086  1.808256  1.808211  1.807264  1.805848  1.804412  75.0  \n",
              "13951  1.555924  1.561532  1.566747  1.570775  1.572884  1.572522  78.0  \n",
              "12825  1.597655  1.603745  1.611515  1.620443  1.629702  1.638282  72.0  \n",
              "6703   1.639587  1.620506  1.603797  1.590367  1.580617  1.574402  38.0  \n",
              "2718   1.751527  1.754333  1.759350  1.766515  1.775550  1.785986  16.0  \n",
              "\n",
              "[14400 rows x 513 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba838407-6e6e-448f-a0f6-bf1629f8b6bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "      <th>512</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16001</th>\n",
              "      <td>1.678120</td>\n",
              "      <td>1.660007</td>\n",
              "      <td>1.643138</td>\n",
              "      <td>1.627678</td>\n",
              "      <td>1.613974</td>\n",
              "      <td>1.602444</td>\n",
              "      <td>1.593452</td>\n",
              "      <td>1.587184</td>\n",
              "      <td>1.583566</td>\n",
              "      <td>1.582257</td>\n",
              "      <td>...</td>\n",
              "      <td>1.687150</td>\n",
              "      <td>1.690127</td>\n",
              "      <td>1.692782</td>\n",
              "      <td>1.694982</td>\n",
              "      <td>1.696698</td>\n",
              "      <td>1.698019</td>\n",
              "      <td>1.699140</td>\n",
              "      <td>1.700320</td>\n",
              "      <td>1.701844</td>\n",
              "      <td>89.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233</th>\n",
              "      <td>1.996164</td>\n",
              "      <td>1.983022</td>\n",
              "      <td>1.966811</td>\n",
              "      <td>1.948035</td>\n",
              "      <td>1.927268</td>\n",
              "      <td>1.905082</td>\n",
              "      <td>1.881997</td>\n",
              "      <td>1.858458</td>\n",
              "      <td>1.834857</td>\n",
              "      <td>1.811564</td>\n",
              "      <td>...</td>\n",
              "      <td>1.491928</td>\n",
              "      <td>1.491751</td>\n",
              "      <td>1.492468</td>\n",
              "      <td>1.493888</td>\n",
              "      <td>1.495770</td>\n",
              "      <td>1.497849</td>\n",
              "      <td>1.499865</td>\n",
              "      <td>1.501605</td>\n",
              "      <td>1.502939</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17135</th>\n",
              "      <td>1.612881</td>\n",
              "      <td>1.606697</td>\n",
              "      <td>1.600482</td>\n",
              "      <td>1.595338</td>\n",
              "      <td>1.592100</td>\n",
              "      <td>1.591197</td>\n",
              "      <td>1.592595</td>\n",
              "      <td>1.595829</td>\n",
              "      <td>1.600118</td>\n",
              "      <td>1.604540</td>\n",
              "      <td>...</td>\n",
              "      <td>1.595881</td>\n",
              "      <td>1.598186</td>\n",
              "      <td>1.600275</td>\n",
              "      <td>1.601689</td>\n",
              "      <td>1.602073</td>\n",
              "      <td>1.601255</td>\n",
              "      <td>1.599290</td>\n",
              "      <td>1.596464</td>\n",
              "      <td>1.593253</td>\n",
              "      <td>96.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11925</th>\n",
              "      <td>1.584283</td>\n",
              "      <td>1.594660</td>\n",
              "      <td>1.604398</td>\n",
              "      <td>1.612894</td>\n",
              "      <td>1.619760</td>\n",
              "      <td>1.624874</td>\n",
              "      <td>1.628378</td>\n",
              "      <td>1.630633</td>\n",
              "      <td>1.632150</td>\n",
              "      <td>1.633497</td>\n",
              "      <td>...</td>\n",
              "      <td>1.531495</td>\n",
              "      <td>1.536493</td>\n",
              "      <td>1.543003</td>\n",
              "      <td>1.551048</td>\n",
              "      <td>1.560367</td>\n",
              "      <td>1.570395</td>\n",
              "      <td>1.580319</td>\n",
              "      <td>1.589172</td>\n",
              "      <td>1.595977</td>\n",
              "      <td>67.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14461</th>\n",
              "      <td>1.578565</td>\n",
              "      <td>1.575550</td>\n",
              "      <td>1.572518</td>\n",
              "      <td>1.569882</td>\n",
              "      <td>1.567996</td>\n",
              "      <td>1.567088</td>\n",
              "      <td>1.567223</td>\n",
              "      <td>1.568295</td>\n",
              "      <td>1.570050</td>\n",
              "      <td>1.572136</td>\n",
              "      <td>...</td>\n",
              "      <td>1.526607</td>\n",
              "      <td>1.601567</td>\n",
              "      <td>1.658287</td>\n",
              "      <td>1.697719</td>\n",
              "      <td>1.723120</td>\n",
              "      <td>1.739021</td>\n",
              "      <td>1.750113</td>\n",
              "      <td>1.760301</td>\n",
              "      <td>1.772099</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13380</th>\n",
              "      <td>1.299977</td>\n",
              "      <td>1.296961</td>\n",
              "      <td>1.295929</td>\n",
              "      <td>1.296972</td>\n",
              "      <td>1.299345</td>\n",
              "      <td>1.301509</td>\n",
              "      <td>1.301453</td>\n",
              "      <td>1.297275</td>\n",
              "      <td>1.287903</td>\n",
              "      <td>1.273758</td>\n",
              "      <td>...</td>\n",
              "      <td>1.796426</td>\n",
              "      <td>1.800927</td>\n",
              "      <td>1.804598</td>\n",
              "      <td>1.807086</td>\n",
              "      <td>1.808256</td>\n",
              "      <td>1.808211</td>\n",
              "      <td>1.807264</td>\n",
              "      <td>1.805848</td>\n",
              "      <td>1.804412</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13951</th>\n",
              "      <td>1.789448</td>\n",
              "      <td>1.807071</td>\n",
              "      <td>1.825282</td>\n",
              "      <td>1.843602</td>\n",
              "      <td>1.861601</td>\n",
              "      <td>1.878967</td>\n",
              "      <td>1.895518</td>\n",
              "      <td>1.911169</td>\n",
              "      <td>1.925849</td>\n",
              "      <td>1.939395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.543197</td>\n",
              "      <td>1.546292</td>\n",
              "      <td>1.550653</td>\n",
              "      <td>1.555924</td>\n",
              "      <td>1.561532</td>\n",
              "      <td>1.566747</td>\n",
              "      <td>1.570775</td>\n",
              "      <td>1.572884</td>\n",
              "      <td>1.572522</td>\n",
              "      <td>78.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12825</th>\n",
              "      <td>1.627521</td>\n",
              "      <td>1.610135</td>\n",
              "      <td>1.594244</td>\n",
              "      <td>1.581089</td>\n",
              "      <td>1.571523</td>\n",
              "      <td>1.565896</td>\n",
              "      <td>1.564017</td>\n",
              "      <td>1.565204</td>\n",
              "      <td>1.568431</td>\n",
              "      <td>1.572525</td>\n",
              "      <td>...</td>\n",
              "      <td>1.589589</td>\n",
              "      <td>1.590863</td>\n",
              "      <td>1.593416</td>\n",
              "      <td>1.597655</td>\n",
              "      <td>1.603745</td>\n",
              "      <td>1.611515</td>\n",
              "      <td>1.620443</td>\n",
              "      <td>1.629702</td>\n",
              "      <td>1.638282</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6703</th>\n",
              "      <td>1.587773</td>\n",
              "      <td>1.590579</td>\n",
              "      <td>1.594525</td>\n",
              "      <td>1.599089</td>\n",
              "      <td>1.603409</td>\n",
              "      <td>1.606451</td>\n",
              "      <td>1.607252</td>\n",
              "      <td>1.605169</td>\n",
              "      <td>1.600082</td>\n",
              "      <td>1.592489</td>\n",
              "      <td>...</td>\n",
              "      <td>1.698117</td>\n",
              "      <td>1.679718</td>\n",
              "      <td>1.659785</td>\n",
              "      <td>1.639587</td>\n",
              "      <td>1.620506</td>\n",
              "      <td>1.603797</td>\n",
              "      <td>1.590367</td>\n",
              "      <td>1.580617</td>\n",
              "      <td>1.574402</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2718</th>\n",
              "      <td>1.656508</td>\n",
              "      <td>1.674532</td>\n",
              "      <td>1.690911</td>\n",
              "      <td>1.704241</td>\n",
              "      <td>1.713723</td>\n",
              "      <td>1.719277</td>\n",
              "      <td>1.721463</td>\n",
              "      <td>1.721291</td>\n",
              "      <td>1.719958</td>\n",
              "      <td>1.718605</td>\n",
              "      <td>...</td>\n",
              "      <td>1.754088</td>\n",
              "      <td>1.751801</td>\n",
              "      <td>1.750791</td>\n",
              "      <td>1.751527</td>\n",
              "      <td>1.754333</td>\n",
              "      <td>1.759350</td>\n",
              "      <td>1.766515</td>\n",
              "      <td>1.775550</td>\n",
              "      <td>1.785986</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14400 rows × 513 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba838407-6e6e-448f-a0f6-bf1629f8b6bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba838407-6e6e-448f-a0f6-bf1629f8b6bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba838407-6e6e-448f-a0f6-bf1629f8b6bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRBTUea7CqNA"
      },
      "source": [
        "## 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d11cd9-1d32-4b34-f9df-923411f39eab",
        "id": "hDNwSicmCqNA"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y_train = to_categorical(data_train[512])\n",
        "y_test = to_categorical(data_test[512])\n",
        "y_val = to_categorical(data_val[512])\n",
        "y_train[14399]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "b975eecb-f695-4c83-af8e-f911e88ab280",
        "id": "R-4v4I6JCqNA"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "16001  1.678120  1.660007  1.643138  1.627678  1.613974  1.602444  1.593452   \n",
              "2233   1.996164  1.983022  1.966811  1.948035  1.927268  1.905082  1.881997   \n",
              "17135  1.612881  1.606697  1.600482  1.595338  1.592100  1.591197  1.592595   \n",
              "11925  1.584283  1.594660  1.604398  1.612894  1.619760  1.624874  1.628378   \n",
              "14461  1.578565  1.575550  1.572518  1.569882  1.567996  1.567088  1.567223   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "13380  1.299977  1.296961  1.295929  1.296972  1.299345  1.301509  1.301453   \n",
              "13951  1.789448  1.807071  1.825282  1.843602  1.861601  1.878967  1.895518   \n",
              "12825  1.627521  1.610135  1.594244  1.581089  1.571523  1.565896  1.564017   \n",
              "6703   1.587773  1.590579  1.594525  1.599089  1.603409  1.606451  1.607252   \n",
              "2718   1.656508  1.674532  1.690911  1.704241  1.713723  1.719277  1.721463   \n",
              "\n",
              "            7         8         9    ...       502       503       504  \\\n",
              "16001  1.587184  1.583566  1.582257  ...  1.684038  1.687150  1.690127   \n",
              "2233   1.858458  1.834857  1.811564  ...  1.493115  1.491928  1.491751   \n",
              "17135  1.595829  1.600118  1.604540  ...  1.593820  1.595881  1.598186   \n",
              "11925  1.630633  1.632150  1.633497  ...  1.527766  1.531495  1.536493   \n",
              "14461  1.568295  1.570050  1.572136  ...  1.435433  1.526607  1.601567   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "13380  1.297275  1.287903  1.273758  ...  1.791576  1.796426  1.800927   \n",
              "13951  1.911169  1.925849  1.939395  ...  1.541475  1.543197  1.546292   \n",
              "12825  1.565204  1.568431  1.572525  ...  1.589067  1.589589  1.590863   \n",
              "6703   1.605169  1.600082  1.592489  ...  1.714012  1.698117  1.679718   \n",
              "2718   1.721291  1.719958  1.718605  ...  1.757069  1.754088  1.751801   \n",
              "\n",
              "            505       506       507       508       509       510       511  \n",
              "16001  1.692782  1.694982  1.696698  1.698019  1.699140  1.700320  1.701844  \n",
              "2233   1.492468  1.493888  1.495770  1.497849  1.499865  1.501605  1.502939  \n",
              "17135  1.600275  1.601689  1.602073  1.601255  1.599290  1.596464  1.593253  \n",
              "11925  1.543003  1.551048  1.560367  1.570395  1.580319  1.589172  1.595977  \n",
              "14461  1.658287  1.697719  1.723120  1.739021  1.750113  1.760301  1.772099  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "13380  1.804598  1.807086  1.808256  1.808211  1.807264  1.805848  1.804412  \n",
              "13951  1.550653  1.555924  1.561532  1.566747  1.570775  1.572884  1.572522  \n",
              "12825  1.593416  1.597655  1.603745  1.611515  1.620443  1.629702  1.638282  \n",
              "6703   1.659785  1.639587  1.620506  1.603797  1.590367  1.580617  1.574402  \n",
              "2718   1.750791  1.751527  1.754333  1.759350  1.766515  1.775550  1.785986  \n",
              "\n",
              "[14400 rows x 512 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c50a0aa-6f87-4805-a87f-ad9b7ec7f733\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16001</th>\n",
              "      <td>1.678120</td>\n",
              "      <td>1.660007</td>\n",
              "      <td>1.643138</td>\n",
              "      <td>1.627678</td>\n",
              "      <td>1.613974</td>\n",
              "      <td>1.602444</td>\n",
              "      <td>1.593452</td>\n",
              "      <td>1.587184</td>\n",
              "      <td>1.583566</td>\n",
              "      <td>1.582257</td>\n",
              "      <td>...</td>\n",
              "      <td>1.684038</td>\n",
              "      <td>1.687150</td>\n",
              "      <td>1.690127</td>\n",
              "      <td>1.692782</td>\n",
              "      <td>1.694982</td>\n",
              "      <td>1.696698</td>\n",
              "      <td>1.698019</td>\n",
              "      <td>1.699140</td>\n",
              "      <td>1.700320</td>\n",
              "      <td>1.701844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2233</th>\n",
              "      <td>1.996164</td>\n",
              "      <td>1.983022</td>\n",
              "      <td>1.966811</td>\n",
              "      <td>1.948035</td>\n",
              "      <td>1.927268</td>\n",
              "      <td>1.905082</td>\n",
              "      <td>1.881997</td>\n",
              "      <td>1.858458</td>\n",
              "      <td>1.834857</td>\n",
              "      <td>1.811564</td>\n",
              "      <td>...</td>\n",
              "      <td>1.493115</td>\n",
              "      <td>1.491928</td>\n",
              "      <td>1.491751</td>\n",
              "      <td>1.492468</td>\n",
              "      <td>1.493888</td>\n",
              "      <td>1.495770</td>\n",
              "      <td>1.497849</td>\n",
              "      <td>1.499865</td>\n",
              "      <td>1.501605</td>\n",
              "      <td>1.502939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17135</th>\n",
              "      <td>1.612881</td>\n",
              "      <td>1.606697</td>\n",
              "      <td>1.600482</td>\n",
              "      <td>1.595338</td>\n",
              "      <td>1.592100</td>\n",
              "      <td>1.591197</td>\n",
              "      <td>1.592595</td>\n",
              "      <td>1.595829</td>\n",
              "      <td>1.600118</td>\n",
              "      <td>1.604540</td>\n",
              "      <td>...</td>\n",
              "      <td>1.593820</td>\n",
              "      <td>1.595881</td>\n",
              "      <td>1.598186</td>\n",
              "      <td>1.600275</td>\n",
              "      <td>1.601689</td>\n",
              "      <td>1.602073</td>\n",
              "      <td>1.601255</td>\n",
              "      <td>1.599290</td>\n",
              "      <td>1.596464</td>\n",
              "      <td>1.593253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11925</th>\n",
              "      <td>1.584283</td>\n",
              "      <td>1.594660</td>\n",
              "      <td>1.604398</td>\n",
              "      <td>1.612894</td>\n",
              "      <td>1.619760</td>\n",
              "      <td>1.624874</td>\n",
              "      <td>1.628378</td>\n",
              "      <td>1.630633</td>\n",
              "      <td>1.632150</td>\n",
              "      <td>1.633497</td>\n",
              "      <td>...</td>\n",
              "      <td>1.527766</td>\n",
              "      <td>1.531495</td>\n",
              "      <td>1.536493</td>\n",
              "      <td>1.543003</td>\n",
              "      <td>1.551048</td>\n",
              "      <td>1.560367</td>\n",
              "      <td>1.570395</td>\n",
              "      <td>1.580319</td>\n",
              "      <td>1.589172</td>\n",
              "      <td>1.595977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14461</th>\n",
              "      <td>1.578565</td>\n",
              "      <td>1.575550</td>\n",
              "      <td>1.572518</td>\n",
              "      <td>1.569882</td>\n",
              "      <td>1.567996</td>\n",
              "      <td>1.567088</td>\n",
              "      <td>1.567223</td>\n",
              "      <td>1.568295</td>\n",
              "      <td>1.570050</td>\n",
              "      <td>1.572136</td>\n",
              "      <td>...</td>\n",
              "      <td>1.435433</td>\n",
              "      <td>1.526607</td>\n",
              "      <td>1.601567</td>\n",
              "      <td>1.658287</td>\n",
              "      <td>1.697719</td>\n",
              "      <td>1.723120</td>\n",
              "      <td>1.739021</td>\n",
              "      <td>1.750113</td>\n",
              "      <td>1.760301</td>\n",
              "      <td>1.772099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13380</th>\n",
              "      <td>1.299977</td>\n",
              "      <td>1.296961</td>\n",
              "      <td>1.295929</td>\n",
              "      <td>1.296972</td>\n",
              "      <td>1.299345</td>\n",
              "      <td>1.301509</td>\n",
              "      <td>1.301453</td>\n",
              "      <td>1.297275</td>\n",
              "      <td>1.287903</td>\n",
              "      <td>1.273758</td>\n",
              "      <td>...</td>\n",
              "      <td>1.791576</td>\n",
              "      <td>1.796426</td>\n",
              "      <td>1.800927</td>\n",
              "      <td>1.804598</td>\n",
              "      <td>1.807086</td>\n",
              "      <td>1.808256</td>\n",
              "      <td>1.808211</td>\n",
              "      <td>1.807264</td>\n",
              "      <td>1.805848</td>\n",
              "      <td>1.804412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13951</th>\n",
              "      <td>1.789448</td>\n",
              "      <td>1.807071</td>\n",
              "      <td>1.825282</td>\n",
              "      <td>1.843602</td>\n",
              "      <td>1.861601</td>\n",
              "      <td>1.878967</td>\n",
              "      <td>1.895518</td>\n",
              "      <td>1.911169</td>\n",
              "      <td>1.925849</td>\n",
              "      <td>1.939395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.541475</td>\n",
              "      <td>1.543197</td>\n",
              "      <td>1.546292</td>\n",
              "      <td>1.550653</td>\n",
              "      <td>1.555924</td>\n",
              "      <td>1.561532</td>\n",
              "      <td>1.566747</td>\n",
              "      <td>1.570775</td>\n",
              "      <td>1.572884</td>\n",
              "      <td>1.572522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12825</th>\n",
              "      <td>1.627521</td>\n",
              "      <td>1.610135</td>\n",
              "      <td>1.594244</td>\n",
              "      <td>1.581089</td>\n",
              "      <td>1.571523</td>\n",
              "      <td>1.565896</td>\n",
              "      <td>1.564017</td>\n",
              "      <td>1.565204</td>\n",
              "      <td>1.568431</td>\n",
              "      <td>1.572525</td>\n",
              "      <td>...</td>\n",
              "      <td>1.589067</td>\n",
              "      <td>1.589589</td>\n",
              "      <td>1.590863</td>\n",
              "      <td>1.593416</td>\n",
              "      <td>1.597655</td>\n",
              "      <td>1.603745</td>\n",
              "      <td>1.611515</td>\n",
              "      <td>1.620443</td>\n",
              "      <td>1.629702</td>\n",
              "      <td>1.638282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6703</th>\n",
              "      <td>1.587773</td>\n",
              "      <td>1.590579</td>\n",
              "      <td>1.594525</td>\n",
              "      <td>1.599089</td>\n",
              "      <td>1.603409</td>\n",
              "      <td>1.606451</td>\n",
              "      <td>1.607252</td>\n",
              "      <td>1.605169</td>\n",
              "      <td>1.600082</td>\n",
              "      <td>1.592489</td>\n",
              "      <td>...</td>\n",
              "      <td>1.714012</td>\n",
              "      <td>1.698117</td>\n",
              "      <td>1.679718</td>\n",
              "      <td>1.659785</td>\n",
              "      <td>1.639587</td>\n",
              "      <td>1.620506</td>\n",
              "      <td>1.603797</td>\n",
              "      <td>1.590367</td>\n",
              "      <td>1.580617</td>\n",
              "      <td>1.574402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2718</th>\n",
              "      <td>1.656508</td>\n",
              "      <td>1.674532</td>\n",
              "      <td>1.690911</td>\n",
              "      <td>1.704241</td>\n",
              "      <td>1.713723</td>\n",
              "      <td>1.719277</td>\n",
              "      <td>1.721463</td>\n",
              "      <td>1.721291</td>\n",
              "      <td>1.719958</td>\n",
              "      <td>1.718605</td>\n",
              "      <td>...</td>\n",
              "      <td>1.757069</td>\n",
              "      <td>1.754088</td>\n",
              "      <td>1.751801</td>\n",
              "      <td>1.750791</td>\n",
              "      <td>1.751527</td>\n",
              "      <td>1.754333</td>\n",
              "      <td>1.759350</td>\n",
              "      <td>1.766515</td>\n",
              "      <td>1.775550</td>\n",
              "      <td>1.785986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14400 rows × 512 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c50a0aa-6f87-4805-a87f-ad9b7ec7f733')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c50a0aa-6f87-4805-a87f-ad9b7ec7f733 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c50a0aa-6f87-4805-a87f-ad9b7ec7f733');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data_train.drop([512], axis=1, inplace=True)\n",
        "data_test.drop([512], axis=1, inplace=True)\n",
        "data_val.drop([512], axis=1, inplace=True)\n",
        "data_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QGLEe_CCqNB"
      },
      "outputs": [],
      "source": [
        "X_train=data_train.values\n",
        "X_test=data_test.values\n",
        "X_val=data_val.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57de4864-29ab-499a-e163-96f49cad44aa",
        "id": "bs46KkHnCqNB"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14400, 512, 1)\n",
            "(1800, 512, 1)\n",
            "(1800, 512, 1)\n",
            "(14400, 101)\n",
            "(1800, 101)\n",
            "(1800, 101)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba156486-4c0b-446c-8bb0-2ca6c0a72c87",
        "id": "6fSvD58TCqNB"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14400, 512, 1), (1800, 512, 1), (1800, 512, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\n",
        "X_train = X_train.reshape(14400, 512, 1)\n",
        "X_test = X_test.reshape(1800, 512, 1)\n",
        "X_val = X_val.reshape(1800, 512, 1)\n",
        "X_train.shape, X_test.shape, X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8UMARndCqNB"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d20884-33bd-441f-a5b3-13d5efdca8c9",
        "id": "EsKxbDbFCqNC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 512, 150)          91200     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 512, 50)           40200     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 512, 50)           20200     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25600)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 25600)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 101)               2585701   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,737,301\n",
            "Trainable params: 2,737,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Input, Embedding, GRU, LSTM, SimpleRNN, MaxPooling1D, GlobalMaxPool1D, CuDNNGRU\n",
        "from keras.layers import Dropout, Dense, Activation, Flatten, Conv1D, SpatialDropout1D\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=150, return_sequences=True, input_shape=(512,1))) #shape[1]=열\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(101, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUHjtj31CqNC"
      },
      "source": [
        "## 모델학습/평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00774a8b-f2e8-4cff-d227-d111005cb24e",
        "id": "EmKhJr6_CqNC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 6s 395ms/step - loss: 0.0098 - accuracy: 0.0126 - val_loss: 0.0098 - val_accuracy: 0.0094\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0116 - val_loss: 0.0098 - val_accuracy: 0.0172\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0098 - accuracy: 0.0130 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.0099 - accuracy: 0.0091 - val_loss: 0.0098 - val_accuracy: 0.0089\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 6s 404ms/step - loss: 0.0098 - accuracy: 0.0098 - val_loss: 0.0098 - val_accuracy: 0.0100\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.0098 - accuracy: 0.0120 - val_loss: 0.0098 - val_accuracy: 0.0094\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 0.0098 - accuracy: 0.0134 - val_loss: 0.0098 - val_accuracy: 0.0050\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0098 - accuracy: 0.0113 - val_loss: 0.0098 - val_accuracy: 0.0083\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0109 - val_loss: 0.0098 - val_accuracy: 0.0133\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 6s 395ms/step - loss: 0.0098 - accuracy: 0.0111 - val_loss: 0.0098 - val_accuracy: 0.0144\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0128 - val_loss: 0.0098 - val_accuracy: 0.0167\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 6s 395ms/step - loss: 0.0098 - accuracy: 0.0142 - val_loss: 0.0098 - val_accuracy: 0.0133\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 6s 394ms/step - loss: 0.0098 - accuracy: 0.0120 - val_loss: 0.0098 - val_accuracy: 0.0067\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 6s 394ms/step - loss: 0.0098 - accuracy: 0.0120 - val_loss: 0.0098 - val_accuracy: 0.0094\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 6s 395ms/step - loss: 0.0098 - accuracy: 0.0117 - val_loss: 0.0098 - val_accuracy: 0.0139\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 6s 395ms/step - loss: 0.0098 - accuracy: 0.0133 - val_loss: 0.0098 - val_accuracy: 0.0133\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 6s 395ms/step - loss: 0.0098 - accuracy: 0.0137 - val_loss: 0.0098 - val_accuracy: 0.0078\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0110 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0156 - val_loss: 0.0098 - val_accuracy: 0.0067\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0098 - accuracy: 0.0107 - val_loss: 0.0098 - val_accuracy: 0.0156\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0098 - accuracy: 0.0199 - val_loss: 0.0098 - val_accuracy: 0.0183\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0098 - accuracy: 0.0137 - val_loss: 0.0098 - val_accuracy: 0.0100\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0115 - val_loss: 0.0098 - val_accuracy: 0.0078\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0145 - val_loss: 0.0098 - val_accuracy: 0.0050\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0149 - val_loss: 0.0098 - val_accuracy: 0.0061\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0146 - val_loss: 0.0098 - val_accuracy: 0.0094\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0165 - val_loss: 0.0098 - val_accuracy: 0.0078\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0131 - val_loss: 0.0098 - val_accuracy: 0.0178\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0181 - val_loss: 0.0098 - val_accuracy: 0.0239\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0183 - val_loss: 0.0098 - val_accuracy: 0.0061\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0178 - val_loss: 0.0098 - val_accuracy: 0.0283\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0312 - val_loss: 0.0098 - val_accuracy: 0.0117\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0219 - val_loss: 0.0098 - val_accuracy: 0.0111\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0229 - val_loss: 0.0098 - val_accuracy: 0.0172\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0352 - val_loss: 0.0098 - val_accuracy: 0.0228\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0310 - val_loss: 0.0098 - val_accuracy: 0.0139\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0174 - val_loss: 0.0098 - val_accuracy: 0.0133\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 6s 395ms/step - loss: 0.0098 - accuracy: 0.0216 - val_loss: 0.0098 - val_accuracy: 0.0100\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0172 - val_loss: 0.0098 - val_accuracy: 0.0106\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0153 - val_loss: 0.0098 - val_accuracy: 0.0150\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0251 - val_loss: 0.0098 - val_accuracy: 0.0222\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0098 - accuracy: 0.0369 - val_loss: 0.0098 - val_accuracy: 0.0161\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 6s 396ms/step - loss: 0.0098 - accuracy: 0.0351 - val_loss: 0.0098 - val_accuracy: 0.0189\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0097 - accuracy: 0.0390 - val_loss: 0.0098 - val_accuracy: 0.0139\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0097 - accuracy: 0.0366 - val_loss: 0.0098 - val_accuracy: 0.0167\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0097 - accuracy: 0.0512 - val_loss: 0.0098 - val_accuracy: 0.0244\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0097 - accuracy: 0.0617 - val_loss: 0.0098 - val_accuracy: 0.0378\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0097 - accuracy: 0.0736 - val_loss: 0.0098 - val_accuracy: 0.0500\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0096 - accuracy: 0.0885 - val_loss: 0.0098 - val_accuracy: 0.0406\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0096 - accuracy: 0.0908 - val_loss: 0.0099 - val_accuracy: 0.0489\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0096 - accuracy: 0.0962 - val_loss: 0.0098 - val_accuracy: 0.0606\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0096 - accuracy: 0.1078 - val_loss: 0.0098 - val_accuracy: 0.0572\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0096 - accuracy: 0.1131 - val_loss: 0.0098 - val_accuracy: 0.0611\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0095 - accuracy: 0.1266 - val_loss: 0.0100 - val_accuracy: 0.0489\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0095 - accuracy: 0.1227 - val_loss: 0.0098 - val_accuracy: 0.0683\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0094 - accuracy: 0.1394 - val_loss: 0.0098 - val_accuracy: 0.0867\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0094 - accuracy: 0.1485 - val_loss: 0.0098 - val_accuracy: 0.0839\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0094 - accuracy: 0.1565 - val_loss: 0.0099 - val_accuracy: 0.0750\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0093 - accuracy: 0.1576 - val_loss: 0.0099 - val_accuracy: 0.0817\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0093 - accuracy: 0.1675 - val_loss: 0.0098 - val_accuracy: 0.1006\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0093 - accuracy: 0.1673 - val_loss: 0.0098 - val_accuracy: 0.1000\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0092 - accuracy: 0.1804 - val_loss: 0.0097 - val_accuracy: 0.1067\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0090 - accuracy: 0.2113 - val_loss: 0.0097 - val_accuracy: 0.1206\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0089 - accuracy: 0.2168 - val_loss: 0.0097 - val_accuracy: 0.1228\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0088 - accuracy: 0.2344 - val_loss: 0.0097 - val_accuracy: 0.1467\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0087 - accuracy: 0.2509 - val_loss: 0.0096 - val_accuracy: 0.1544\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0086 - accuracy: 0.2584 - val_loss: 0.0096 - val_accuracy: 0.1400\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0085 - accuracy: 0.2687 - val_loss: 0.0095 - val_accuracy: 0.1644\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0083 - accuracy: 0.2923 - val_loss: 0.0094 - val_accuracy: 0.1850\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0082 - accuracy: 0.3067 - val_loss: 0.0093 - val_accuracy: 0.2094\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0080 - accuracy: 0.3251 - val_loss: 0.0095 - val_accuracy: 0.1733\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0080 - accuracy: 0.3332 - val_loss: 0.0091 - val_accuracy: 0.2233\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0077 - accuracy: 0.3583 - val_loss: 0.0089 - val_accuracy: 0.2389\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0076 - accuracy: 0.3694 - val_loss: 0.0089 - val_accuracy: 0.2494\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0074 - accuracy: 0.3905 - val_loss: 0.0090 - val_accuracy: 0.2494\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0073 - accuracy: 0.4035 - val_loss: 0.0089 - val_accuracy: 0.2656\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0071 - accuracy: 0.4216 - val_loss: 0.0085 - val_accuracy: 0.2917\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0069 - accuracy: 0.4443 - val_loss: 0.0083 - val_accuracy: 0.3156\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0067 - accuracy: 0.4641 - val_loss: 0.0083 - val_accuracy: 0.3200\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0064 - accuracy: 0.4865 - val_loss: 0.0083 - val_accuracy: 0.3300\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0064 - accuracy: 0.4974 - val_loss: 0.0082 - val_accuracy: 0.3428\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0062 - accuracy: 0.5133 - val_loss: 0.0079 - val_accuracy: 0.3733\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0059 - accuracy: 0.5326 - val_loss: 0.0078 - val_accuracy: 0.3894\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0057 - accuracy: 0.5525 - val_loss: 0.0075 - val_accuracy: 0.4100\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0055 - accuracy: 0.5774 - val_loss: 0.0077 - val_accuracy: 0.3922\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0052 - accuracy: 0.5948 - val_loss: 0.0071 - val_accuracy: 0.4550\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0051 - accuracy: 0.6128 - val_loss: 0.0068 - val_accuracy: 0.4794\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0048 - accuracy: 0.6331 - val_loss: 0.0070 - val_accuracy: 0.4617\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0046 - accuracy: 0.6507 - val_loss: 0.0064 - val_accuracy: 0.5194\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0043 - accuracy: 0.6774 - val_loss: 0.0072 - val_accuracy: 0.4594\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0045 - accuracy: 0.6643 - val_loss: 0.0063 - val_accuracy: 0.5372\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0040 - accuracy: 0.6975 - val_loss: 0.0057 - val_accuracy: 0.5789\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0038 - accuracy: 0.7158 - val_loss: 0.0056 - val_accuracy: 0.5861\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0036 - accuracy: 0.7312 - val_loss: 0.0056 - val_accuracy: 0.5867\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0034 - accuracy: 0.7444 - val_loss: 0.0056 - val_accuracy: 0.5939\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0034 - accuracy: 0.7536 - val_loss: 0.0055 - val_accuracy: 0.5894\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0031 - accuracy: 0.7671 - val_loss: 0.0049 - val_accuracy: 0.6411\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0030 - accuracy: 0.7781 - val_loss: 0.0051 - val_accuracy: 0.6306\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0030 - accuracy: 0.7795 - val_loss: 0.0053 - val_accuracy: 0.6100\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0029 - accuracy: 0.7866 - val_loss: 0.0048 - val_accuracy: 0.6472\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0027 - accuracy: 0.8020 - val_loss: 0.0048 - val_accuracy: 0.6544\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0025 - accuracy: 0.8114 - val_loss: 0.0045 - val_accuracy: 0.6800\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0025 - accuracy: 0.8189 - val_loss: 0.0046 - val_accuracy: 0.6728\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0025 - accuracy: 0.8156 - val_loss: 0.0045 - val_accuracy: 0.6683\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0023 - accuracy: 0.8295 - val_loss: 0.0042 - val_accuracy: 0.6972\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0022 - accuracy: 0.8400 - val_loss: 0.0043 - val_accuracy: 0.6900\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0022 - accuracy: 0.8423 - val_loss: 0.0042 - val_accuracy: 0.7044\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0020 - accuracy: 0.8511 - val_loss: 0.0041 - val_accuracy: 0.7194\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0020 - accuracy: 0.8526 - val_loss: 0.0048 - val_accuracy: 0.6567\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0020 - accuracy: 0.8576 - val_loss: 0.0043 - val_accuracy: 0.7028\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0019 - accuracy: 0.8649 - val_loss: 0.0041 - val_accuracy: 0.7072\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0018 - accuracy: 0.8696 - val_loss: 0.0037 - val_accuracy: 0.7350\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0018 - accuracy: 0.8706 - val_loss: 0.0041 - val_accuracy: 0.7050\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0018 - accuracy: 0.8715 - val_loss: 0.0040 - val_accuracy: 0.7228\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0017 - accuracy: 0.8768 - val_loss: 0.0038 - val_accuracy: 0.7383\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0016 - accuracy: 0.8839 - val_loss: 0.0040 - val_accuracy: 0.7133\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0015 - accuracy: 0.8883 - val_loss: 0.0035 - val_accuracy: 0.7528\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0014 - accuracy: 0.8925 - val_loss: 0.0034 - val_accuracy: 0.7567\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0014 - accuracy: 0.8944 - val_loss: 0.0033 - val_accuracy: 0.7661\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0013 - accuracy: 0.8979 - val_loss: 0.0034 - val_accuracy: 0.7594\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0013 - accuracy: 0.8996 - val_loss: 0.0033 - val_accuracy: 0.7700\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0013 - accuracy: 0.9036 - val_loss: 0.0033 - val_accuracy: 0.7656\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0012 - accuracy: 0.9072 - val_loss: 0.0033 - val_accuracy: 0.7633\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0012 - accuracy: 0.9074 - val_loss: 0.0032 - val_accuracy: 0.7717\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0012 - accuracy: 0.9081 - val_loss: 0.0037 - val_accuracy: 0.7533\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0013 - accuracy: 0.9058 - val_loss: 0.0033 - val_accuracy: 0.7700\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0012 - accuracy: 0.9111 - val_loss: 0.0033 - val_accuracy: 0.7667\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0011 - accuracy: 0.9144 - val_loss: 0.0031 - val_accuracy: 0.7783\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0011 - accuracy: 0.9170 - val_loss: 0.0032 - val_accuracy: 0.7772\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0010 - accuracy: 0.9197 - val_loss: 0.0030 - val_accuracy: 0.7828\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0010 - accuracy: 0.9201 - val_loss: 0.0030 - val_accuracy: 0.7978\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0011 - accuracy: 0.9177 - val_loss: 0.0033 - val_accuracy: 0.7633\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0010 - accuracy: 0.9208 - val_loss: 0.0038 - val_accuracy: 0.7278\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0012 - accuracy: 0.9147 - val_loss: 0.0032 - val_accuracy: 0.7778\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0011 - accuracy: 0.9212 - val_loss: 0.0031 - val_accuracy: 0.7817\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0010 - accuracy: 0.9236 - val_loss: 0.0032 - val_accuracy: 0.7800\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 9.7230e-04 - accuracy: 0.9274 - val_loss: 0.0029 - val_accuracy: 0.7989\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 9.2239e-04 - accuracy: 0.9299 - val_loss: 0.0029 - val_accuracy: 0.8039\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 8.8079e-04 - accuracy: 0.9323 - val_loss: 0.0031 - val_accuracy: 0.7828\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 9.1915e-04 - accuracy: 0.9311 - val_loss: 0.0030 - val_accuracy: 0.7911\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 8.7589e-04 - accuracy: 0.9324 - val_loss: 0.0029 - val_accuracy: 0.8033\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 8.7644e-04 - accuracy: 0.9323 - val_loss: 0.0028 - val_accuracy: 0.8061\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 8.6710e-04 - accuracy: 0.9331 - val_loss: 0.0028 - val_accuracy: 0.8078\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 8.5407e-04 - accuracy: 0.9335 - val_loss: 0.0029 - val_accuracy: 0.8044\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 9.2088e-04 - accuracy: 0.9303 - val_loss: 0.0034 - val_accuracy: 0.7667\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 9.2350e-04 - accuracy: 0.9303 - val_loss: 0.0028 - val_accuracy: 0.8028\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 8.2499e-04 - accuracy: 0.9355 - val_loss: 0.0029 - val_accuracy: 0.7967\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 7.9618e-04 - accuracy: 0.9374 - val_loss: 0.0027 - val_accuracy: 0.8150\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 7.5211e-04 - accuracy: 0.9399 - val_loss: 0.0027 - val_accuracy: 0.8122\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 7.3808e-04 - accuracy: 0.9410 - val_loss: 0.0026 - val_accuracy: 0.8211\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 7.1136e-04 - accuracy: 0.9417 - val_loss: 0.0026 - val_accuracy: 0.8117\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 6.9227e-04 - accuracy: 0.9419 - val_loss: 0.0026 - val_accuracy: 0.8194\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 6.8120e-04 - accuracy: 0.9426 - val_loss: 0.0026 - val_accuracy: 0.8222\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 6.7270e-04 - accuracy: 0.9432 - val_loss: 0.0026 - val_accuracy: 0.8156\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.6419e-04 - accuracy: 0.9444 - val_loss: 0.0025 - val_accuracy: 0.8250\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.5483e-04 - accuracy: 0.9454 - val_loss: 0.0025 - val_accuracy: 0.8211\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.4720e-04 - accuracy: 0.9460 - val_loss: 0.0025 - val_accuracy: 0.8244\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.4841e-04 - accuracy: 0.9462 - val_loss: 0.0030 - val_accuracy: 0.7933\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 7.6566e-04 - accuracy: 0.9416 - val_loss: 0.0029 - val_accuracy: 0.8000\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 7.1325e-04 - accuracy: 0.9453 - val_loss: 0.0027 - val_accuracy: 0.8178\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 6.6225e-04 - accuracy: 0.9473 - val_loss: 0.0025 - val_accuracy: 0.8256\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 6.5314e-04 - accuracy: 0.9474 - val_loss: 0.0026 - val_accuracy: 0.8183\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.4081e-04 - accuracy: 0.9483 - val_loss: 0.0025 - val_accuracy: 0.8228\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 6.1764e-04 - accuracy: 0.9492 - val_loss: 0.0025 - val_accuracy: 0.8267\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 6.1847e-04 - accuracy: 0.9492 - val_loss: 0.0024 - val_accuracy: 0.8294\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 6.0220e-04 - accuracy: 0.9506 - val_loss: 0.0025 - val_accuracy: 0.8194\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 5.8283e-04 - accuracy: 0.9519 - val_loss: 0.0024 - val_accuracy: 0.8339\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.7709e-04 - accuracy: 0.9526 - val_loss: 0.0025 - val_accuracy: 0.8239\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.7858e-04 - accuracy: 0.9533 - val_loss: 0.0026 - val_accuracy: 0.8233\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.8785e-04 - accuracy: 0.9531 - val_loss: 0.0024 - val_accuracy: 0.8317\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 5.5770e-04 - accuracy: 0.9542 - val_loss: 0.0024 - val_accuracy: 0.8361\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.3828e-04 - accuracy: 0.9551 - val_loss: 0.0024 - val_accuracy: 0.8361\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 5.4219e-04 - accuracy: 0.9554 - val_loss: 0.0023 - val_accuracy: 0.8383\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.4076e-04 - accuracy: 0.9556 - val_loss: 0.0023 - val_accuracy: 0.8383\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.2214e-04 - accuracy: 0.9571 - val_loss: 0.0023 - val_accuracy: 0.8339\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.0049e-04 - accuracy: 0.9581 - val_loss: 0.0023 - val_accuracy: 0.8372\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.8766e-04 - accuracy: 0.9590 - val_loss: 0.0022 - val_accuracy: 0.8456\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.7467e-04 - accuracy: 0.9598 - val_loss: 0.0022 - val_accuracy: 0.8539\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 4.6755e-04 - accuracy: 0.9608 - val_loss: 0.0022 - val_accuracy: 0.8517\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.7339e-04 - accuracy: 0.9609 - val_loss: 0.0022 - val_accuracy: 0.8422\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.7436e-04 - accuracy: 0.9608 - val_loss: 0.0022 - val_accuracy: 0.8461\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.5927e-04 - accuracy: 0.9619 - val_loss: 0.0025 - val_accuracy: 0.8294\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.2046e-04 - accuracy: 0.9595 - val_loss: 0.0025 - val_accuracy: 0.8261\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 5.2805e-04 - accuracy: 0.9597 - val_loss: 0.0024 - val_accuracy: 0.8350\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.4007e-04 - accuracy: 0.9585 - val_loss: 0.0025 - val_accuracy: 0.8261\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 5.5731e-04 - accuracy: 0.9581 - val_loss: 0.0030 - val_accuracy: 0.7933\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 5.6769e-04 - accuracy: 0.9576 - val_loss: 0.0025 - val_accuracy: 0.8267\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.8923e-04 - accuracy: 0.9623 - val_loss: 0.0024 - val_accuracy: 0.8378\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.5529e-04 - accuracy: 0.9642 - val_loss: 0.0022 - val_accuracy: 0.8406\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 4.3581e-04 - accuracy: 0.9651 - val_loss: 0.0022 - val_accuracy: 0.8411\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 4.1116e-04 - accuracy: 0.9665 - val_loss: 0.0022 - val_accuracy: 0.8456\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.9648e-04 - accuracy: 0.9669 - val_loss: 0.0021 - val_accuracy: 0.8533\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 3.8983e-04 - accuracy: 0.9672 - val_loss: 0.0024 - val_accuracy: 0.8267\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0019 - accuracy: 0.8668 - val_loss: 0.0039 - val_accuracy: 0.7372\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0012 - accuracy: 0.9166 - val_loss: 0.0032 - val_accuracy: 0.7839\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 7.9267e-04 - accuracy: 0.9454 - val_loss: 0.0027 - val_accuracy: 0.8172\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 6.1999e-04 - accuracy: 0.9552 - val_loss: 0.0024 - val_accuracy: 0.8367\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 6.1336e-04 - accuracy: 0.9570 - val_loss: 0.0024 - val_accuracy: 0.8344\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 5.0625e-04 - accuracy: 0.9627 - val_loss: 0.0023 - val_accuracy: 0.8406\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.6314e-04 - accuracy: 0.9650 - val_loss: 0.0023 - val_accuracy: 0.8472\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 6s 404ms/step - loss: 4.3086e-04 - accuracy: 0.9670 - val_loss: 0.0022 - val_accuracy: 0.8517\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.1120e-04 - accuracy: 0.9673 - val_loss: 0.0022 - val_accuracy: 0.8506\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 4.3948e-04 - accuracy: 0.9657 - val_loss: 0.0024 - val_accuracy: 0.8350\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.3263e-04 - accuracy: 0.9663 - val_loss: 0.0022 - val_accuracy: 0.8522\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 4.0001e-04 - accuracy: 0.9682 - val_loss: 0.0020 - val_accuracy: 0.8594\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 3.8155e-04 - accuracy: 0.9690 - val_loss: 0.0020 - val_accuracy: 0.8622\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.6930e-04 - accuracy: 0.9695 - val_loss: 0.0020 - val_accuracy: 0.8611\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.6103e-04 - accuracy: 0.9696 - val_loss: 0.0020 - val_accuracy: 0.8656\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.5972e-04 - accuracy: 0.9699 - val_loss: 0.0020 - val_accuracy: 0.8661\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 3.5254e-04 - accuracy: 0.9703 - val_loss: 0.0019 - val_accuracy: 0.8594\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.4662e-04 - accuracy: 0.9706 - val_loss: 0.0019 - val_accuracy: 0.8656\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.3923e-04 - accuracy: 0.9711 - val_loss: 0.0019 - val_accuracy: 0.8656\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.3068e-04 - accuracy: 0.9718 - val_loss: 0.0019 - val_accuracy: 0.8711\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 3.2772e-04 - accuracy: 0.9722 - val_loss: 0.0019 - val_accuracy: 0.8683\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.2538e-04 - accuracy: 0.9727 - val_loss: 0.0019 - val_accuracy: 0.8678\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 3.1762e-04 - accuracy: 0.9732 - val_loss: 0.0019 - val_accuracy: 0.8722\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.1890e-04 - accuracy: 0.9735 - val_loss: 0.0019 - val_accuracy: 0.8767\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 3.1794e-04 - accuracy: 0.9733 - val_loss: 0.0019 - val_accuracy: 0.8744\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.1369e-04 - accuracy: 0.9737 - val_loss: 0.0018 - val_accuracy: 0.8789\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.1713e-04 - accuracy: 0.9736 - val_loss: 0.0019 - val_accuracy: 0.8722\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.1217e-04 - accuracy: 0.9741 - val_loss: 0.0019 - val_accuracy: 0.8711\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.0587e-04 - accuracy: 0.9743 - val_loss: 0.0019 - val_accuracy: 0.8744\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 3.0481e-04 - accuracy: 0.9743 - val_loss: 0.0019 - val_accuracy: 0.8728\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.0193e-04 - accuracy: 0.9746 - val_loss: 0.0018 - val_accuracy: 0.8733\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.9976e-04 - accuracy: 0.9747 - val_loss: 0.0018 - val_accuracy: 0.8783\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.0095e-04 - accuracy: 0.9747 - val_loss: 0.0019 - val_accuracy: 0.8689\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.9592e-04 - accuracy: 0.9749 - val_loss: 0.0018 - val_accuracy: 0.8756\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.9247e-04 - accuracy: 0.9750 - val_loss: 0.0018 - val_accuracy: 0.8789\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.9189e-04 - accuracy: 0.9750 - val_loss: 0.0018 - val_accuracy: 0.8778\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.8892e-04 - accuracy: 0.9751 - val_loss: 0.0018 - val_accuracy: 0.8733\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.9000e-04 - accuracy: 0.9751 - val_loss: 0.0018 - val_accuracy: 0.8772\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.9026e-04 - accuracy: 0.9751 - val_loss: 0.0018 - val_accuracy: 0.8767\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.8881e-04 - accuracy: 0.9751 - val_loss: 0.0018 - val_accuracy: 0.8756\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.8697e-04 - accuracy: 0.9751 - val_loss: 0.0018 - val_accuracy: 0.8750\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.8662e-04 - accuracy: 0.9751 - val_loss: 0.0018 - val_accuracy: 0.8750\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.8960e-04 - accuracy: 0.9751 - val_loss: 0.0018 - val_accuracy: 0.8744\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.8751e-04 - accuracy: 0.9752 - val_loss: 0.0018 - val_accuracy: 0.8733\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.8454e-04 - accuracy: 0.9753 - val_loss: 0.0018 - val_accuracy: 0.8761\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.8433e-04 - accuracy: 0.9754 - val_loss: 0.0018 - val_accuracy: 0.8761\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.8237e-04 - accuracy: 0.9755 - val_loss: 0.0018 - val_accuracy: 0.8772\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.8117e-04 - accuracy: 0.9756 - val_loss: 0.0018 - val_accuracy: 0.8750\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 6s 406ms/step - loss: 2.8001e-04 - accuracy: 0.9756 - val_loss: 0.0018 - val_accuracy: 0.8711\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.7754e-04 - accuracy: 0.9758 - val_loss: 0.0018 - val_accuracy: 0.8778\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.8105e-04 - accuracy: 0.9758 - val_loss: 0.0018 - val_accuracy: 0.8817\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.7916e-04 - accuracy: 0.9760 - val_loss: 0.0018 - val_accuracy: 0.8783\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.7605e-04 - accuracy: 0.9761 - val_loss: 0.0018 - val_accuracy: 0.8783\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.7521e-04 - accuracy: 0.9762 - val_loss: 0.0018 - val_accuracy: 0.8728\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.7210e-04 - accuracy: 0.9764 - val_loss: 0.0018 - val_accuracy: 0.8800\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.6730e-04 - accuracy: 0.9768 - val_loss: 0.0018 - val_accuracy: 0.8806\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.6573e-04 - accuracy: 0.9772 - val_loss: 0.0019 - val_accuracy: 0.8672\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.6219e-04 - accuracy: 0.9774 - val_loss: 0.0018 - val_accuracy: 0.8728\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.6379e-04 - accuracy: 0.9774 - val_loss: 0.0018 - val_accuracy: 0.8672\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.6042e-04 - accuracy: 0.9776 - val_loss: 0.0017 - val_accuracy: 0.8833\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.5715e-04 - accuracy: 0.9776 - val_loss: 0.0018 - val_accuracy: 0.8794\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.5586e-04 - accuracy: 0.9777 - val_loss: 0.0017 - val_accuracy: 0.8806\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.5503e-04 - accuracy: 0.9777 - val_loss: 0.0017 - val_accuracy: 0.8778\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.5522e-04 - accuracy: 0.9776 - val_loss: 0.0017 - val_accuracy: 0.8839\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.5418e-04 - accuracy: 0.9777 - val_loss: 0.0018 - val_accuracy: 0.8772\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.5337e-04 - accuracy: 0.9777 - val_loss: 0.0017 - val_accuracy: 0.8783\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.5328e-04 - accuracy: 0.9778 - val_loss: 0.0017 - val_accuracy: 0.8778\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.5205e-04 - accuracy: 0.9778 - val_loss: 0.0017 - val_accuracy: 0.8833\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.4943e-04 - accuracy: 0.9781 - val_loss: 0.0018 - val_accuracy: 0.8800\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.4587e-04 - accuracy: 0.9785 - val_loss: 0.0017 - val_accuracy: 0.8828\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.4502e-04 - accuracy: 0.9785 - val_loss: 0.0017 - val_accuracy: 0.8850\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.4183e-04 - accuracy: 0.9787 - val_loss: 0.0018 - val_accuracy: 0.8811\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.5535e-04 - accuracy: 0.9785 - val_loss: 0.0018 - val_accuracy: 0.8800\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.4880e-04 - accuracy: 0.9789 - val_loss: 0.0018 - val_accuracy: 0.8750\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.3727e-04 - accuracy: 0.9797 - val_loss: 0.0018 - val_accuracy: 0.8756\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.3754e-04 - accuracy: 0.9802 - val_loss: 0.0018 - val_accuracy: 0.8739\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.2801e-04 - accuracy: 0.9808 - val_loss: 0.0017 - val_accuracy: 0.8817\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.2507e-04 - accuracy: 0.9808 - val_loss: 0.0017 - val_accuracy: 0.8789\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.2198e-04 - accuracy: 0.9809 - val_loss: 0.0017 - val_accuracy: 0.8839\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.2305e-04 - accuracy: 0.9809 - val_loss: 0.0018 - val_accuracy: 0.8744\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.2793e-04 - accuracy: 0.9807 - val_loss: 0.0017 - val_accuracy: 0.8817\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.2960e-04 - accuracy: 0.9808 - val_loss: 0.0017 - val_accuracy: 0.8789\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.2295e-04 - accuracy: 0.9811 - val_loss: 0.0018 - val_accuracy: 0.8756\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.2252e-04 - accuracy: 0.9810 - val_loss: 0.0017 - val_accuracy: 0.8833\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.1940e-04 - accuracy: 0.9811 - val_loss: 0.0017 - val_accuracy: 0.8817\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.1762e-04 - accuracy: 0.9811 - val_loss: 0.0017 - val_accuracy: 0.8850\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.1604e-04 - accuracy: 0.9812 - val_loss: 0.0017 - val_accuracy: 0.8839\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.1817e-04 - accuracy: 0.9811 - val_loss: 0.0017 - val_accuracy: 0.8800\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 2.1866e-04 - accuracy: 0.9812 - val_loss: 0.0017 - val_accuracy: 0.8872\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.1671e-04 - accuracy: 0.9812 - val_loss: 0.0017 - val_accuracy: 0.8850\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.1645e-04 - accuracy: 0.9814 - val_loss: 0.0017 - val_accuracy: 0.8906\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.1265e-04 - accuracy: 0.9819 - val_loss: 0.0017 - val_accuracy: 0.8872\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.1206e-04 - accuracy: 0.9823 - val_loss: 0.0017 - val_accuracy: 0.8800\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.0836e-04 - accuracy: 0.9827 - val_loss: 0.0017 - val_accuracy: 0.8828\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.1603e-04 - accuracy: 0.9827 - val_loss: 0.0019 - val_accuracy: 0.8717\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.1741e-04 - accuracy: 0.9826 - val_loss: 0.0019 - val_accuracy: 0.8706\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 2.2299e-04 - accuracy: 0.9823 - val_loss: 0.0018 - val_accuracy: 0.8778\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.1670e-04 - accuracy: 0.9826 - val_loss: 0.0020 - val_accuracy: 0.8683\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.1316e-04 - accuracy: 0.9829 - val_loss: 0.0018 - val_accuracy: 0.8800\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.0929e-04 - accuracy: 0.9829 - val_loss: 0.0019 - val_accuracy: 0.8678\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0029 - accuracy: 0.8072 - val_loss: 0.0068 - val_accuracy: 0.5517\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0027 - accuracy: 0.8225 - val_loss: 0.0042 - val_accuracy: 0.7222\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0015 - accuracy: 0.9013 - val_loss: 0.0035 - val_accuracy: 0.7672\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0011 - accuracy: 0.9293 - val_loss: 0.0029 - val_accuracy: 0.8128\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 6.3766e-04 - accuracy: 0.9579 - val_loss: 0.0027 - val_accuracy: 0.8250\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.9782e-04 - accuracy: 0.9665 - val_loss: 0.0027 - val_accuracy: 0.8217\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.5160e-04 - accuracy: 0.9697 - val_loss: 0.0025 - val_accuracy: 0.8383\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 3.4735e-04 - accuracy: 0.9761 - val_loss: 0.0022 - val_accuracy: 0.8528\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.9180e-04 - accuracy: 0.9793 - val_loss: 0.0021 - val_accuracy: 0.8633\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.4757e-04 - accuracy: 0.9818 - val_loss: 0.0020 - val_accuracy: 0.8694\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.3643e-04 - accuracy: 0.9824 - val_loss: 0.0020 - val_accuracy: 0.8672\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.3324e-04 - accuracy: 0.9826 - val_loss: 0.0019 - val_accuracy: 0.8778\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 2.2086e-04 - accuracy: 0.9828 - val_loss: 0.0019 - val_accuracy: 0.8772\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.1276e-04 - accuracy: 0.9833 - val_loss: 0.0019 - val_accuracy: 0.8722\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.1287e-04 - accuracy: 0.9832 - val_loss: 0.0019 - val_accuracy: 0.8706\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.1305e-04 - accuracy: 0.9831 - val_loss: 0.0018 - val_accuracy: 0.8811\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.1000e-04 - accuracy: 0.9833 - val_loss: 0.0018 - val_accuracy: 0.8750\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 2.0737e-04 - accuracy: 0.9833 - val_loss: 0.0019 - val_accuracy: 0.8772\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.0662e-04 - accuracy: 0.9833 - val_loss: 0.0019 - val_accuracy: 0.8728\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.0894e-04 - accuracy: 0.9833 - val_loss: 0.0019 - val_accuracy: 0.8767\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.1040e-04 - accuracy: 0.9833 - val_loss: 0.0018 - val_accuracy: 0.8772\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.0426e-04 - accuracy: 0.9833 - val_loss: 0.0018 - val_accuracy: 0.8806\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.0126e-04 - accuracy: 0.9834 - val_loss: 0.0018 - val_accuracy: 0.8822\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9985e-04 - accuracy: 0.9834 - val_loss: 0.0018 - val_accuracy: 0.8783\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.0050e-04 - accuracy: 0.9834 - val_loss: 0.0018 - val_accuracy: 0.8756\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9951e-04 - accuracy: 0.9833 - val_loss: 0.0018 - val_accuracy: 0.8772\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.0095e-04 - accuracy: 0.9834 - val_loss: 0.0018 - val_accuracy: 0.8817\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 2.0659e-04 - accuracy: 0.9832 - val_loss: 0.0019 - val_accuracy: 0.8661\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.0429e-04 - accuracy: 0.9833 - val_loss: 0.0018 - val_accuracy: 0.8761\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.0112e-04 - accuracy: 0.9833 - val_loss: 0.0018 - val_accuracy: 0.8767\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.0189e-04 - accuracy: 0.9833 - val_loss: 0.0018 - val_accuracy: 0.8800\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.0064e-04 - accuracy: 0.9833 - val_loss: 0.0018 - val_accuracy: 0.8789\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.0149e-04 - accuracy: 0.9833 - val_loss: 0.0018 - val_accuracy: 0.8800\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.0054e-04 - accuracy: 0.9833 - val_loss: 0.0018 - val_accuracy: 0.8778\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9561e-04 - accuracy: 0.9835 - val_loss: 0.0018 - val_accuracy: 0.8806\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9629e-04 - accuracy: 0.9835 - val_loss: 0.0018 - val_accuracy: 0.8800\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.9464e-04 - accuracy: 0.9835 - val_loss: 0.0018 - val_accuracy: 0.8806\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9316e-04 - accuracy: 0.9835 - val_loss: 0.0018 - val_accuracy: 0.8806\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9379e-04 - accuracy: 0.9835 - val_loss: 0.0018 - val_accuracy: 0.8817\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9367e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8861\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9392e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8839\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9343e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8822\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9121e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8861\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9180e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8856\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9256e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8833\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9152e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8844\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9304e-04 - accuracy: 0.9835 - val_loss: 0.0018 - val_accuracy: 0.8822\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.9280e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8828\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9176e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8839\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9121e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8822\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9092e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8828\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8965e-04 - accuracy: 0.9836 - val_loss: 0.0017 - val_accuracy: 0.8833\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8996e-04 - accuracy: 0.9836 - val_loss: 0.0017 - val_accuracy: 0.8856\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9039e-04 - accuracy: 0.9836 - val_loss: 0.0017 - val_accuracy: 0.8839\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8954e-04 - accuracy: 0.9836 - val_loss: 0.0017 - val_accuracy: 0.8850\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8945e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8817\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8858e-04 - accuracy: 0.9837 - val_loss: 0.0017 - val_accuracy: 0.8917\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8896e-04 - accuracy: 0.9837 - val_loss: 0.0017 - val_accuracy: 0.8878\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8979e-04 - accuracy: 0.9837 - val_loss: 0.0017 - val_accuracy: 0.8844\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8987e-04 - accuracy: 0.9836 - val_loss: 0.0017 - val_accuracy: 0.8856\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8877e-04 - accuracy: 0.9837 - val_loss: 0.0017 - val_accuracy: 0.8867\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8799e-04 - accuracy: 0.9837 - val_loss: 0.0017 - val_accuracy: 0.8861\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8732e-04 - accuracy: 0.9837 - val_loss: 0.0017 - val_accuracy: 0.8894\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8794e-04 - accuracy: 0.9837 - val_loss: 0.0017 - val_accuracy: 0.8872\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8772e-04 - accuracy: 0.9837 - val_loss: 0.0016 - val_accuracy: 0.8878\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8849e-04 - accuracy: 0.9839 - val_loss: 0.0016 - val_accuracy: 0.8856\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8813e-04 - accuracy: 0.9838 - val_loss: 0.0017 - val_accuracy: 0.8856\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8873e-04 - accuracy: 0.9837 - val_loss: 0.0017 - val_accuracy: 0.8856\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8897e-04 - accuracy: 0.9838 - val_loss: 0.0017 - val_accuracy: 0.8828\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8674e-04 - accuracy: 0.9840 - val_loss: 0.0016 - val_accuracy: 0.8867\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8687e-04 - accuracy: 0.9840 - val_loss: 0.0016 - val_accuracy: 0.8867\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8761e-04 - accuracy: 0.9840 - val_loss: 0.0016 - val_accuracy: 0.8867\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8755e-04 - accuracy: 0.9840 - val_loss: 0.0017 - val_accuracy: 0.8850\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8515e-04 - accuracy: 0.9840 - val_loss: 0.0017 - val_accuracy: 0.8783\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 2.0295e-04 - accuracy: 0.9833 - val_loss: 0.0018 - val_accuracy: 0.8761\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.0771e-04 - accuracy: 0.9835 - val_loss: 0.0017 - val_accuracy: 0.8861\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 2.0283e-04 - accuracy: 0.9835 - val_loss: 0.0018 - val_accuracy: 0.8828\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9761e-04 - accuracy: 0.9837 - val_loss: 0.0017 - val_accuracy: 0.8817\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9265e-04 - accuracy: 0.9839 - val_loss: 0.0017 - val_accuracy: 0.8828\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.9078e-04 - accuracy: 0.9840 - val_loss: 0.0017 - val_accuracy: 0.8867\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9071e-04 - accuracy: 0.9839 - val_loss: 0.0016 - val_accuracy: 0.8911\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8864e-04 - accuracy: 0.9840 - val_loss: 0.0017 - val_accuracy: 0.8878\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9507e-04 - accuracy: 0.9837 - val_loss: 0.0017 - val_accuracy: 0.8878\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8899e-04 - accuracy: 0.9841 - val_loss: 0.0017 - val_accuracy: 0.8844\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8214e-04 - accuracy: 0.9849 - val_loss: 0.0017 - val_accuracy: 0.8856\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7938e-04 - accuracy: 0.9850 - val_loss: 0.0017 - val_accuracy: 0.8900\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8477e-04 - accuracy: 0.9848 - val_loss: 0.0018 - val_accuracy: 0.8822\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8451e-04 - accuracy: 0.9849 - val_loss: 0.0016 - val_accuracy: 0.8917\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8007e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8950\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8423e-04 - accuracy: 0.9849 - val_loss: 0.0017 - val_accuracy: 0.8844\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8286e-04 - accuracy: 0.9849 - val_loss: 0.0016 - val_accuracy: 0.8939\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8422e-04 - accuracy: 0.9850 - val_loss: 0.0017 - val_accuracy: 0.8894\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8453e-04 - accuracy: 0.9849 - val_loss: 0.0016 - val_accuracy: 0.8906\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8194e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8911\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.7963e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8911\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.7730e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8922\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.7721e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8956\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.7858e-04 - accuracy: 0.9850 - val_loss: 0.0017 - val_accuracy: 0.8883\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7823e-04 - accuracy: 0.9850 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.7898e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8928\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.7960e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8950\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8721e-04 - accuracy: 0.9849 - val_loss: 0.0019 - val_accuracy: 0.8750\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.0309e-04 - accuracy: 0.9838 - val_loss: 0.0017 - val_accuracy: 0.8811\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.2268e-04 - accuracy: 0.9832 - val_loss: 0.0021 - val_accuracy: 0.8583\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.3188e-04 - accuracy: 0.9822 - val_loss: 0.0021 - val_accuracy: 0.8594\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.4472e-04 - accuracy: 0.9817 - val_loss: 0.0018 - val_accuracy: 0.8767\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.6454e-04 - accuracy: 0.9803 - val_loss: 0.0040 - val_accuracy: 0.7417\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0013 - accuracy: 0.9104 - val_loss: 0.0036 - val_accuracy: 0.7733\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 0.0013 - accuracy: 0.9142 - val_loss: 0.0036 - val_accuracy: 0.7728\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0011 - accuracy: 0.9267 - val_loss: 0.0033 - val_accuracy: 0.7933\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 0.0010 - accuracy: 0.9322 - val_loss: 0.0032 - val_accuracy: 0.7933\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 6.1640e-04 - accuracy: 0.9575 - val_loss: 0.0027 - val_accuracy: 0.8317\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 4.5497e-04 - accuracy: 0.9696 - val_loss: 0.0023 - val_accuracy: 0.8572\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 3.3581e-04 - accuracy: 0.9776 - val_loss: 0.0019 - val_accuracy: 0.8706\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.4868e-04 - accuracy: 0.9823 - val_loss: 0.0019 - val_accuracy: 0.8733\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 2.2679e-04 - accuracy: 0.9835 - val_loss: 0.0018 - val_accuracy: 0.8861\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.0997e-04 - accuracy: 0.9844 - val_loss: 0.0017 - val_accuracy: 0.8872\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 2.0027e-04 - accuracy: 0.9847 - val_loss: 0.0016 - val_accuracy: 0.8939\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9626e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8939\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9425e-04 - accuracy: 0.9850 - val_loss: 0.0017 - val_accuracy: 0.8922\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9134e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8972\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9040e-04 - accuracy: 0.9849 - val_loss: 0.0017 - val_accuracy: 0.8872\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9026e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8933\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8852e-04 - accuracy: 0.9851 - val_loss: 0.0017 - val_accuracy: 0.8906\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.9285e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9654e-04 - accuracy: 0.9849 - val_loss: 0.0016 - val_accuracy: 0.8933\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9294e-04 - accuracy: 0.9849 - val_loss: 0.0017 - val_accuracy: 0.8906\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9187e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.9000\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8886e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8956\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8999e-04 - accuracy: 0.9850 - val_loss: 0.0016 - val_accuracy: 0.8956\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8818e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8956\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 1.8689e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8939\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8730e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8922\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8490e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9006\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8642e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.8978\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8616e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.8961\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8444e-04 - accuracy: 0.9850 - val_loss: 0.0015 - val_accuracy: 0.8994\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8567e-04 - accuracy: 0.9849 - val_loss: 0.0016 - val_accuracy: 0.8922\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8474e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8229e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9000\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8204e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8377e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8972\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8104e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.9006\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8415e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.9000\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8393e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8351e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.8983\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8218e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8967\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.7931e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8961\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8143e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9000\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8043e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8967\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8052e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8967\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8073e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8989\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8117e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.8972\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8053e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9039\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.7865e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8983\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.7904e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9028\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8597e-04 - accuracy: 0.9849 - val_loss: 0.0016 - val_accuracy: 0.8983\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8521e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8956\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8092e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8972\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8094e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8972\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8160e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9017\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8045e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.8978\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8118e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8180e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9000\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8010e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8911\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.7879e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9000\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.7978e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9017\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8003e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8928\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8043e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.8950\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8234e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.8961\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9365e-04 - accuracy: 0.9848 - val_loss: 0.0016 - val_accuracy: 0.8911\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8863e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8325e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8933\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8016e-04 - accuracy: 0.9852 - val_loss: 0.0017 - val_accuracy: 0.8933\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9887e-04 - accuracy: 0.9843 - val_loss: 0.0017 - val_accuracy: 0.8867\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9311e-04 - accuracy: 0.9849 - val_loss: 0.0018 - val_accuracy: 0.8783\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.9310e-04 - accuracy: 0.9847 - val_loss: 0.0018 - val_accuracy: 0.8778\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8797e-04 - accuracy: 0.9848 - val_loss: 0.0016 - val_accuracy: 0.8933\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8362e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8917\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8506e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8961\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8083e-04 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 0.8972\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7871e-04 - accuracy: 0.9852 - val_loss: 0.0016 - val_accuracy: 0.8972\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.7966e-04 - accuracy: 0.9852 - val_loss: 0.0016 - val_accuracy: 0.8894\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.7896e-04 - accuracy: 0.9852 - val_loss: 0.0016 - val_accuracy: 0.8922\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8003e-04 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 0.8994\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8043e-04 - accuracy: 0.9852 - val_loss: 0.0016 - val_accuracy: 0.8939\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8080e-04 - accuracy: 0.9852 - val_loss: 0.0016 - val_accuracy: 0.8961\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8692e-04 - accuracy: 0.9849 - val_loss: 0.0016 - val_accuracy: 0.8933\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8142e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8928\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7848e-04 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.7743e-04 - accuracy: 0.9852 - val_loss: 0.0016 - val_accuracy: 0.8944\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.7653e-04 - accuracy: 0.9852 - val_loss: 0.0016 - val_accuracy: 0.8978\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8733e-04 - accuracy: 0.9848 - val_loss: 0.0017 - val_accuracy: 0.8928\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8319e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.8956\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8705e-04 - accuracy: 0.9848 - val_loss: 0.0015 - val_accuracy: 0.8994\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8167e-04 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 0.9033\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 6s 401ms/step - loss: 1.8067e-04 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 0.8972\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8252e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9000\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.8778e-04 - accuracy: 0.9849 - val_loss: 0.0017 - val_accuracy: 0.8839\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8861e-04 - accuracy: 0.9849 - val_loss: 0.0017 - val_accuracy: 0.8917\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8578e-04 - accuracy: 0.9851 - val_loss: 0.0016 - val_accuracy: 0.8950\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9248e-04 - accuracy: 0.9849 - val_loss: 0.0016 - val_accuracy: 0.8978\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9027e-04 - accuracy: 0.9846 - val_loss: 0.0015 - val_accuracy: 0.8989\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8278e-04 - accuracy: 0.9852 - val_loss: 0.0015 - val_accuracy: 0.8994\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8997e-04 - accuracy: 0.9849 - val_loss: 0.0016 - val_accuracy: 0.8961\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 6s 400ms/step - loss: 1.9064e-04 - accuracy: 0.9849 - val_loss: 0.0015 - val_accuracy: 0.8956\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 6s 399ms/step - loss: 1.8492e-04 - accuracy: 0.9851 - val_loss: 0.0015 - val_accuracy: 0.9000\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, batch_size =1024, epochs = 500, verbose = 1, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afac0ed1-e2b2-4400-d85b-b2278d1d0407",
        "id": "D29cO2IxCqNC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 1s 22ms/step - loss: 0.0015 - accuracy: 0.9017\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0014801811194047332, 0.9016666412353516]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('lstm_lowpass_2s.h5')"
      ],
      "metadata": {
        "id": "5DxE8ul2Qisz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyeuHQ8OCqND"
      },
      "source": [
        "## 그래프 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "outputId": "dbb8d682-c685-4f7e-b37c-39034c15cd17",
        "id": "xL7NRpO3CqND"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f66f6213ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "history=history.history\n",
        "epochs = range(1, len(history['loss']) + 1)\n",
        "acc = history['accuracy']\n",
        "loss = history['loss']\n",
        "val_acc = history['val_accuracy']\n",
        "val_loss = history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(epochs, acc, label='accuracy')\n",
        "plt.plot(epochs, val_acc, label='val_acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(epochs, loss, label='loss', color='g')\n",
        "plt.plot(epochs, val_loss, label='val_loss', color='r')\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKAUUKqPCqNE"
      },
      "source": [
        "## 예측해보기(predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델을 잊어버리고 저장을 안해놔서 해당 모델 예측해보기는 못했습니다."
      ],
      "metadata": {
        "id": "LuosrdImHPXt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e06685b-4c91-4d7b-804a-f36f83b0daf8",
        "id": "zBIH6nMgCqNF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "188/188 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[44,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0, 57,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0, 65, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 68,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0, 67,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0, 57]])"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348ddc8c-b4b0-4b45-9b9b-a83b87cbce28",
        "id": "DYzkKasECqNF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       59.0\n",
              "1       68.0\n",
              "2       72.0\n",
              "3        2.0\n",
              "4       57.0\n",
              "        ... \n",
              "5995     3.0\n",
              "5996    87.0\n",
              "5997    40.0\n",
              "5998    68.0\n",
              "5999    37.0\n",
              "Name: y_test, Length: 6000, dtype: float64"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test_p=pd.DataFrame(y_test)\n",
        "\n",
        "for i in range(1,101):\n",
        "  y_test_p.loc[y_test_p[i] == 1.0 , 'y_test'] = i  \n",
        "y_test_p.y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "22f2ac13-d7ce-409c-db36-bf92c9ca0cad",
        "id": "rIYlxRoGCqNF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>87.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>45.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33a2dfcf-6ed7-497f-9b45-70f7cc7db973');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         0\n",
              "0     59.0\n",
              "1     68.0\n",
              "2     72.0\n",
              "3      2.0\n",
              "4     57.0\n",
              "...    ...\n",
              "5995   3.0\n",
              "5996  87.0\n",
              "5997  40.0\n",
              "5998  68.0\n",
              "5999  45.0\n",
              "\n",
              "[6000 rows x 1 columns]"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex=np.argmax(y_pred, axis=1)\n",
        "ex=ex.astype('float64')\n",
        "ex=pd.DataFrame(ex)\n",
        "ex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvlX3N8KCqNF"
      },
      "outputs": [],
      "source": [
        "ch1 = pd.DataFrame(np.rint(y_pred))\n",
        "ch1['pred'] = ex\n",
        "data_test.reset_index(inplace=True, drop=True)\n",
        "predict = pd.concat([data_test,ch1['pred'], y_test_p['y_test']],axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICBAIoG-CqNG"
      },
      "outputs": [],
      "source": [
        "predict['compare'] = np.where(predict['pred']==predict['y_test'],'yes', 'no')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "833df983-0f21-460a-de46-668f491d18e1",
        "id": "SX_3O1e0CqNG"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-22dffb56-3200-49eb-89c1-97f537806f07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>pred</th>\n",
              "      <th>y_test</th>\n",
              "      <th>compare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.001909</td>\n",
              "      <td>0.008317</td>\n",
              "      <td>0.014489</td>\n",
              "      <td>0.020412</td>\n",
              "      <td>0.025995</td>\n",
              "      <td>0.031137</td>\n",
              "      <td>0.035801</td>\n",
              "      <td>0.040075</td>\n",
              "      <td>0.044195</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044631</td>\n",
              "      <td>0.050399</td>\n",
              "      <td>0.057432</td>\n",
              "      <td>0.066046</td>\n",
              "      <td>0.076371</td>\n",
              "      <td>0.088327</td>\n",
              "      <td>0.101648</td>\n",
              "      <td>85.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.096114</td>\n",
              "      <td>0.095362</td>\n",
              "      <td>0.095047</td>\n",
              "      <td>0.095447</td>\n",
              "      <td>0.096676</td>\n",
              "      <td>0.098677</td>\n",
              "      <td>0.101247</td>\n",
              "      <td>0.104083</td>\n",
              "      <td>0.106844</td>\n",
              "      <td>0.109202</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004398</td>\n",
              "      <td>-0.008214</td>\n",
              "      <td>-0.013081</td>\n",
              "      <td>-0.019006</td>\n",
              "      <td>-0.025674</td>\n",
              "      <td>-0.032320</td>\n",
              "      <td>-0.037693</td>\n",
              "      <td>83.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>-0.041972</td>\n",
              "      <td>-0.048778</td>\n",
              "      <td>-0.055266</td>\n",
              "      <td>-0.061636</td>\n",
              "      <td>-0.067728</td>\n",
              "      <td>-0.073065</td>\n",
              "      <td>-0.076978</td>\n",
              "      <td>-0.078796</td>\n",
              "      <td>-0.078050</td>\n",
              "      <td>-0.074630</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.102289</td>\n",
              "      <td>-0.108650</td>\n",
              "      <td>-0.114708</td>\n",
              "      <td>-0.119718</td>\n",
              "      <td>-0.122885</td>\n",
              "      <td>-0.123496</td>\n",
              "      <td>-0.121095</td>\n",
              "      <td>20.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.050686</td>\n",
              "      <td>0.056807</td>\n",
              "      <td>0.061922</td>\n",
              "      <td>0.066330</td>\n",
              "      <td>0.070463</td>\n",
              "      <td>0.074831</td>\n",
              "      <td>0.079964</td>\n",
              "      <td>0.086349</td>\n",
              "      <td>0.094365</td>\n",
              "      <td>0.104239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.125449</td>\n",
              "      <td>0.136371</td>\n",
              "      <td>0.147691</td>\n",
              "      <td>0.159697</td>\n",
              "      <td>0.172642</td>\n",
              "      <td>0.186692</td>\n",
              "      <td>0.201860</td>\n",
              "      <td>41.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>-0.511413</td>\n",
              "      <td>-0.507140</td>\n",
              "      <td>-0.469849</td>\n",
              "      <td>-0.408462</td>\n",
              "      <td>-0.333769</td>\n",
              "      <td>-0.256404</td>\n",
              "      <td>-0.185178</td>\n",
              "      <td>-0.126038</td>\n",
              "      <td>-0.081724</td>\n",
              "      <td>-0.052058</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031533</td>\n",
              "      <td>0.034874</td>\n",
              "      <td>0.038518</td>\n",
              "      <td>0.042180</td>\n",
              "      <td>0.045745</td>\n",
              "      <td>0.049241</td>\n",
              "      <td>0.052764</td>\n",
              "      <td>4.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>0.005315</td>\n",
              "      <td>-0.043084</td>\n",
              "      <td>-0.083200</td>\n",
              "      <td>-0.110473</td>\n",
              "      <td>-0.122973</td>\n",
              "      <td>-0.121490</td>\n",
              "      <td>-0.109050</td>\n",
              "      <td>-0.090022</td>\n",
              "      <td>-0.069069</td>\n",
              "      <td>-0.050204</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.027012</td>\n",
              "      <td>-0.029614</td>\n",
              "      <td>-0.031356</td>\n",
              "      <td>-0.033020</td>\n",
              "      <td>-0.035244</td>\n",
              "      <td>-0.038329</td>\n",
              "      <td>-0.042129</td>\n",
              "      <td>95.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5981</th>\n",
              "      <td>-0.005281</td>\n",
              "      <td>-0.018280</td>\n",
              "      <td>-0.031669</td>\n",
              "      <td>-0.042939</td>\n",
              "      <td>-0.050464</td>\n",
              "      <td>-0.053648</td>\n",
              "      <td>-0.052817</td>\n",
              "      <td>-0.048958</td>\n",
              "      <td>-0.043371</td>\n",
              "      <td>-0.037307</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016826</td>\n",
              "      <td>-0.013496</td>\n",
              "      <td>-0.011275</td>\n",
              "      <td>-0.010594</td>\n",
              "      <td>-0.011830</td>\n",
              "      <td>-0.015208</td>\n",
              "      <td>-0.020697</td>\n",
              "      <td>52.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5992</th>\n",
              "      <td>-0.084734</td>\n",
              "      <td>-0.091664</td>\n",
              "      <td>-0.098196</td>\n",
              "      <td>-0.101411</td>\n",
              "      <td>-0.098148</td>\n",
              "      <td>-0.085744</td>\n",
              "      <td>-0.062829</td>\n",
              "      <td>-0.030004</td>\n",
              "      <td>0.009808</td>\n",
              "      <td>0.051498</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072150</td>\n",
              "      <td>0.081214</td>\n",
              "      <td>0.090895</td>\n",
              "      <td>0.101388</td>\n",
              "      <td>0.112932</td>\n",
              "      <td>0.125713</td>\n",
              "      <td>0.139775</td>\n",
              "      <td>100.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5994</th>\n",
              "      <td>0.008461</td>\n",
              "      <td>0.011468</td>\n",
              "      <td>0.012707</td>\n",
              "      <td>0.012096</td>\n",
              "      <td>0.009875</td>\n",
              "      <td>0.006558</td>\n",
              "      <td>0.002841</td>\n",
              "      <td>-0.000513</td>\n",
              "      <td>-0.002782</td>\n",
              "      <td>-0.003375</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.048723</td>\n",
              "      <td>-0.051678</td>\n",
              "      <td>-0.052151</td>\n",
              "      <td>-0.050205</td>\n",
              "      <td>-0.046318</td>\n",
              "      <td>-0.041326</td>\n",
              "      <td>-0.036264</td>\n",
              "      <td>95.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>0.052145</td>\n",
              "      <td>0.038833</td>\n",
              "      <td>0.024907</td>\n",
              "      <td>0.010402</td>\n",
              "      <td>-0.004429</td>\n",
              "      <td>-0.019087</td>\n",
              "      <td>-0.032867</td>\n",
              "      <td>-0.044991</td>\n",
              "      <td>-0.054774</td>\n",
              "      <td>-0.061789</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.056943</td>\n",
              "      <td>-0.054300</td>\n",
              "      <td>-0.054324</td>\n",
              "      <td>-0.058068</td>\n",
              "      <td>-0.065599</td>\n",
              "      <td>-0.075635</td>\n",
              "      <td>-0.085448</td>\n",
              "      <td>45.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>545 rows × 259 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22dffb56-3200-49eb-89c1-97f537806f07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22dffb56-3200-49eb-89c1-97f537806f07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22dffb56-3200-49eb-89c1-97f537806f07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "30    0.001909  0.008317  0.014489  0.020412  0.025995  0.031137  0.035801   \n",
              "46    0.096114  0.095362  0.095047  0.095447  0.096676  0.098677  0.101247   \n",
              "54   -0.041972 -0.048778 -0.055266 -0.061636 -0.067728 -0.073065 -0.076978   \n",
              "55    0.050686  0.056807  0.061922  0.066330  0.070463  0.074831  0.079964   \n",
              "71   -0.511413 -0.507140 -0.469849 -0.408462 -0.333769 -0.256404 -0.185178   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "5971  0.005315 -0.043084 -0.083200 -0.110473 -0.122973 -0.121490 -0.109050   \n",
              "5981 -0.005281 -0.018280 -0.031669 -0.042939 -0.050464 -0.053648 -0.052817   \n",
              "5992 -0.084734 -0.091664 -0.098196 -0.101411 -0.098148 -0.085744 -0.062829   \n",
              "5994  0.008461  0.011468  0.012707  0.012096  0.009875  0.006558  0.002841   \n",
              "5999  0.052145  0.038833  0.024907  0.010402 -0.004429 -0.019087 -0.032867   \n",
              "\n",
              "             7         8         9  ...       249       250       251  \\\n",
              "30    0.040075  0.044195  0.048538  ...  0.044631  0.050399  0.057432   \n",
              "46    0.104083  0.106844  0.109202  ... -0.004398 -0.008214 -0.013081   \n",
              "54   -0.078796 -0.078050 -0.074630  ... -0.102289 -0.108650 -0.114708   \n",
              "55    0.086349  0.094365  0.104239  ...  0.125449  0.136371  0.147691   \n",
              "71   -0.126038 -0.081724 -0.052058  ...  0.031533  0.034874  0.038518   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "5971 -0.090022 -0.069069 -0.050204  ... -0.027012 -0.029614 -0.031356   \n",
              "5981 -0.048958 -0.043371 -0.037307  ... -0.016826 -0.013496 -0.011275   \n",
              "5992 -0.030004  0.009808  0.051498  ...  0.072150  0.081214  0.090895   \n",
              "5994 -0.000513 -0.002782 -0.003375  ... -0.048723 -0.051678 -0.052151   \n",
              "5999 -0.044991 -0.054774 -0.061789  ... -0.056943 -0.054300 -0.054324   \n",
              "\n",
              "           252       253       254       255   pred  y_test  compare  \n",
              "30    0.066046  0.076371  0.088327  0.101648   85.0    36.0       no  \n",
              "46   -0.019006 -0.025674 -0.032320 -0.037693   83.0    80.0       no  \n",
              "54   -0.119718 -0.122885 -0.123496 -0.121095   20.0    71.0       no  \n",
              "55    0.159697  0.172642  0.186692  0.201860   41.0    50.0       no  \n",
              "71    0.042180  0.045745  0.049241  0.052764    4.0    93.0       no  \n",
              "...        ...       ...       ...       ...    ...     ...      ...  \n",
              "5971 -0.033020 -0.035244 -0.038329 -0.042129   95.0    23.0       no  \n",
              "5981 -0.010594 -0.011830 -0.015208 -0.020697   52.0    40.0       no  \n",
              "5992  0.101388  0.112932  0.125713  0.139775  100.0    83.0       no  \n",
              "5994 -0.050205 -0.046318 -0.041326 -0.036264   95.0    49.0       no  \n",
              "5999 -0.058068 -0.065599 -0.075635 -0.085448   45.0    37.0       no  \n",
              "\n",
              "[545 rows x 259 columns]"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_1 = predict[predict[\"compare\"]=='no']\n",
        "predict_1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Lzt1SMEoSshL",
        "EgfaelmnXe04",
        "m-Hm3lsWXkbE",
        "Na73oRb9Xq69",
        "DBnTIBCDGX94",
        "mLO6GGJ5Nn9w",
        "2aZgEs15Kln5"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}